Neon documentation
Neon is a serverless Postgres platform designed to help you build reliable and scalable applications faster. We separate compute and storage to offer modern developer features such as autoscaling, branching, point-in-time restore, and more. Get started today with our generous free plan.
Why Neon?
Neon is Serverless Postgres built for the cloud

Looking back at Neon's debut blog post, SELECT ’Hello, World’, the fundamental reasons for Why Neon remain the same:

To build the best Postgres experience in the cloud

This is still our core mission today. It was clear to us then, as it is now, that database workloads are shifting into the cloud — and no one wants to manage a database themselves.

In an ever-changing technology stack, we believe Postgres is here to stay

Just like the Linux operating system or Git version control, we believe Postgres is the default choice for a relational database system. That’s why all of the major platforms like AWS, Azure, Google Cloud, Digital Ocean, and many newcomers to this space offer Postgres as a service.

An idea that a modern Postgres cloud service can be designed differently

We call this approach separation of storage and compute, which lets us architect the service around performance, reliability, manageability, and cost-efficiency.

The belief that our architecture can provide a better Developer Experience (DevX)

Features such as autoscaling, branching, time travel, and instant databases, backups, and restore improve the developer experience by allowing quick environment setup, efficient developer workflows, and immediate database availability.

These are Neon's reasons, but given the many database-as-a-service options available today, let's take a look at the reasons why you should choose Neon:

Neon is Postgres
Postgres is the world's most popular open-source database.

From its beginning as a DARPA-sponsored project at Berkeley, Postgres has fostered an ever-growing community and is a preferred database among developers because of its performance, reliability, extensibility, and support for features like ACID transactions, advanced SQL, and NoSQL/JSON. Neon supports all of the latest Postgres versions and numerous Postgres extensions.

If your application runs on Postgres, it runs on Neon. If it doesn't run on Postgres, sign up for a Free Plan account, join our Discord server, and start the journey with us.

Neon is serverless
A serverless architecture built for performance, reliability, manageability, and cost efficiency

Neon's architecture separates compute from storage, which enables serverless features like instant provisioning, autoscaling, autosuspend, and more.

Separating compute from storage refers to an architecture where the database computation processes (queries, transactions, etc.) are handled by one set of resources (compute), while the data itself is stored on a separate set of resources (storage). This design contrasts with traditional architectures where compute and storage are tightly coupled on the same server. In Neon, Postgres runs on a compute, and data (except for what's cached in memory) resides on Neon's storage layer.

Separation of compute and storage enables scalability as these resources can be scaled independently. You can adjust for processing power or storage capacity as needed without affecting the other. This approach is also cost-efficient. The ability to scale resources independently means you can benefit from the lower cost of storage compared to compute or avoid paying for additional storage when you only require extra processing power. Decoupling compute and storage also improves availability and durability, as data remains accessible and safe even if a compute fails.

Read more about the benefits of Neon's serverless architecture and how it supports database-per-user architectures, variable workloads, and database branching workflows.

Neon is fully managed
Leave the database administrative, maintenance, and scaling burdens to us.

Being a fully managed service means that Neon provides high availability without requiring users to handle administrative, maintenance, or scaling burdens associated with managing a database system. This approach allows developers to focus more on developing applications and less on the operational aspects of database management. Neon takes care of the complexities of scaling, backups, maintenance, and ensuring availability, enabling developers to manage their data without worrying about the underlying infrastructure.

Neon is open source
Neon is developed under an Apache 2.0 license.

Neon is not the first to offer separation of storage and compute for Postgres. AWS Aurora is probably the most famous example; however, it is proprietary and tied to AWS’s internal infrastructure.

We believe we have an opportunity to define the standard for cloud Postgres. We carefully designed our storage, focusing on cloud independence, performance, manageability, DevX, and cost. We chose the most permissive open-source license, Apache 2.0, and invited the world to participate. You can already build and run your own self-hosted instance of Neon. Check out our neon GitHub repository and the #self-hosted channel on our Discord server.

Neon doesn't lock you in
As a true Postgres platform, there's no lock-in with Neon.

Building on Neon is building on Postgres. If you are already running Postgres, getting started is easy. Import your data and connect. Migrating from other databases like MySQL or MongoDB is just as easy.

If you need to move data, you won't have to tear apart your application to remove proprietary application layers. Neon is pro-ecosystem and pro-integration. We encourage you to build with the frameworks, platforms, and services that best fit your requirements. Neon works to enable that. Check out our ever-expanding collection of framework, language, and integration guides.

Who should use Neon?
You. And we're ready to help you get started.

Neon is designed for a wide range of users, from individual developers to enterprises, seeking modern, serverless Postgres capabilities. It caters to those who need a fully managed, scalable, and cost-effective database solution. Key users include:

Individual developers looking for a fast and easy way to set up a Postgres database without the hassle of installation or configuration. Neon's Free Plan makes it easy to get started. Free Plan users get access to all regions and features like connection pooling, project sharing, and branching. When you are ready to scale, you can easily upgrade your account to a paid plan for more computing power, storage, and advanced features.

Neon's Free Plan is here to stay
Neon's Free Plan is a fundamental part of our commitment to users. Our architecture, which separates storage and compute, enables a sustainable Free Plan. You can build your personal project or PoC with confidence, knowing that our Free Plan is here to stay. Learn more about our Free Plan from Neon's CEO.

Teams and organizations that aim to enhance their development workflows with the ability to create database branches for testing new features or updates, mirroring the branching process used in code version control.

Enterprises requiring scalable, high-performance database solutions with advanced features like autoscaling, autosuspend, point-in-time restore, and logical replication. Enterprises can benefit from custom pricing, higher resource allowances, and enterprise-level support to meet their specific requirements.

In summary, Neon is built for anyone who requires a Postgres database and wants to benefit from the scalability, ease of use, cost savings, and advanced DevX capabilities provided by Neon's serverless architecture.

Neon makes it easy to get started with Postgres
Set up your Postgres database in seconds.

Log in with an email address, Google, or GitHub account.
Provide a project name and database name, and select a region.
Click Create Project.
Neon's architecture allows us to spin up a Postgres database almost instantly and provide you with a database URL, which you can plug into your application or database client.

postgresql://alex:AbC123dEf@ep-cool-darkness-123456.us-east-2.aws.neon.tech/dbname
Additionally, after signing up, we land you on your project dashboard, where you'll find connection snippets for various frameworks, languages, and platforms.

Next.js connection snippet from the Connection details widget on the Neon Dashboard

If you are not quite ready to hook up an application, you can explore Neon from the console. Create the playing_with_neon table using the Neon SQL Editor, run some queries, or create a database branch.

Initially, you'll be signed up for Neon's Free Plan, but you can easily upgrade to one of our paid plans when you're ready.
Developer experience with Neon
Enhancing development workflows with Neon

Discover how Neon's features can streamline your development process, reduce risks, and enhance productivity, helping you to ship faster with confidence.

Developer velocity with database branching workflows
Branch your data like code for local and preview development workflows.

Neon's branching feature lets you branch your data like you branch code. Neon branches are full database copies, including both schema and data. You can instantly create database branches for integration with your development workflows.

Branching workflows

You can build your database branching workflows using the Neon CLI, Neon API, or GitHub Actions. For example, this example shows how to create a development branch from main with a simple CLI command:

neon branches create --name dev/alex
Neon's copy-on-write technique makes branching instantaneous and cost-efficient. Whether your database is 1 GiB or 1 TiB, it only takes seconds to create a branch, and Neon's branches are full database copies, not partial or schema-only.

Also, with Neon, you can easily keep your development branches up-to-date by resetting your schema and data to the latest from main with a simple command.

neon branches reset dev/alex --parent
No more time-consuming restore operations when you need a fresh database copy.

You can use branching with deployment platforms such as Vercel to create a database branch for each preview deployment. If you'd rather not build your own branching workflow, you can use the Neon Vercel integration to set one up in just a few clicks.

To learn more, read Database Branching Workflows, and the Database branching workflow guide for developers.

Compare database branches with Schema Diff
Neon's Schema Diff tool lets you compare the schemas for two selected branches in a side-by-side view. For more, see Schema Diff.

Instant database recovery
Instant Point-in-Time Restore with Time Travel Assist

We've all heard about multi-hour outages and data losses due to errant queries or problematic migrations. Neon's Point-in-Time Restore feature allows you to instantly restore your data to a point in time before the issue occurred. With Neon, you can perform a restore operation in a few clicks, letting you get back online in the time it takes to choose a restore point, which can be a date and time or a Log Sequence Number (LSN).

To help you find the correct restore point, Neon provides a Time Travel Assist feature that lets you connect to any selected time or LSN within your database history and run queries. Time Travel Assist is designed to work in tandem with Neon's restore capability to facilitate precise and informed restore operations.

Low-latency connections
Connect from Edge and serverless environments.

The Neon serverless driver, which currently has over 100K weekly downloads, is a low-latency Postgres driver designed for JavaScript and TypeScript applications. It enables you to query data from edge and serverless environments like Vercel Edge Functions or Cloudflare Workers over HTTP or WebSockets instead of TCP. This capability is particularly useful for achieving reduced query latencies, with the potential to achieve sub-10ms Postgres query times when querying from Edge or serverless functions. But don't take our word for it. Try it for yourself with Vercel's Functions + Database Latency app. This graph shows latencies for Neon's serverless driver:

Vercel's Functions Database Latency app

Postgres extension support
No database is more extensible than Postgres.

Postgres extensions are add-ons that enhance the functionality of Postgres, letting you tailor your Postgres database to your specific requirements. They offer features ranging from advanced indexing and data types to geospatial capabilities and analytics, allowing you to significantly expand the native capabilities of Postgres. Some of the more popular Postgres extensions include:

PostGIS: Adds support for geographic objects, turning PostgreSQL into a spatial database.
pg_stat_statements: Tracks execution statistics of all SQL queries for performance tuning.
pg_partman: Simplifies partition management, making it easier to maintain time-based or serial-based table partitions.
pg_trgm: Provides fast similarity search using trigrams, ideal for full-text search.
hstore: Implements key-value pairs for semi-structured data storage.
plpgsql: Enables procedural language functions with PL/pgSQL scripting.
pgcrypto: Offers cryptographic functions, including data encryption and decryption.
pgvector: Brings vector similarity search to Postgres for building AI applications.
These are just a few of the extensions supported by Neon. Explore all supported extensions here.

Extensions can be installed with a simple CREATE EXTENSION command from Neon's SQL Editor or any SQL client; for example:

CREATE EXTENSION pgcrypto;
Build your AI applications with Postgres
Why pay for a specialized vector database service when you can just use Postgres?

Neon supports the pgvector Postgres extension for storing and retrieving vector embeddings within your Postgres database. This feature is essential for building next-generation AI applications, enabling operations like fast and accurate similarity search, information retrieval, and recommendation systems directly in Postgres. Why pay for or add the complexity of a specialized vector database service when you have leading-edge capabilities in Postgres? Neon's own Ask Neon AI chat, built in collaboration with InKeep, uses Neon with pgvector. For more, see Powering next gen AI apps with Postgres.

Database DevOps with Neon's CLI, API, and GitHub Actions
Neon is built for DevOps. Use our CLI, API, or GitHub Actions to build your CI/CD pipelines.

Neon CLI

With the Neon CLI, you can integrate Neon with development tools and CI/CD pipelines to enhance your development workflows, reducing the friction associated with database-related operations like creating projects, databases, and branches. Once you have your connection string, you can manage your entire Neon database from the command line. This makes it possible to quickly set up deployment pipelines using GitHub Actions, GitLab CI/CD, or Vercel Preview Environments. These operations and pipelines can also be treated as code and live alongside your applications as they evolve and mature.

neon branches create --name dev/alex
Neon API

The Neon API is a REST API that enables you to manage your Neon projects programmatically. It provides resource-oriented URLs, accepts request bodies, returns JSON responses, and uses standard HTTP response codes. This API allows for a wide range of operations, enabling automation management of various aspects of Neon, including projects, branches, computes, databases, and roles. Like the Neon CLI, you can use the Neon API for seamless integration of Neon's capabilities into automated workflows, CI/CD pipelines, and developer tools. Give it a try using our interactive Neon API reference.

curl --request POST \
    --url https://console.neon.tech/api/v2/projects/ancient-rice-43775340/branches \
    --header 'accept: application/json' \
    --header 'authorization: Bearer $NEON_API_KEY' \
    --header 'content-type: application/json' \
    --data '
{
  "branch": {
    "name": "dev/alex"
  },
  "endpoints": [
    {
      "type": "read_write"
    }
  ]
}
'
-- GitHub Actions

Neon provides the GitHub Actions for working with database branches, which you can add to your CI workflows. To learn more, see Automate branching with GitHub Actions.

name: Create Neon Branch with GitHub Actions Demo
run-name: Create a Neon Branch 🚀
jobs:
  Create-Neon-Branch:
    uses: neondatabase/create-branch-action@v5
    with:
      project_id: rapid-haze-373089
      # optional (defaults to your project's default branch)
      parent: dev
      # optional (defaults to neondb)
      database: my-database
      branch_name: from_action_reusable
      username: db_user_for_url
      api_key: ${{ secrets.NEON_API_KEY }}
    id: create-branch
  - run: echo db_url ${{ steps.create-branch.outputs.db_url }}
  - run: echo host ${{ steps.create-branch.outputs.host }}
  - run: echo branch_id ${{ steps.create-branch.outputs.branch_id }}

Production readiness with Neon
Neon features for real-world workloads

Learn how autoscaling, scale-to-zero, Neon's storage architecture, change data capture, read replicas, and support for thousands of connections can improve performance, reliability, and efficiency for your production environments.

Autoscaling
Automatically scale to meet demand.

Neon's autoscaling feature automatically and transparently scales up compute resources on demand in response to your application workload and scales down during periods of inactivity. What does this mean for you?

You are always ready for an increased load. Enable autoscaling and stop worrying about occasional traffic spikes.
You can stop paying for compute resources that you only use sometimes. You no longer have to run a maximum potential load configuration at all times.
No more manual scaling disruptions. With autoscaling, you can focus more on your application and less on managing infrastructure.
To learn more, see our Autoscaling guide.

Scale to zero
Stop paying for idle databases.

Neon's Autosuspend feature automatically transitions a Neon compute (where Postgres runs) to an idle state when it is not being used, effectively scaling it to zero to minimize compute usage and costs.

Why do you need a database that scales to zero? Combined with Neon's branching capability, scale to zero allows you to instantly spin up databases for development, experimentation, or testing without the typical costs associated with "always-running" databases with relatively little usage. This approach is ideal for various scenarios:

Non-production databases: Development, staging, and testing environments benefit as developers can work on multiple instances without cost concerns since these databases only use resources when active.
Internal apps: These apps often experience downtime during off-hours or holidays. Scale to zero ensures their supporting databases pause during inactivity, cutting costs without affecting usage during active periods.
Small projects: Implementing scale to zero for these projects' databases enhances cost efficiency without significantly impacting user experience.
Learn more about why you want a database that scales to zero.

A storage architecture built for the cloud
Efficient, performant, reliable storage

Neon's storage was built for high availability and durability. Every transaction is stored in multiple copies across availability zones and S3. Efficiency and performance are achieved through a multi-tier architecture designed to balance latency, throughput, and cost considerations.

Neon storage is architected to integrate storage, backups, and archiving into one system to reduce operational headaches and administrative overhead associated with checkpoints, data backups, and restore.

Neon uses cloud-based object storage solutions, like S3, to relocate less frequently accessed data to the most cost-efficient storage option. For your most frequently accessed data, which requires rapid access and high throughput, Neon uses locally attached SSDs to ensure high performance and low latency.

The entire Neon storage framework is developed in Rust for maximum performance and usability. Read about how we scale an open source, multi-tenant storage engine for Postgres written in Rust, or take a deep dive into the Neon storage engine with Neon Co-Founder, Heikki Linnakangas.

Change Data Capture (CDC) with Logical Replication
Stream your data to external data platforms and services.

Neon's Logical Replication feature enables replicating data from your Neon database to external destinations, allowing for Change Data Capture (CDC) and real-time analytics. Stream your data to data warehouses, analytical database services, messaging platforms, event-streaming platforms, external Postgres databases, and more. To learn more, see Get started with logical replication.

Scale with read replicas
Add read replicas to achieve instant scale.

Neon supports read replicas that let you instantly scale your application by offloading read-only workloads from your primary read-write compute.

Create a read replica with the Neon CLI:

neon branches create --name my_read_replica_branch --type read_only
To learn more, see Read replicas.

Support for thousands of connections
Add support for thousands of concurrent connections with a pooled connection string.

Neon's connection pooling feature supports up to 10,000 concurrent connections. Connection pooling works by caching and reusing database connections, which helps to significantly optimize resource usage and enhance performance. It reduces the overhead associated with establishing new connections and closing old ones, allowing applications to handle a higher volume of requests more efficiently. Neon uses PgBouncer to support connection pooling. Enabling connection pooling is easy. Just grab a pooled connection string from the console:

postgresql://alex:AbC123dEf@ep-cool-darkness-123456-pooler.us-east-2.aws.neon.tech/dbname
More Neon features
For an overview of all the features that Neon supports, including security features, visit Detailed Plan Comparison on the Neon Pricing page.

Neon architecture
Neon architecture is based on the separation of compute and storage and is orchestrated by the Neon Control Plane, which manages cloud resources across both storage and compute.

A Neon compute runs Postgres, and storage is a multi-tenant key-value store for Postgres pages that is custom-built for the cloud.

Neon architecture diagram

Neon storage consists of three main components: Safekeepers, Pageservers, and cloud object storage.

Safekeepers are responsible for durability of recent updates. Postgres streams Write-Ahead Log (WAL) to the Safekeepers, and the Safekeepers store the WAL durably until it has been processed by the Pageservers and uploaded to cloud storage.

Pageservers are responsible for serving read requests. To do that, Pageservers process the incoming WAL stream into a custom storage format that makes all page versions easily accessible. Pageservers also upload data to cloud object storage, and download the data on demand.

Safekeepers can be thought of as an ultra-reliable write buffer that holds the latest data until it is processed and uploaded to cloud storage. Safekeepers implement the Paxos protocol for reliability. Pageservers also function as a read cache for cloud storage, providing fast random access to data pages.

Durability
Durability is at the core of Neon's architecture. As described earlier, incoming WAL data is initially stored across multiple availability zones in a Paxos cluster before being uploaded to S3 (99.999999999% durability), both in raw WAL and materialized form. Additional copies are maintained across Pageservers to enhance the read performance of frequently accessed data. Consequently, there are always multiple copies of your data in Neon, ensuring durability.

Architecture
Autoscaling architecture
Learn how Neon automatically scales compute resources on demand

What you will learn:
How Neon's autoscaling architecture is structured

The role of key components like the autoscaler-agent and Kubernetes scheduler

Related topics
Introduction to autoscaling
Enabling autoscaling
How the algorithm works
A Neon project can have one or more computes, each representing an individual Postgres instance. Storage is decoupled from these computes, meaning that the Postgres servers executing queries are physically separate from the data storage location. This separation offers numerous advantages, including enablement of Neon's autoscaling feature.

High-level architecture diagram

Looking more closely, you can see that each Postgres instance operates within its own virtual machine inside a Kubernetes cluster, with multiple VMs hosted on each node of the cluster. Autoscaling is implemented by allocating and deallocating vCPU and RAM to each VM.

Autoscaling diagram

The autoscaler-agent
Each Kubernetes node hosts a single instance of the autoscaler-agent, which serves as the control mechanism for Neon's autoscaling system. The agent collects metrics from the VMs on its node, makes scaling decisions, and performs the necessary checks and requests to implement those decisions.

The Kubernetes scheduler
A Neon-modified Kubernetes scheduler coordinates with the autoscaler-agent and is the single source of truth for resource allocation. The autoscaler-agent obtains approval for all upscaling from the scheduler. The scheduler maintains a global view of all resource usage changes and approves requests for additional resources from the autoscaler-agent or standard scheduling. In this way, the scheduler assumes responsibility for preventing overcommitting of memory resources. In the rare event that a node exhausts its resources, new pods are not scheduled on the node, and the autoscaler-agent is denied permission to allocate more resources.

NeonVM
Kubernetes does not natively support the creation or management of VMs. To address this, Neon uses a tool called NeonVM. This tool is a custom resource definition and controller for VMs, handling tasks such as adding or removing CPUs and memory. Internally, NeonVM utilizes QEMU and KVM (where available) to achieve near-native performance.

When an autoscaler-agent needs to modify a VM's resource allocation, it simply updates the corresponding NeonVM object in Kubernetes, and the VM controller then manages the rest of the process.

Live migration
In cases where a Kubernetes node becomes saturated, NeonVM manages the process of live migrating a VM, transferring the VM from one machine to another with minimal interruptions (typically around 100ms). Live migration transmits the internal state of the original VM to a new one while the former continues to operate, swiftly transitioning to the new VM after most of the data is copied. From within the VM, the only indication that a migration occurred might be a temporary performance reduction. Importantly, the VM retains its IP address, ensuring that connections are preserved and queries remain uninterrupted.

The live migration process allows for the proactive reduction of node load by migrating VMs away before reaching capacity. Although it is still possible for the node to fill up in the interim, Neon's separation of storage and compute means that VMs typically use minimal disk space, resulting in fast migrations.

Memory scaling
Postgres memory consumption can escalate rapidly in specific scenarios. Fortunately, Neon's autoscaling system is able to detect memory usage increases without constantly requesting metrics from the VM. This is accomplished by running Postgres within a cgroups, which provides notifications when memory usage crosses a specified threshold. Using cgroups in this way requires running our vm-monitor in the VM alongside Postgres to request more resources from the autoscaler-agent when Postgres consumes too much memory. The vm-monitor also verifies that downscaling requests from an autoscaler-agent will leave sufficient memory leftover.

Local File Cache
To expedite queries, the autoscaling system incorporates a Postgres extension that places a cache in front of the storage layer. Many queries benefit from this additional memory, particularly those requiring multiple database scans (such as creating an index). The Local File Cache (LFC) capitalizes on the additional memory allocated to the VM by dedicating a portion to the cache to itself. The cache is backed by disk and kept at a size intended to fit in the kernel page cache. Due to the storage model, writebacks are not required, resulting in near-instant evictions. The vm-monitor adjusts the LFC size when scaling occurs through the autoscaler-agent, ensuring seamless operation.

Autoscaling source code
To further explore Neon's autoscaling implementation, visit Neon's autoscaling GitHub repository. While not primarily designed for external use, Neon welcomes exploration and contributions.

Architecture
Compute lifecycle
A compute in Neon is a stateless Postgres process due to the separation of storage and compute. It has two main states: Idle and Active.

Generally, an Idle compute has been suspended by Neon's Autosuspend feature due to inactivity, while an Active compute has been activated by a connection, indicating that Postgres is currently running.

Autosuspend
If there are no active queries for 5 minutes, which is the default autosuspend setting in Neon, your compute is automatically placed into an Idle state. If you are on a paid plan, you can disable this autosuspension behavior so that a compute always remains active, or you can increase or decrease the amount of time after which a compute is placed into an Idle state. Autosuspension behavior is controlled by your compute's Autosuspend setting.

Autosuspend configuration dialog

For information about configuring this setting, see Edit a compute.

note
Neon's Autosuspend feature is conservative. It treats an "idle-in-transaction" connection as active to avoid breaking application logic that involves long-running transactions. Only the truly inactive connections are closed after the defined period of inactivity.

Compute activation
When you connect to an idle compute, Neon automatically activates it. Activation generally takes a few hundred milliseconds.

Considering this activation time, your first connection may have a slightly higher latency than subsequent connections to an already-active compute. Also, Postgres memory buffers are cold after a compute wakes up from the Idle state, which means that initial queries may take longer until the memory buffers are warmed.

After a period of time in the Idle state, Neon occasionally activates your compute to check for data availability. The time between checks gradually increases if the compute does not receive any client connections over an extended period.

In the Branches widget on your Project Dashboard, you can check if a compute is active or idle and watch as it transitions from one state to another.

Compute state

Session context considerations
When connections are closed due to a compute being suspended, anything that exists within a session context is forgotten and must be recreated before being used again. For example, Postgres parameters set for a specific session, in-memory statistics, temporary tables, prepared statements, advisory locks, and notifications and listeners defined using NOTIFY/LISTEN commands only exist for the duration of the current session and are lost when the session ends.

For more, see Session context.

Neon feature guides
Explore Neon's capabilities with our feature guides

Autoscaling
Automatically scale compute resources up and down based on demand.

Learn about autoscaling
Find out how autoscaling can reduce your costs.

Enable autoscaling
Enable autoscaling to automatically scale compute resources on demand

Autosuspend
Control when Neon compute resources scale to zero.

Learn about Autosuspend
Discover how Neon can reduce your compute to zero when not in use

Configure Autosuspend
Configure autosuspend to control when your compute scales to zero

Branching
Branch data the same way you branch your code.

Learn about branching
With Neon, you can instantly branch your data in the same way that you branch your code

Point-in-time restore
Restore your data to a past state with database branching

Test queries on a branch
Use branching to test queries before running them in production

Branching with the CLI
Create and manage branches with the Neon CLI

Branching with the API
Create and manage branches with the Neon API

Branching with GitHub Actions
Automate branching with GitHub Actions

Refresh a branch
Refresh a development branch with the Neon API

Promote a branch to default
Promote a branch to default with the the Neon API

Logical replication
Replicate data from Neon to external data platforms and services.

Logical replication guide
Get started with logical replication in Neon

Logical replication concepts
Learn about Postgres logical replication concepts

Logical replication commands
Commands for managing your logical replication configuration

Logical replication in Neon
Information about logical replication specific to Neon

Read replicas
Learn how Neon read replicas can help you scale and manage read-only workloads.

Learn about read replicas
Learn how Neon maximizes scalability and more with read replicas

Working with read replicas
How to create and manage read replicas

Data analysis and reporting
Offload data analysis and reporting queries to read replicas

Use read replicas with Prisma
Scale your applications with Neon read replicas and Prisma Client

Time Travel
Travel back in time to view your database's history.

Learn about Time Travel
Learn how to query point-in-time connections against your data's history

Time Travel tutorial
Use Time Travel to analyze changes made to your database over time

Schema Diff
Compare your database branches.

Learn about Schema Diff
Learn how to use Neon's Schema Diff tool to compare branches of your database

Schema Diff tutorial
Step-by-step guide showing you how to compare two development branches using Schema Diff

Project sharing
Share your Neon project with anyone.

Share your Neon project with others
Give other users access to your project from the Neon Console, API, and CLI

IP Allow
Limit access to trusted IP addresses.

Define your IP allowlist
Learn how to limit database access to trusted IP addresses

Protected branches
Protect your production or sensitive data.

Configure protected branches
Learn how to use Neon's protected branches feature to secure access to critical data

Features
Serverless
Postgres with instant provisioning, no server management, and pay-per-usage billing

Neon takes the world's most loved database — Postgres — and delivers it as a serverless platform, enabling teams to ship reliable and scalable applications faster.

Enabling serverless Postgres begins with Neon's native decoupling of storage and compute. By separating these components, Neon can dynamically scale up during periods of high activity and down to zero when idle. Developers can be hands-off instead of sizing infrastructure manually.

This serverless character also makes Neon databases highly agile and well-suited for use cases that require automatic creation, management, and deletion of a high number of Postgres databases, like database-per-user architectures with thousands of tenants, as well as database branching workflows that accelerate development by enabling the management of dev/testing databases via CI/CD.

Multi-tenant storage

Read our Architecture section for more information on how Neon is built.

What “serverless” means to us
At Neon, we interpret “serverless” not only as the absence of servers to manage but as a set of principles and features designed to streamline your development process and optimize operational efficiency for your database.

To us, serverless means:

Instant provisioning: Neon allows you to spin up Postgres databases in seconds, eliminating the long setup times traditionally associated with database provisioning.
No server management: You don’t have to deal with the complexities of provisioning, maintaining, and administering servers. Neon handles it all, so you can focus on your application.
Autoscaling: Compute resources automatically scale up or down based on real-time demand, ensuring optimal performance without manual intervention.
Usage-based pricing: Your costs are directly tied to the resources your workload consumes—both compute and storage. There's no need to over-provision or pay for idle capacity.
Built-in availability and fault tolerance: We’ve designed our architecture for high availability and resilience, ensuring your data is safe and your applications are always accessible.
Focus on business logic: With the heavy lifting of infrastructure management handled by Neon, you can dedicate your time and effort to writing code and delivering value to your users.
To us, serverless does not mean…
That Neon only works with serverless architectures. Neon is fully compatible with the entire PostgreSQL ecosystem. Whether you're using Django, Rails, or even a bash script in your basement, if it works with Postgres, it works with Neon.

That you have to pay per query. Your charges are based on compute and storage usage, not the number of queries. For example, you could run billions of queries for as little as $19 a month if they fit within the resources allotted in the Launch plan. The CPU allowance is ample for running sites 24/7 with low CPU requirements.

That you’ll get unpredictable costs due to traffic spikes. We provide transparency in your potential costs. You always set a maximum autoscaling limit to avoid unpredictable bills, and you can always check your consumption. We send you notifications if your storage usage grows quickly.

Learn more
Autoscaling
Autosuspend
Plans and billing
Database-per-tenant use cases
Variable workload use cases
Postgres for SaaS use cases

Autoscaling
An introduction to Neon's autoscaling

Neon's Autoscaling feature dynamically adjusts the amount of compute resources allocated to a Neon compute in response to the current load, eliminating the need for manual intervention.

The following visualization shows how Neon’s autoscaling works throughout a typical day. The compute resources scale up or down based on demand, ensuring that your database has the necessary compute resources when it needs them, while conserving resources during off-peak times.

visualization for autoscaling

To dive deeper into how Neon's autoscaling algorithm operates, visit Understanding Neon’s autoscaling algorithm.

Autoscaling benefits
Neon's Autoscaling feature offers the following benefits:

On-demand scaling: Autoscaling helps with workloads that experience variations over time, such as applications with time-based changes in demand or occasional spikes.
Cost-effectiveness: Autoscaling optimizes resource utilization, ensuring that you only use required resources, rather than over-provisioning to handle peak loads.
Resource and cost control: Autoscaling operates within a user-defined range, ensuring that your compute resources and associated costs do not scale indefinitely.
No manual intervention: After you enable autoscaling and set scaling limits, no manual intervention is required, allowing you to focus on your applications.
Configuring autoscaling
You can enable autoscaling for any compute instance, whether it's a primary compute or a read replica. Simply open Edit compute settings (learn how) for your compute and set the autoscaling range. This range defines the minimum and maximum compute sizes within which your compute will automatically scale. For example, you might set the minimum to 2 vCPUs with 8 GB of RAM and the maximum to 8 vCPUs with 32 GB of RAM. Your compute resources will dynamically adjust within these limits, never dropping below the minimum or exceeding the maximum, regardless of demand. We recommend regularly monitoring your usage from the Monitoring Dashboard to determine if adjustments to this range are needed.

autoscaling configuration

For full details about enabling and configuring autoscaling, see Enabling autoscaling.

Autoscaling architecture
Learn how Neon automatically scales compute resources on demand

What you will learn:
How Neon's autoscaling architecture is structured

The role of key components like the autoscaler-agent and Kubernetes scheduler

Related topics
Introduction to autoscaling
Enabling autoscaling
How the algorithm works
A Neon project can have one or more computes, each representing an individual Postgres instance. Storage is decoupled from these computes, meaning that the Postgres servers executing queries are physically separate from the data storage location. This separation offers numerous advantages, including enablement of Neon's autoscaling feature.

High-level architecture diagram

Looking more closely, you can see that each Postgres instance operates within its own virtual machine inside a Kubernetes cluster, with multiple VMs hosted on each node of the cluster. Autoscaling is implemented by allocating and deallocating vCPU and RAM to each VM.

Autoscaling diagram

The autoscaler-agent
Each Kubernetes node hosts a single instance of the autoscaler-agent, which serves as the control mechanism for Neon's autoscaling system. The agent collects metrics from the VMs on its node, makes scaling decisions, and performs the necessary checks and requests to implement those decisions.

The Kubernetes scheduler
A Neon-modified Kubernetes scheduler coordinates with the autoscaler-agent and is the single source of truth for resource allocation. The autoscaler-agent obtains approval for all upscaling from the scheduler. The scheduler maintains a global view of all resource usage changes and approves requests for additional resources from the autoscaler-agent or standard scheduling. In this way, the scheduler assumes responsibility for preventing overcommitting of memory resources. In the rare event that a node exhausts its resources, new pods are not scheduled on the node, and the autoscaler-agent is denied permission to allocate more resources.

NeonVM
Kubernetes does not natively support the creation or management of VMs. To address this, Neon uses a tool called NeonVM. This tool is a custom resource definition and controller for VMs, handling tasks such as adding or removing CPUs and memory. Internally, NeonVM utilizes QEMU and KVM (where available) to achieve near-native performance.

When an autoscaler-agent needs to modify a VM's resource allocation, it simply updates the corresponding NeonVM object in Kubernetes, and the VM controller then manages the rest of the process.

Live migration
In cases where a Kubernetes node becomes saturated, NeonVM manages the process of live migrating a VM, transferring the VM from one machine to another with minimal interruptions (typically around 100ms). Live migration transmits the internal state of the original VM to a new one while the former continues to operate, swiftly transitioning to the new VM after most of the data is copied. From within the VM, the only indication that a migration occurred might be a temporary performance reduction. Importantly, the VM retains its IP address, ensuring that connections are preserved and queries remain uninterrupted.

The live migration process allows for the proactive reduction of node load by migrating VMs away before reaching capacity. Although it is still possible for the node to fill up in the interim, Neon's separation of storage and compute means that VMs typically use minimal disk space, resulting in fast migrations.

Memory scaling
Postgres memory consumption can escalate rapidly in specific scenarios. Fortunately, Neon's autoscaling system is able to detect memory usage increases without constantly requesting metrics from the VM. This is accomplished by running Postgres within a cgroups, which provides notifications when memory usage crosses a specified threshold. Using cgroups in this way requires running our vm-monitor in the VM alongside Postgres to request more resources from the autoscaler-agent when Postgres consumes too much memory. The vm-monitor also verifies that downscaling requests from an autoscaler-agent will leave sufficient memory leftover.

Local File Cache
To expedite queries, the autoscaling system incorporates a Postgres extension that places a cache in front of the storage layer. Many queries benefit from this additional memory, particularly those requiring multiple database scans (such as creating an index). The Local File Cache (LFC) capitalizes on the additional memory allocated to the VM by dedicating a portion to the cache to itself. The cache is backed by disk and kept at a size intended to fit in the kernel page cache. Due to the storage model, writebacks are not required, resulting in near-instant evictions. The vm-monitor adjusts the LFC size when scaling occurs through the autoscaler-agent, ensuring seamless operation.

Autoscaling source code
To further explore Neon's autoscaling implementation, visit Neon's autoscaling GitHub repository. While not primarily designed for external use, Neon welcomes exploration and contributions.

Features
/
Autoscaling
Enable Autoscaling in Neon
What you will learn:
Enable autoscaling for a compute

Configure autoscaling defaults for your project

Related topics
About autoscaling
How the algorithm works
This guide demonstrates how to enable autoscaling in your Neon project and how to visualize your usage.

Enable autoscaling for a compute
You can edit an individual compute to alter the compute configuration, which includes autoscaling.

To edit a compute:

In the Neon Console, select Branches.

Select a branch.

On the Compute tab, identify the compute you want to configure and click Edit.Edit compute menu

On the Edit compute settings drawer, toggle Enable autoscaling to enable it and use the slider to specify a minimum and maximum compute size.Autoscaling edit settings

Neon scales the compute size up and down within the specified range to meet workload demand. Autoscaling currently supports a range of 1/4 (.25) to 10 vCPUs. One vCPU has 4 GB of RAM, 2 vCPUs have 8 GB of RAM, and so on. The amount of RAM in GB is always 4 times the number of vCPUs. For an overview of available compute sizes, see Compute size and autoscaling configuration.

note
You can configure the autosuspend setting for your compute at the same time. The Suspend compute after a period of inactivity setting defines the period of inactivity after which a compute scales to zero. For more, see Autosuspend.

Click Save.

Configure autoscaling defaults for your project
You can configure autoscaling configuration defaults for your project so that newly created computes (including those created when you create a new branch or add read replica) are created with the same autoscaling configuration. This will save your from having to configure autoscaling each time, assuming you want the same settings for all of your computes.

note
Changing your autoscaling default settings does not alter the autoscaling configuration for existing computes.

To configure autoscaling defaults:

Navigate to your Project Dashboard and select Settings from the sidebar.
Select Compute.
Select Change to open the Change default compute settings modal.Edit autoscaling defaults
Use the slider to specify a minimum and maximum compute size and Save your changes.
The next time you create a compute, these settings will be applied to it.

Monitor autoscaling
From the Neon Console, you can view how your vCPU and RAM usage scales over time (last hour, day, and week). From the Branches page, open the branch you want to inspect, then open the Edit modal for its compute.

autoscaling graph example

Some key points about this Autoscaling view:

Allocation refers to the vCPU and memory size provisioned to handle current demand; autoscaling automatically adjusts this allocation, increasing or decreasing the allocated vCPU and memory size in a step-wise fashion as demand fluctuates, within your minimum and maximum limits.
Your minimum and maximum limits are shown as solid horizontal lines. This represents the allocation boundary: the size of your allocated vCPU/memory stays within this range so long as your compute remains active. It scales to zero after the defined period of inactivity.
A re-activated compute scales up immediately to your minimum allocation, ensuring adequate performance for your anticipated demand.
Place your cursor anywhere in the graph to get more usage detail about that particular point in time.

autoscaling graph detail

note
To refresh the graph, close the Edit compute settings drawer and reopen it.

See below for some rules of thumb on actions you might want to take based on trends you see in this view.

Start with a good minimum
Ideally, for smaller datasets, you want to keep as much of your dataset in memory (RAM) as possible. This improves performance by minimizing I/O operations. We recommend setting a large enough minimum limit to fit your full dataset in memory. For larger datasets and more sizing advice, see how to size your compute.

Setting your maximum
If your autoscaling graphs show regular spikes that hit your maximum setting, consider increasing your maximum. However, because these spikes plateau at the maximum setting, it can be difficult to determine your actual demand.

Another approach is to set a higher threshold than you need and monitor usage spikes to get a sense of where your typical maximum demand reaches; you can then throttle the maximum setting down closer to anticipated/historical demand. Either way, with autoscaling you only use what's necessary; a higher setting does not translate to increased usage unless there's demand for it.

The neon_utils extension
Another tool for understanding usage, the neon_utils extension provides a num_cpus() function that helps you monitor how the Autoscaling feature allocates compute resources in response to workload. For more information, see The neon_utils extension.

Understanding Neon’s autoscaling algorithm
How Neon’s algorithm scales resources to match your workload

What you will learn:
Key metrics that drive autoscaling decisions

How often the algorithm checks these metrics

Related topics
Introduction to autoscaling
Enabling autoscaling
The key concept behind autoscaling is that compute resizing happens automatically — once you set up your minimum and maximum compute sizes, there’s no action required on your part other than monitoring your usage metrics to see if adjustments are needed.

That said, it can be helpful to understand exactly when and under what circumstances the algorithm optimizes your database on two key fronts — performance and efficiency. In a nutshell, the algorithm automatically scales up your compute to ensure optimal performance and scales down to maximize efficiency.

autoscaling algorithm

How the algorithm works
Neon's autoscaling algorithm uses two components, the vm-monitor and the autoscaler-agent, to continuously monitor three key metrics: your average CPU load, your memory usage, and the activity of your Local File Cache (LFC). These metrics determine how your compute resources — the virtual machine that powers your database — should be scaled to maintain performance and efficiency.

The Formula
In essence, the algorithm is built on goals. We set a goal (an ideal compute size) for each of the three key metrics:

cpuGoalCU — Keep the 1-minute average CPU load at or below 90% of the available CPU capacity.
memGoalCU — Keep memory usage at or below 75% of the total allocated RAM.
lfcGoalCU — Fit your frequently accessed working set within 75% of the compute's RAM allocated to the LFC.
The formula can be expressed as:

goalCU := max(cpuGoalCU, memGoalCU, lfcGoalCU)
The algorithm selects the highest value from these goals as the overall goalCU, ensuring your database has enough resources to handle the most demanding metric — while staying within the minimum and maximum limits you’ve set.

The Metrics
Let's go into a bit more detail about each metric.

CPU load average
The CPU load average is a measure of how much work your CPU is handling. Every 5 seconds, the autoscaler-agent checks the 1-minute load average from the virtual machine (VM) running your database. This load average reflects the average number of processes waiting to be executed by the vCPU over the previous minute.

The goal is to keep the CPU load at or below 90% of the available vCPU capacity. If the load exceeds this threshold, the algorithm increases the compute allocated to your database to handle the additional demand.

In simpler terms, if your database is working too hard, the algorithm adds more CPU power to keep things running smoothly.

Memory Usage
Memory usage refers to the amount of RAM your database and its related processes are using. Every 5 seconds, the autoscaler-agent checks for the latest memory metrics from inside the VM, and every 100ms the vm-monitor checks memory usage from Postgres.

The algorithm aims to keep overall memory usage at or below 75% of the total allocated memory. If your database starts using more memory than this threshold, the algorithm increases compute size to allocate more memory, making sure your database has enough RAM to perform well without over-provisioning.

Local File Cache (LFC) working set size
An important part of the scaling algorithm is estimating your current working set size — a subset of your most frequently accessed data — and scaling your compute to ensure it fits within the LFC.

Every 20 seconds, the autoscaler-agent checks the working set size across a variety of time windows, ranging from 1 to 60 minutes. The goal is to fit your working set within 75% of the compute’s RAM allocated to the LFC. If your working set exceeds this threshold, the algorithm increases compute size to expand the LFC, keeping frequently accessed data in memory for faster access.

note
If your dataset is small enough, you can improve performance by keeping the entire dataset in memory. Check your database size on the Monitoring dashboard and adjust your minimum compute size accordingly. For example, a 6.4 GiB database can comfortably fit within a compute size of 2 vCPU with 8 GB of RAM (where the LFC can use up to 80% of the available RAM).

How often the metrics are polled
To give you a sense of the algorithm's responsiveness, here's a summary of how often the metrics are polled:

Every 5 seconds → the autoscaler-agent fetches load metrics from the VM, including CPU usage and overall memory usage.
Every 20 seconds → the autoscaler-agent checks the Local File Cache (LFC) metrics, including the working set size across various time windows: 1 minute, 2 minutes, up to 60 minutes.
Every 100 milliseconds → the vm-monitor checks memory usage specifically within Postgres.
This frequent polling allows the algorithm to respond swiftly to changes in workload, ensuring that your compute resources are always appropriately scaled to meet current demands.

Autosuspend
Scale computes to zero when not in use

Neon's Autosuspend feature controls when a Neon compute transitions to an Idle state (scales to zero) due to inactivity.

By default, a Neon compute scales to zero after 300 seconds (5 minutes) of inactivity. For Neon Free Plan users, this setting is fixed. Users on paid plans can increase, decrease, or disable the autosuspend setting, controlling when or if a compute scales to zero.

Reasons for adjusting the autosuspend setting might include:

Avoiding cold starts. Restarting a compute from an Idle state can take anywhere from 500 ms to a few seconds (see Compute lifecycle). You can turn off the Autosuspend feature to avoid cold starts.
Reducing the frequency of cold starts. You can configure autosuspend to occur less frequently, keeping your compute active during busier hours while ensuring that it suspends when usage drops off.
Suspending a compute more quickly to reduce compute usage. Compute startup times can be as low as 500 ms, which may be sufficient for your purposes. In this case, you can suspend computes more frequently reduce compute usage.
You can configure the autosuspend setting in an existing project by editing a compute. You can also configure it when you first create a Neon project, which sets the autosuspend default for the project. For instructions, refer to Configuring autosuspend for Neon computes.
Features
/
Autosuspend
Configuring Autosuspend for Neon computes
Learn how to configure Neon's Autosuspend feature to control when your compute scales to zero

Neon's Autosuspend feature controls when a Neon compute transitions to an Idle state (scales to zero) due to inactivity. For example, if your autosuspend setting is 5 minutes, your compute will "scale to zero" after it's been inactive for 5 minutes. Neon's paid plans allow you to configure this time period to keep your compute active for longer, suspend it more quickly, or disable autosuspension entirely, depending on your requirements.

important
If you disable autosuspension entirely or your compute is never idle long enough to be automatically suspended, you will have to manually restart your compute to pick up the latest updates to Neon's compute images. Neon typically releases compute-related updates weekly. Not all releases contain critical updates, but a weekly compute restart is recommended to ensure that you do not miss anything important. For how to restart a compute, see Restart a compute.

This guide demonstrates how to configure the autosuspend setting for a new project, for an existing project, or for an individual compute.

Autosuspend limits
The autosuspend limits differ by Neon plan. The limits for each plan are outlined below. The initial default setting for all plans is 5 minutes.

Plan	Autosuspend delay	Can be disabled?
Free Plan	5 minutes	
Launch	5 minutes to 7 days	✓
Scale	1 minute to 7 days	✓
Enterprise	0 up to 7 days	✓
Configure the autosuspend setting for a new project
Configuring the autosuspend setting for a new project sets the project's default, which is applied to all computes created from that point forward. You can adjust this autosuspend default at any time, or configure the setting for individual computes later, as necessary.

To configure the autosuspend default setting when you first create your project:

Navigate to the Neon Console.
If you are creating your very first project, click Create a project. Otherwise, click New Project.
Specify a name, a Postgres version, and a region.
Under Compute size, select Suspend compute after a period of inactivity and specify your delay period. Deselecting Suspend compute after a period of inactivity disables autosuspend, meaning the compute is always active.
note
You can configure default Compute size settings at the same time.

Click Save.
Click Create Project. Your initial compute is created with the specified setting.
Configure the autosuspend setting for an existing project
Configuring the autosuspend setting for an existing project sets the project's default, which is applied to all computes created from that point forward. Existing computes are unaffected. You can adjust the autosuspend default or configure the setting for individual computes later, as necessary.

To configure the autosuspend default for an existing project:

Select a project in the Neon Console.
On the Neon Dashboard, select Project settings.
Select Compute and click Change.
Select Suspend compute after a period of inactivity and specify your delay period. Deselecting Suspend compute after a period of inactivity disables autosuspend, meaning the compute is always active.
note
You can configure default Compute size settings at the same time.

Click Save.
Configure autosuspend for a compute
To configure the autosuspend setting for an individual compute:

In the Neon Console, select Branches.
Select a branch.
Click the menu in the Computes table, and select Edit.Edit compute menu
Under Compute size, select Suspend compute after a period of inactivity and specify your delay period. The maximum setting is 7 days. Deselecting Suspend compute after a period of inactivity means the compute is always active.
note
You can configure Compute size settings for your compute at the same time.

Click Save.
Monitor autosuspend
You can monitor autosuspend on the Branches page in the Neon Console. A compute reports either an Active or Idle status.

Compute status

You can also view compute state transitions in the Branches widget on the Neon Dashboard.

User actions that activate an idle compute include connecting from a client such as psql, running a query on your database from the Neon SQL Editor, or accessing the compute via the Neon API.

info
The Neon API includes Start endpoint and Suspend endpoint APIs for the specific purpose of activating and suspending a compute.

You can try any of these methods and watch the status of your compute as it transitions from an Idle to an Active state.

Get started with branching
Everything you need to get started with Neon's branching feature

Find detailed information and instructions about Neon's branching feature and how you can integrate branching with your development workflows.

What is branching?
Learn about branching and how you can apply it in your development workflows.

Learn about branching
Learn about Neon's branching feature and how to use it in your development workflows

Database branching for Postgres
Blog: Read about how Neon's branching feature works and what it means for your workflows

Automate branching
Integrate branching into your CI/CD pipelines and workflows with the Neon API, CLI, GitHub Actions, and Githooks.

Branching with the Neon API
Learn how to instantly create and manage branches with the Neon API

Branching with the Neon CLI
Learn how to instantly create and manage branches with the Neon CLI

Branching with GitHub Actions
Automate branching with Neon's GitHub Actions for branching

Branching with Githooks
Blog: Learn how to automating branch creation with Githooks

Preview deployments
Create a branch for each preview deployment with the Neon Vercel Integration.

The Neon Vercel Integration
Connect your Vercel project and create a branch for each preview deployment

Preview deployments with Vercel
Blog: Read about full-stack preview deployments using the Neon Vercel Integration

A database for every preview
Blog: A database for every preview environment with GitHub Actions and Vercel

Test queries
Test potentially destructive or performance-impacting queries before your run them in production.

Branching — Testing queries
Instantly create a branch to test queries before running them in production

Data recovery and audits
Recover lost data or track down issues by restoring a branch to its history, or just create a point-in-time branch for historical analysis or any other reason.

Branch Restore with Time Travel Assist
Learn how to revert changes or recover lost data using Neon Branch Restore with Time Travel Assist

Time Travel
Query point-in-time connections with Time Travel

Schema diff
Visualize schema differences between branches to help with troubleshooting

Branching guides
Learn how to promote a branch to become your default branch.

Promote a branch
Promote a branch to the default branch of your Neon project using the Neon API

Example applications
Explore example applications that use Neon's branching feature.

Time Travel Demo
Use Neon branching, the Neon API, and a bisect script to recover lost data

Neon Twitter app
Use GitHub Actions to create and delete a branch with each pull request

Preview branches app
An application demonstrating using GitHub Actions with preview deployments in Vercel

Neon Discord Bot
Learn how to build a Discord bot while leveraging Neon branching

Features
/
Branching
Branching
Branch your data the same way you branch your code

With Neon, you can quickly and cost-effectively branch your data for development, testing, and various other purposes, enabling you to improve developer productivity and optimize continuous integration and delivery (CI/CD) pipelines.

What is a branch?
A branch is a copy-on-write clone of your data. You can create a branch from a current or past state. For example, you can create a branch that includes all data up to the current time or an earlier time.

A branch is isolated from its originating data, so you are free to play around with it, modify it, or delete it when it's no longer needed. Changes to a branch are independent. A branch and its parent can share the same history (within the defined point-in-time restore window) but diverge at the point of branch creation. Writes to a branch are saved as a delta.

Creating a branch does not increase load on the parent branch or affect it in any way, which means you can create a branch without impacting the performance of your production system.

Each Neon project is created with a root branch called main. The first branch that you create is branched from the project's root branch. Subsequent branches can be branched from the root branch or from a previously created branch.

Branching workflows
You can use Neon's branching feature in variety workflows.

Development
You can create a branch of your production database that developers are free to play with and modify. By default, branches are created with all of the data that existed in the parent branch, eliminating the setup time required to deploy and maintain a development database.

development environment branch

The following video shows how to create a branch in the Neon Console. For step-by-step instructions, see Create a branch.

You can integrate branching into your development workflows and toolchains using the Neon CLI, API, or GitHub Actions. If you use Vercel, you can use the Neon Vercel Integration to create a branch for each preview deployment.

Refer to the following guides for instructions:

Branching with the Neon API
Learn how to instantly create and manage branches with the Neon API

Branching with the Neon CLI
Learn how to instantly create and manage branches with the Neon CLI

Branching with GitHub Actions
Automate branching with Neon's GitHub Actions for branching

The Neon Vercel Integration
Connect your Vercel project and create a branch for each preview deployment

Testing
Testers can create branches for testing schema changes, validating new queries, or testing potentially destructive queries before deploying them to production. A branch is isolated from its parent branch but has all of the parent branch's data up to the point of branch creation, which eliminates the effort involved in hydrating a database. Tests can also run on separate branches in parallel, with each branch having dedicated compute resources.

test environment branches

Refer to the following guide for instructions.

Branching — Testing queries
Instantly create a branch to test queries before running them in production

Data recovery
If you lose data due to an unintended deletion or some other event, you can restore a branch to any point in its history retention period to recover lost data. You can also create a new point-in-time branch for historical analysis or any other reason.

data recovery branch

Refer to the following guides for instructions.

Branch Restore with Time Travel
Restore a branch to its history with Branch Restore

Create a branch from the past
Learn how to create a branch from historical data

Branch reset and restore
Learn about the different branch reset and restore features in Neon

Neon retains a history of changes for all branches. This shared history provides the basis for a variety of branch restore and reset operations: resetting a branch to its parent, restoring a branch to its history, creating a new branch from a selected point-in-time, and Time Travel queries against the shared history. You can use these features to reset a development branch to main, to recover lost data, as a database backup strategy, or to view the past state of your database.

History retention
The history retention limit is 24 hours for Neon Free Plan users, 7 days for Launch plan users, and 30 days for Scale plan users.

You can configure the History retention setting in the Neon Console, under Project settings > Storage. For further instructions, see Configure history retention.History retention configuration

Increasing the history retention period affects all branches in your Neon project and increases project storage. You can scale History retention down to zero if reducing storage cost is more important than the ability to restore your data to a past state.

History is retained in the form of Write-Ahead-Log (WAL) records. As WAL records age out of the retention period, they are evicted from storage and no longer count toward project storage.

Branch reset and restore features
Find out more about the different branch reset and restore features that Neon provides.

Branch Restore with Time Travel
Learn how to restore a branch to its history with Time Travel assist

Reset a branch from its parent
Learn how to restore a branch to its history with Time Travel assist

Create a point-in-time branch
Create a new point-in-time branch from timestamp or LSN

Features
/
Branching
/
Branch reset and restore
Reset from parent
Learn how to reset a branch from its parent

Neon's Reset from parent feature lets you instantly reset all databases on a branch to the latest schema and data from its parent branch, helping you recover from issues, start on new feature development, or keep the different branches in your environment in sync.

Example scenario
When working with database branches, you might find yourself in a situation where you need to update your working branch to the latest data from your main branch.

For example, let's say you have two child branches staging and development forked from your main branch. You have been working on the development branch and find it is now too far out of date with main.

You have no schema changes in development to consider or preserve; you just want a quick refresh of the data. With the Reset from parent feature, you can perform a clean, instant reset to the latest data from the parent in a single operation, saving you the complication of manually creating and restoring branches.

How Reset from parent works
When you reset a branch to its parent, the data and schema is completely replaced with the latest data and schema from its parent.

Key points
You can only reset a branch to the latest data from its parent. Point-in-time resets based on timestamp or LSN are possible using Branch Restore, a similar feature, with some differences: branch restore leaves a backup branch and is in general is intended more for data recovery than development workflow.
This reset is a complete overwrite, not a refresh or a merge. Any local changes made to the child branch are lost during this reset.
Existing connections will be temporarily interrupted during the reset. However, your connection details do not change. All connections are re-established as soon as the reset is done.
How to Reset from parent
You can reset any branch to its parent using any of our tools.

Console
CLI
API
On the Branches page in the Neon Console, select the branch that you want to reset.

The console opens to the details page for your branch, giving you key information about the branch and its child status: its parent, the last time it was reset, and other relevent detail.

To reset the branch, select Reset from parent from either the More dropdown or the Last Data Reset panel.

Reset from parent

note
If this branch has children of its own, resetting is blocked. The resulting error dialog lets you delete these child branches, after which you can continue with the reset.

Integrating branch resets in CI/CD workflows
You can include resetting database branches as part of your CI/CD workflow. For example, when starting a new feature or refreshing staging.

For New features
Initiate feature development by resetting your development branch to align with staging or production, ensuring a fresh starting point. Use the command:

neon branches reset --name dev-branch --parent staging
This strategy preserves a stable connection string for your development environment, while still giving your team a clean slate for each new feature.

Refresh staging
Keep staging in sync with production to minimize discrepancies. Automate staging updates with:

neon branches reset --name staging --parent main
This ensures staging accurately reflects the current production state for reliable testing.
Features
/
Branching
/
Branch reset and restore
Branch Restore
Learn how to revert changes or recover lost data using Neon Branch Restore with Time Travel Assist

With Neon's branch restore capability, you can easily restore a branch to an earlier state in its own or another branch's history. You can use Time Travel Assist to connect to a specific point in your history retention window, where you can run read-only queries to pinpoint the exact moment you need to restore to. You can also use Schema Diff to get a side-by-side, Github-style visual comparison of your selected branches before restoring.

How branch restore works
Restore from history
The restore operation lets you revert the state of a selected branch to an earlier point in time in its own or another branch's history, using time and date or Log Sequence Number (LSN). For example, you can revert to a state just before a data loss occurred.

branch restore to timestamp

The default history retention for a Neon project differs by plan. You can revert a branch to any time within your configured retention window, down to the millisecond.

A few key points to keep in mind about the restore operation:

Restore backups are created automatically in case you make a mistake
Current data is overwritten
All databases on a branch are restored
Connections to the selected branch are temporarily interrupted
Automatic backups
In case you need to rollback a restore, Neon preserves the branch's final state before the restore operation in an automatically created backup branch, which takes the following format:

{branch_name}_old_{head_timestamp}
You can use this backup to rollback the restore operation if necessary. The backup branches are listed on the Branches page in the Neon Console among your other branches.

Can you delete a backup branch?
Unfortunately, not at this time. A backup branch is the parent of a restored branch, and you cannot delete a parent branch without first removing its child branches. Support for deleting backup branches is expected in a future release.

In the meantime, if you're certain you no longer need a backup branch, you can free up its storage space by connecting to the branch and dropping its databases or tables. Be sure to connect to the correct branch when doing this. You can connect to a backup branch like any other branch via the Neon SQL Editor or an SQL client like psql.

If backup branches clutter your Branches page, consider renaming them. For example, you can prefix their names with a z to move them to the bottom of the list. See Rename a branch for details.

This backup becomes the parent of your original branch, which makes rolling back the restore operation simple: Reset from parent.

Backup branch as parent to original

Overwrite, not a merge
It is important to understand that whenever you restore a branch, you are performing a complete overwrite, not a merge or refresh. Everything on your current branch, data and schema, is replaced with the contents from the historical source. All data changes from the selected restore point onwards are excluded from the branch.

Changes apply to all databases
A reminder that in Neon's object hierarchy, a branch can include any number of databases. Keep this in mind when restoring branches. For example, let's say you want to restore lost data in a given database. If you restore your branch to an earlier point in time before the data loss occurred, the operation applies to all databases on the branch, not just the one you are troubleshooting. You can expect the restore operation to last a few seconds.

In general, Neon recommends that you avoid creating too many databases in a single Neon project. If you have multiple, distinct applications, each one deserves its own Neon project. A good rule of thumb: use one Neon project per source code repository.

Connections temporarily interrupted
Existing connections to the selected branch are temporarily interrupted during the restore operation. However, your connection details do not change. Applications can automatically re-establish their database connections as soon as the restore operation is finished.

Technical details
Neon is open source and built in public, so if you are interested in understanding the technical implementation of a branch restore operation, see the details below.

View technical details
Time Travel Assist
Use Time Travel Assist to make sure you've targetted the correct restore point before you restore your branch.

See Time Travel Assist to learn more.

How to use branch restore
You can use the Neon Console, CLI, or API to restore branches.

Console
CLI
API
Restoring from history
Use the Restore page to restore a branch to an earlier timestamp in its history.

First, select the Branch to restore. This is the target branch for the restore operation.

branch restore to timestamp

To restore a branch from its own history:
Make sure the From history tab is selected.

Choose your timestamp or switch to LSN.

Click Next.

A confirmation window opens giving you details about the pending restore operation. Review these details to make sure you've made the correct selections.

Click Restore to complete the operation.

To restore from another branch:
Switch to the From another branch tab.

Select the source branch that that you want to restore data from.

By default, the operation pulls the latest data from the source branch. If you want to pull from an earlier point in time, disable Restore from latest data (head).

The timestamp selector will appear.

Choose your timestamp or switch to the LSN input.

Click Next, confirm the details of the operation, then click Restore to complete.

All databases on the selected branch are instantly updated with the data and schema from the chosen point in time. From the Branches page, you can now see a backup branch was created with the state of the branch at the restore point in time.

branch restore backup branch

To make sure you choose the right restore point, we encourage you to use Time Travel Assist before running a restore job, but the backup branch is there if you need it. If you do need to revert your changes, you can Reset from parent since that is your branch's relationship to the restore point backup.

Billing considerations
There are minimal impacts to billing from the branch restore and Time Travel Assist features:

Branch Restore — The backups created when you restore a branch do add to your total number of branches, but since they do not have a compute attached they do not add to consumption costs.
Time Travel Assist — Costs related to Time Travel queries are minimal. See Billing considerations.
Limitations
You cannot delete a backup branch without first removing the child branch. See the note above.

Once you restore a branch, Reset from parent restores from the restore backup branch, not the original parent.

For example, let's say you have a main branch with a child development branch dev/alex. You are working on dev/alex and decide to restore to an earlier point in time to fix something during development. At this point, dev/alex's parent switches from main to the backup dev/alex_old_timestamp. A day later, you want to refresh dev/alex with the latest data from main. You can't use Reset from parent, since the backup is now the parent. Instead, use Branch Restore and select the original parent main as the source.

Features
/
Branching
Branching with the Neon CLI
Learn how to create and delete branches with the Neon CLI

The examples in this guide demonstrate creating, viewing, and deleting branches using the Neon CLI. For other branch-related CLI commands, refer to Neon CLI commands — branches. This guide also describes how to use the --api-key option to authenticate CLI branching commands from the command line.

The examples show the default table output format. The Neon CLI also supports json and yaml output formats. For example, if you prefer output in json, add --output json to your Neon CLI command.

Prerequisites
The Neon CLI. See Install the Neon CLI for instructions.
To run CLI commands, you must either authenticate through your browser or supply an API key using the --api-key option. See Connect with the Neon CLI.
Create a branch with the CLI
The following Neon CLI command creates a branch. If your Neon account has more than one project, you will be required to specify a project ID using the --project-id option. To view the CLI documentation for this command, refer to the Neon CLI reference. The command response includes the branch ID, the compute ID, and and the connection URI for connecting to the branch.

tip
You can use the --name option with a neon branches create command to specify your own branch name instead of using the name generated by Neon. For example: neon branches create --name mybranch. Also, for any Neon CLI command, you can specify --output json to change the command output from the default table format to JSON format.

neon branches create
branch
┌───────────────────────┬───────────────────────┬─────────┬──────────────────────┬──────────────────────┐
│ Id                    │ Name                  │ Primary │ Created At           │ Updated At           │
├───────────────────────┼───────────────────────┼─────────┼──────────────────────┼──────────────────────┤
│ br-lucky-mud-08878834 │ br-lucky-mud-08878834 │ false   │ 2023-07-24T20:22:42Z │ 2023-07-24T20:22:42Z │
└───────────────────────┴───────────────────────┴─────────┴──────────────────────┴──────────────────────┘
endpoints
┌────────────────────────┬──────────────────────┐
│ Id                     │ Created At           │
├────────────────────────┼──────────────────────┤
│ ep-mute-voice-52609794 │ 2023-07-24T20:22:42Z │
└────────────────────────┴──────────────────────┘
connection_uris
┌───────────────────────────────────────────────────────────────────────────────────────┐
│ Connection Uri                                                                        │
├───────────────────────────────────────────────────────────────────────────────────────┤
│ postgresql://[user]:[password]@[neon_hostname]/[dbname]                               │
└───────────────────────────────────────────────────────────────────────────────────────┘
tip
The Neon CLI provides a neon connection-string command you can use to extract a connection uri programmatically. See Neon CLI commands — connection-string.

Create a branch from a non-default parent
Using the option --parent, you can specify any non-default branch that you want to use as the parent for your new branch, depending on the needs of your development workflow.

In this example, we're creating a branch for a hotfix called alex/hotfix using the long-lived development branch dev/alex as the parent:

neon branches create --name alex/hotfix --parent dev/alex --project-id crimson-voice-12345678
branch
┌───────────────────────┬─────────────┬─────────┬──────────────────────┬──────────────────────┐
│ Id                    │ Name        │ Primary │ Created At           │ Updated At           │
├───────────────────────┼─────────────┼─────────┼──────────────────────┼──────────────────────┤
│ br-misty-mud-a5poo34s │ alex/hotfix │ false   │ 2024-04-23T17:04:10Z │ 2024-04-23T17:04:10Z │
└───────────────────────┴─────────────┴─────────┴──────────────────────┴──────────────────────┘
endpoints
┌──────────────────────────┬──────────────────────┐
│ Id                       │ Created At           │
├──────────────────────────┼──────────────────────┤
│ ep-orange-heart-123456 │ 2024-04-23T17:04:10Z │
└──────────────────────────┴──────────────────────┘
connection_uris
┌──────────────────────────────────────────────────────────────────────────────────────────────────────────────┐
│ Connection Uri                                                                                               │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ postgresql://neondb_owner:123456@ep-orange-heart-a54grm9j.us-east-2.aws.neon.tech/neondb?sslmode=require     │
└──────────────────────────────────────────────────────────────────────────────────────────────────────────────┘
List branches with the CLI
The following Neon CLI command lists all branches in your Neon project, as well as any branches shared with you. If your Neon account has more than one project, you will be required to specify a project ID using the --project-id option. To view the CLI documentation for this method, refer to the Neon CLI reference.

neon projects list
Projects
┌────────────────────────┬────────────────────┬───────────────┬──────────────────────┐
│ Id                     │ Name               │ Region Id     │ Created At           │
├────────────────────────┼────────────────────┼───────────────┼──────────────────────┤
│ crimson-voice-12345678 │ frontend           │ aws-us-east-2 │ 2024-04-15T11:17:30Z │
├────────────────────────┼────────────────────┼───────────────┼──────────────────────┤
│ calm-thunder-12121212  │ backend            │ aws-us-east-2 │ 2024-04-10T15:21:01Z │
├────────────────────────┼────────────────────┼───────────────┼──────────────────────┤
│ nameless-hall-87654321 │ billing            │ aws-us-east-2 │ 2024-04-10T14:35:17Z │
└────────────────────────┴────────────────────┴───────────────┴──────────────────────┘
Shared with me
┌───────────────────┬────────────────────┬──────────────────┬──────────────────────┐
│ Id                │ Name               │ Region Id        │ Created At           │
├───────────────────┼────────────────────┼──────────────────┼──────────────────────┤
│ noisy-fire-212121 │ API                │ aws-eu-central-1 │ 2023-04-22T18:41:13Z │
└───────────────────┴────────────────────┴──────────────────┴──────────────────────┘
Delete a branch with the CLI
The following Neon CLI command deletes the specified branch. If your Neon account has more than one project, you will be required to specify a project ID using the --project-id option. To view the CLI documentation for this command, refer to the Neon CLI reference. You can delete a branch by its ID or name.

neon branches delete br-rough-sky-158193
┌───────────────────────┬───────────────────────┬─────────┬──────────────────────┬──────────────────────┐
│ Id                    │ Name                  │ Primary │ Created At           │ Updated At           │
├───────────────────────┼───────────────────────┼─────────┼──────────────────────┼──────────────────────┤
│ br-lucky-mud-08878834 │ br-lucky-mud-08878834 │ false   │ 2023-07-24T20:22:42Z │ 2023-07-24T20:44:51Z │
└───────────────────────┴───────────────────────┴─────────┴──────────────────────┴──────────────────────┘
Branching automation with the Neon CLI
The Neon CLI enables easy automation of branching operations for integration into your workflows or toolchains. To facilitate authentication to Neon when running a CLI command, the Neon CLI allows you to use an API key. For information about obtaining an API key, see Create an API key.

To use an API key, you can store it in an environment variable on your system. This prevents the key from being hardcoded into your automation scripts or exposed in another way. For example, you can add the following line to your shell's profile file (.bashrc or .bash_profile for bash shell):

export NEON_API_KEY=<neon_api_key>
After exporting your key, source the profile file (source ~/.bashrc or source ~/.bash_profile), or start a new terminal session.

You do not need to specify the variable name explicitly when using a Neon CLI command. A Neon CLI command looks for a NEON_API_KEY variable setting by default.

This API key configuration ensures that the API key is kept secure while still providing a way to authenticate your CLI commands. Remember, you should handle your API key with the same level of security as your other credentials.

Resetting a branch from its parent
Depending on your development workflow, you might need to periodically reset a branch to match the latest state of its parent. This is useful, for example, when resetting a long-lived development branch back to the main branch before starting work on a new feature.

Use the following command to reset a branch to the current state (HEAD) of its parent branch:

neon branches reset <id|name> --parent
Example:

This example resets a developer's branch to match the latest state of its parent branch:

neon branches reset dev/alex --parent
┌────────────────────────────┬──────────┬─────────┬──────────────────────┬──────────────────────┐
│ Id                         │ Name     │ Primary │ Created At           │ Last Reset At        │
├────────────────────────────┼──────────┼─────────┼──────────────────────┼──────────────────────┤
│ br-twilight-smoke-123456   │ dev/alex │ false   │ 2024-04-23T17:01:49Z │ 2024-04-23T17:57:35Z │
If the branch you want to reset has child branches, you need to include the preserve-under-name parameter. This will save the current state of your branch under a new name before performing the reset. The child branches will then show this newly named branch as their parent. This step ensures that your original branch can be reset cleanly, as all child branches will have been transferred to the new parent name.

For example, here we are resetting dev/alex to its parent while preserving its latest state under the branch name dev/alex_backup:

neon branches reset dev/alex --parent --preserve-under-name dev/alex_backup
┌────────────────────────────┬──────────┬─────────┬──────────────────────┬──────────────────────┐
│ Id                         │ Name     │ Primary │ Created At           │ Last Reset At        │
├────────────────────────────┼──────────┼─────────┼──────────────────────┼──────────────────────┤
│ br-twilight-smoke-a5ofkxry │ dev/alex │ false   │ 2024-04-23T17:01:49Z │ 2024-04-23T18:02:36Z │
For more details, see Reset from parent.

Restoring a branch to its own or another branch's history
Using the CLI, you can restore a branch to an earlier point in its history or another branch's history using the following command:

neon branches restore <target id|name> <source id|name @ timestamp|lsn>
This command restores the branch main to an earlier timestamp in it's own history, saving to a backup branch called main_restore_backup_2024-02-20

neon branches restore main ^self@2024-05-06T10:00:00.000Z --preserve-under-name main_restore_backup_2024-05-06
Results of the operation:

INFO: Restoring branch br-purple-dust-a5hok5mk to the branch br-purple-dust-a5hok5mk timestamp 2024-05-06T10:00:00.000Z
Restored branch
┌─────────────────────────┬──────┬──────────────────────┐
│ Id                      │ Name │ Last Reset At        │
├─────────────────────────┼──────┼──────────────────────┤
│ br-purple-dust-a5hok5mk │ main │ 2024-05-07T09:45:21Z │
└─────────────────────────┴──────┴──────────────────────┘
Backup branch
┌─────────────────────────┬────────────────────────────────┐
│ Id                      │ Name                           │
├─────────────────────────┼────────────────────────────────┤
│ br-flat-forest-a5z016gm │ main_restore_backup_2024-05-06 │
└─────────────────────────┴────────────────────────────────┘
For full details about the different restore options available with this command, see Restoring using the CLI.
Features
/
Branching
Branching with the Neon API
Learn how to create and delete branches with the Neon API

The examples in this guide demonstrate creating, viewing, and deleting branches using the Neon API. For other branch-related API methods, refer to the Neon API reference.

note
The API examples that follow may only show some of the user-configurable request body attributes that are available to you. To view all attributes for a particular method, refer to the method's request body schema in the Neon API reference.

The jq program specified in each example is an optional third-party tool that formats the JSON response, making it easier to read. For information about this utility, see jq.

Prerequisites
A Neon API request requires an API key. For information about obtaining an API key, see Create an API key. In the examples below, $NEON_API_KEY is specified in place of an actual API key, which you must provide when making a Neon API request.

Create a branch with the API
The following Neon API method creates a branch. To view the API documentation for this method, refer to the Neon API reference.

POST /projects/{project_id}/branches
The API method appears as follows when specified in a cURL command:

note
This method does not require a request body. Without a request body, the method creates a branch from the project's default branch, and a compute is not created.

curl 'https://console.neon.tech/api/v2/projects/<project_id>/branches' \
  -H 'Accept: application/json' \
  -H "Authorization: Bearer $NEON_API_KEY" \
  -H 'Content-Type: application/json' \
  -d '{
  "endpoints": [
    {
      "type": "read_write"
    }
  ],
  "branch": {
    "parent_id": "br-wispy-dew-591433"
  }
}' | jq
The project_id for a Neon project is found on the Project settings page in the Neon Console, or you can find it by listing the projects for your Neon account using the Neon API. It is a generated value that looks something like this: autumn-disk-484331.
The endpoints attribute creates a compute, which is required to connect to the branch. Neon supports read_write and read_only compute types. A branch can be created with or without a compute. You can specify read_only to create a read replica.
The branch attribute specifies the parent branch.
The parent_id can be obtained by listing the branches for your project. See List branches. The parent_id is the id of the branch you are branching from. A branch id has a br- prefix. You can branch from your Neon project's default branch or a non-default branch.
The response includes information about the branch, the branch's compute, and the create_branch and start_compute operations that were initiated.

{
  "branch": {
    "id": "br-dawn-scene-747675",
    "project_id": "autumn-disk-484331",
    "parent_id": "br-wispy-dew-591433",
    "parent_lsn": "0/1AA6408",
    "name": "br-dawn-scene-747675",
    "current_state": "init",
    "pending_state": "ready",
    "created_at": "2022-12-08T19:55:43Z",
    "updated_at": "2022-12-08T19:55:43Z"
  },
  "endpoints": [
    {
      "host": "ep-small-bush-675287.us-east-2.aws.neon.tech",
      "id": "ep-small-bush-675287",
      "project_id": "autumn-disk-484331",
      "branch_id": "br-dawn-scene-747675",
      "autoscaling_limit_min_cu": 1,
      "autoscaling_limit_max_cu": 1,
      "region_id": "aws-us-east-2",
      "type": "read_write",
      "current_state": "init",
      "pending_state": "active",
      "settings": {
        "pg_settings": {}
      },
      "pooler_enabled": false,
      "pooler_mode": "transaction",
      "disabled": false,
      "passwordless_access": true,
      "created_at": "2022-12-08T19:55:43Z",
      "updated_at": "2022-12-08T19:55:43Z",
      "proxy_host": "us-east-2.aws.neon.tech"
    }
  ],
  "operations": [
    {
      "id": "22acbb37-209b-4b90-a39c-8460090e1329",
      "project_id": "autumn-disk-484331",
      "branch_id": "br-dawn-scene-747675",
      "action": "create_branch",
      "status": "running",
      "failures_count": 0,
      "created_at": "2022-12-08T19:55:43Z",
      "updated_at": "2022-12-08T19:55:43Z"
    },
    {
      "id": "055b17e6-ffe3-47ab-b545-cfd7db6fd8b8",
      "project_id": "autumn-disk-484331",
      "branch_id": "br-dawn-scene-747675",
      "endpoint_id": "ep-small-bush-675287",
      "action": "start_compute",
      "status": "scheduling",
      "failures_count": 0,
      "created_at": "2022-12-08T19:55:43Z",
      "updated_at": "2022-12-08T19:55:43Z"
    }
  ]
}
List branches with the API
The following Neon API method lists branches for the specified project. To view the API documentation for this method, refer to the Neon API reference.

GET /projects/{project_id}/branches
The API method appears as follows when specified in a cURL command:

curl 'https://console.neon.tech/api/v2/projects/autumn-disk-484331/branches' \
  -H 'accept: application/json' \
  -H "Authorization: Bearer $NEON_API_KEY" | jq
The project_id for a Neon project is found on the Project settings page in the Neon Console, or you can find it by listing the projects for your Neon account using the Neon API.

The response lists the project's default branch and any child branches. The name of the default branch in this example is main.

Response:

{
  "branches": [
    {
      "id": "br-dawn-scene-747675",
      "project_id": "autumn-disk-484331",
      "parent_id": "br-wispy-dew-591433",
      "parent_lsn": "0/1AA6408",
      "name": "br-dawn-scene-747675",
      "current_state": "ready",
      "logical_size": 28,
      "created_at": "2022-12-08T19:55:43Z",
      "updated_at": "2022-12-08T19:55:43Z"
    },
    {
      "id": "br-wispy-dew-591433",
      "project_id": "autumn-disk-484331",
      "name": "main",
      "current_state": "ready",
      "logical_size": 28,
      "physical_size": 31,
      "created_at": "2022-12-07T00:45:05Z",
      "updated_at": "2022-12-07T00:45:05Z"
    }
  ]
}
Delete a branch with the API
The following Neon API method deletes the specified branch. To view the API documentation for this method, refer to the Neon API reference.

DELETE /projects/{project_id}/branches/{branch_id}
The API method appears as follows when specified in a cURL command:

curl -X 'DELETE' \
  'https://console.neon.tech/api/v2/projects/autumn-disk-484331/branches/br-dawn-scene-747675' \
  -H 'accept: application/json' \
  -H "Authorization: Bearer $NEON_API_KEY" | jq
The project_id for a Neon project is found on the Project settings page in the Neon Console, or you can find it by listing the projects for your Neon account using the Neon API.
The branch_id can be found by listing the branches for your project. The <branch_id> is the id of a branch. A branch id has a br- prefix. See List branches.
The response shows information about the branch being deleted and the suspend_compute and delete_timeline operations that were initiated.

{
  "branch": {
    "id": "br-dawn-scene-747675",
    "project_id": "autumn-disk-484331",
    "parent_id": "br-shy-meadow-151383",
    "parent_lsn": "0/1953508",
    "name": "br-flat-darkness-194551",
    "current_state": "ready",
    "created_at": "2022-12-08T20:01:31Z",
    "updated_at": "2022-12-08T20:01:31Z"
  },
  "operations": [
    {
      "id": "c7ee9bea-c984-41ac-8672-9848714104bc",
      "project_id": "autumn-disk-484331",
      "branch_id": "br-dawn-scene-747675",
      "endpoint_id": "ep-small-bush-675287",
      "action": "suspend_compute",
      "status": "running",
      "failures_count": 0,
      "created_at": "2022-12-08T20:01:31Z",
      "updated_at": "2022-12-08T20:01:31Z"
    },
    {
      "id": "41646f65-c692-4621-9538-32265f74ffe5",
      "project_id": "autumn-disk-484331",
      "branch_id": "br-dawn-scene-747675",
      "action": "delete_timeline",
      "status": "scheduling",
      "failures_count": 0,
      "created_at": "2022-12-06T01:12:10Z",
      "updated_at": "2022-12-06T01:12:10Z"
    }
  ]
}
You can verify that a branch is deleted by listing the branches for your project. See List branches. The deleted branch should no longer be listed.

Restoring a branch using the API
To revert changes or recover lost data, you can use the branch restore endpoint in the Neon API.

POST /projects/{project_id}/branches/{branch_id_to_restore}/restore
For details on how to use this endpoint to restore a branch to its own or another branch's history, restore a branch to the head of its parent, and other restore options, see Branch Restore using the API.
Features
/
Branching
Automate branching with GitHub Actions
Create and delete branches with GitHub Actions

Neon provides the following GitHub Actions for working with Neon branches, which you can add to your CI workflows:

Create branch action
Delete branch action
Reset from parent action
tip
Neon supports a GitHub integration that connects your Neon project to a GitHub repository. The integration automatically configures a NEON_API_KEY secret and PROJECT_ID variable in your GitHub repository and provides a sample GitHub Actions workflow that utilizes Neon's Create branch and Delete branch actions. See Neon GitHub integration for more.

Create branch action
This GitHub Action creates a new branch in your Neon project.

info
The source code for this action is available on GitHub.

Prerequisites
Using the action requires a Neon API key. For information about obtaining an API key, see Create an API key.
Add your Neon API key to your GitHub Secrets:
In your GitHub repository, go to Project settings and locate Secrets at the bottom of the left sidebar.
Click Actions > New Repository Secret.
Name the secret NEON_API_KEY and paste your API key in the Secret field
Click Add Secret.
Example
The following example creates a branch based on the specified parent branch:

name: Create Neon Branch with GitHub Actions Demo
run-name: Create a Neon Branch 🚀
jobs:
  Create-Neon-Branch:
  steps:
    - uses: neondatabase/create-branch-action@v5
      with:
        project_id: rapid-haze-373089
        # optional (defaults to your project's default branch)
        parent: dev
        # optional (defaults to neondb)
        database: my-database
        branch_name: from_action_reusable
        username: db_user_for_url
        api_key: ${{ secrets.NEON_API_KEY }}
        id: create-branch
    - run: echo db_url ${{ steps.create-branch.outputs.db_url }}
    - run: echo host ${{ steps.create-branch.outputs.host }}
    - run: echo branch_id ${{ steps.create-branch.outputs.branch_id }}
Input variables
inputs:
  project_id:
    required: true
    description: 'The project id'
  branch_name:
    required: false
    description: 'The branch name'
  api_key:
    description: 'The Neon API key'
    required: true
  username:
    description: 'The db role name'
    required: true
  database:
    description: 'The database name'
    default: neondb
  prisma:
    description: 'Use prisma or not'
    default: 'false'
  parent:
    description: 'The parent branch name or id or LSN or timestamp. By default the primary branch is used'
  suspend_timeout:
    description: >
      Duration of inactivity in seconds after which the compute endpoint is
      For more information, see [Auto-suspend configuration](https://neon.tech/docs/manage/endpoints#auto-suspend-configuration).
    default: '0'
  ssl:
    description: >
      Add sslmode to the connection string. Supported values are: "require", "verify-ca", "verify-full", "omit".
    default: 'require'
Outputs
outputs:
  db_url:
    description: 'New branch DATABASE_URL'
    value: ${{ steps.create-branch.outputs.db_url }}
  db_url_with_pooler:
    description: 'New branch DATABASE_URL with pooling enabled'
    value: ${{ steps.create-branch.outputs.db_url_with_pooler }}
  host:
    description: 'New branch host'
    value: ${{ steps.create-branch.outputs.host }}
  host_with_pooler:
    description: 'New branch host with pooling enabled'
    value: ${{ steps.create-branch.outputs.host_with_pooler }}
  branch_id:
    description: 'New branch id'
    value: ${{ steps.create-branch.outputs.branch_id }}
  password:
    description: 'Password for connecting to the new branch database with the input username'
    value: ${{ steps.create-branch.outputs.password }}
Delete branch action
This GitHub Action deletes a branch from your Neon project.

info
The source code for this action is available on GitHub.

Prerequisites
Using the action requires a Neon API key. For information about obtaining an API key, see Create an API key.
Add your Neon API key to your GitHub Secrets:
In your GitHub repository, go to Project settings and locate Secrets at the bottom of the left sidebar.
Click Actions > New Repository Secret.
Name the secret NEON_API_KEY and paste your API key in the Secret field
Click Add Secret.
Example
The following example deletes a branch with the br-long-forest-224191 branch ID from a Neon project with the project ID rapid-haze-373089 when a pull request is merged.

name: Delete Neon Branch with GitHub Actions Demo
run-name: Delete a Neon Branch 🚀
on: [push]
jobs:
  delete-neon-branch:
    steps:
      uses: neondatabase/delete-branch-action@v3
      with:
        project_id: rapid-haze-373089
        branch: br-long-forest-224191
        api_key: { { secrets.NEON_API_KEY } }
Input variables
inputs:
  project_id:
    required: true
    description: 'The Neon project id'
  branch_id:
    description: 'The Neon branch id'
    deprecationMessage: 'The `branch_id` input is deprecated in favor of `branch`'
  api_key:
    description: 'The Neon API key, read more at https://neon.tech/docs/manage/api-keys'
    required: true
  branch:
    description: 'The Neon branch name or id'
Outputs
This Action has no outputs.

Reset from parent action
This GitHub Action resets a child branch with the latest data from its parent branch.

info
The source code for this action is available on GitHub.

Prerequisites
Using this action requires a Neon API key. For information about obtaining an API key, see Create an API key.
Add your Neon API key to your GitHub Secrets:
In your GitHub repository, go to Project settings and locate Secrets at the bottom of the left sidebar.
Click Actions > New Repository Secret.
Name the secret NEON_API_KEY and paste your API key in the Secret field.
Click Add Secret.
Example
The following example demonstrates how to reset a branch in your Neon project:

name: Reset Neon Branch with GitHub Actions Demo
run-name: Reset a Neon Branch 🚀
jobs:
  Reset-Neon-Branch:
    steps:
      - uses: neondatabase/reset-branch-action@v1
        with:
          project_id: rapid-haze-373089
          parent: true
          branch: child_branch
          api_key: ${{ secrets.NEON_API_KEY }}
        id: reset-branch
      - run: echo branch_id ${{ steps.reset-branch.outputs.branch_id }}
Input variables
inputs:
  project_id:
    required: true
    description: 'The project id'
  branch:
    required: true
    description: 'The branch name or id to reset'
  api_key:
    description: 'The Neon API key'
    required: true
  parent:
    description: 'If specified, the branch will be reset to the parent branch'
    required: false
  cs_role_name:
    description: 'The output connection string db role name'
    required: false
  cs_database:
    description: 'The output connection string database name'
    required: false
  cs_prisma:
    description: 'Use prisma in output connection string or not'
    required: false
    default: 'false'
  cs_ssl:
    description: >
      Add sslmode to the connection string. Supported values are: "require", "verify-ca", "verify-full", "omit".
    required: false
    default: 'require'
project_id: The ID of your Neon project. Find this value in the Neon Console on the Settings page.
parent: If specified, the branch will be reset to the latest state of the parent branch.
branch: The name or id of the branch to reset.
api_key: An API key created in your Neon account.
The action outputs a connection string. You can modify the connection string with these optional connection string (cs_*) inputs:

cs_role_name: The output connection string database role name.
cs_database: The output connection string database name.
cs_prisma: Use Prisma in output connection string or not. The default is 'false'.
cs_ssl: Add sslmode to the connection string. Supported values are: "require", "verify-ca", "verify-full", "omit". The default is "require".
Outputs
outputs:
  branch_id:
    description: 'Reset branch id'
    value: ${{ steps.reset-branch.outputs.branch_id }}
  db_url:
    description: 'DATABASE_URL of the branch after the reset'
    value: ${{ steps.reset-branch.outputs.db_url }}
  db_url_with_pooler:
    description: 'DATABASE_URL with pooler of the branch after the reset'
    value: ${{ steps.reset-branch.outputs.db_url_with_pooler }}
  host:
    description: 'Branch host after reset'
    value: ${{ steps.reset-branch.outputs.host }}
  host_with_pooler:
    description: 'Branch host with pooling enabled after reset'
    value: ${{ steps.reset-branch.outputs.host_with_pooler }}
  password:
    description: 'Password for connecting to the branch database after reset'
    value: ${{ steps.reset-branch.outputs.password }}
branch_id: The ID of the newly reset branch.
db_url: Database connection string for the branch after the reset.
db_url_with_pooler: The pooled database connection string for the branch after the reset.
host: The branch host after the reset.
host_with_pooler: The branch host with pooling after the reset.
password: The password for connecting to the branch database after the reset.
Example applications
The following example applications use GitHub Actions workflows to create and delete branches in Neon.

Preview branches with Cloudflare Pages
Demonstrates using GitHub Actions workflows to create a Neon branch for every Cloudflare Pages preview deployment

Preview branches with Vercel
Demonstrates using GitHub Actions workflows to create a Neon branch for every Vercel preview deployment

Preview branches with Fly.io
Demonstrates using GitHub Actions workflows to create a Neon branch for every Fly.io preview deployment

Neon Twitter app
Demonstrates using GitHub Actions workflows to create a Neon branch for schema validation and perform migrations

Features
/
Branching
Branching — Testing queries
Create a Neon branch to test queries before running them in production

Complex queries that modify data or alter schemas have the potential to be destructive. It is advisable to test these types of queries before running them in production. On other database systems, testing potentially destructive queries can be time and resource intensive. For example, testing may involve setting up a separate database instance and replicating data. With Neon, you can instantly create a database branch with a full copy-on-write clone of your production data in just a few clicks. When you finish testing, you can remove the branch just as easily.

This guide walks you through creating a branch of your production data, testing a potentially destructive query, and deleting the branch when you are finished.

Create a test branch
Test your query
Delete the test branch
For the purpose of this guide, let's assume you have a database in Neon with the following table and data:

CREATE TABLE Post (
    id INT PRIMARY KEY,
    title VARCHAR(255),
    content TEXT,
    author_name VARCHAR(100),
    date_published DATE
);
INSERT INTO Post (id, title, content, author_name, date_published)
VALUES
(1, 'My first post', 'This is the content of the first post.', 'Alice', '2023-01-01'),
(2, 'My second post', 'This is the content of the second post.', 'Alice', '2023-02-01'),
(3, 'Old post by Bob', 'This is an old post by Bob.', 'Bob', '2020-01-01'),
(4, 'Recent post by Bob', 'This is a recent post by Bob.', 'Bob', '2023-06-01'),
(5, 'Another old post', 'This is another old post.', 'Alice', '2019-06-01');
Create a test branch
In the Neon Console, select your project.
Select Branches.
Click Create branch to open the branch creation dialog.Create branch dialog
Enter a name for the branch. This guide uses the name my_test_branch.
Select a parent branch. Select the branch defined as your default branch.
Under Include data up to, select the Current point in time option to create a branch with the latest available data from the parent branch (the default).
Click Create new branch to create your branch.
You are directed to the Branches page where you are shown the details for your new branch.

You can also create a test branch using the Neon CLI or Neon API.

CLI
API
neon branches create --project-id <project-id> --name my_test_branch
Test your query
Navigate to the SQL Editor, select the test branch, and run your query. For example, perhaps you are deleting blog posts from your database for a certain author published before a certain date, and you want to make sure the query only removes the intended records.

DELETE FROM Post
WHERE author_name = 'Alice' AND date_published < '2020-01-01';
Next, inspect the data to ensure the intended records were deleted, while others remained unaffected. This query allows you to quickly see if the number of records matches your expectations:

SELECT COUNT(*) FROM Post;
Before the DELETE query, there were 5 records. If the query ran correctly, this should now show 4.

Delete the test branch
When you finish testing your query, you can delete the test branch:

In the Neon Console, select a project.
Select Branches.
Select the test branch from the table.
From the Actions menu on the branch overview page, select Delete.
You can also delete a branch using the Neon CLI or Neon API.

CLI
API
neon branches delete my_test_branch

Features
/
Branching
Promote a branch
Learn how to promote a branch to the default branch of your Neon project using the Neon API

This guide describes how to create a new branch and promote it to the default branch of your Neon project in the context of a data recovery scenario. It also describes how to move the compute from your existing default branch to the new branch to avoid having to reconfigure your application's database connection details.

What is a default branch?
Each Neon project has a default branch. In the Neon Console, your default branch is identified on the Branches page by a DEFAULT tag. You can designate any branch as the default branch. The advantage of the default branch is that its compute remains accessible if you exceed your project's limits, ensuring uninterrupted access to data that resides on the default branch, which is typically the branch used in production.

For Neon Free Plan users, the compute associated with the default branch is always available.
For users on paid plans, the compute associated with the default branch is exempt from the limit on simultaneously active computes, ensuring that it is always available. Neon has a default limit of 20 concurrently active computes to protect your account from unintended usage.
Why promote a branch to default?
A common usage scenario involving promoting a branch to default is data recovery. For example, a data loss occurs on the current default branch. To recover the lost data, you create a point-in-time branch with data that existed before the data loss occurred. To avoid modifying your application's database connection configuration, you move the computefrom the current default branch to the new branch and make that branch your default branch.

The procedure described below creates a new branch and promotes it to the default branch of your project by performing the following steps:

Creating a new point-in-time branch without a compute
Moving the compute from your current default branch to the new branch
Renaming the old default branch
Renaming the new branch to the name of the old default branch
Promoting the new branch to default
Prerequisites
The following information is required to perform the procedure:

A Neon API key. For information about obtaining an API key, see Create an API key.
The project_id for your Neon project. You can obtain a project_id using the List projects method, or you can find it on your project's Project settings page in the Neon Console.
The branch_id of the current default branch. You can obtain a branch_id using the List branches method, or you can find it on the your project's Branches page in the Neon Console. A branch_id has a br- prefix.
The endpoint_id of the compute associated with the current default branch. You can obtain an endpoint_id using the List endpoints method, or you can find it on the Branches page in the Neon Console. An endpoint_id has an ep- prefix.
Creating a new point-in-time branch without a compute
The Create branch request shown below creates a point-in-time branch without a compute. The project_id is a required parameter. To create a point-in-time branch, specify a parent_timestamp value in the branch object. The parent_timestamp value must be provided in ISO 8601 format. You can use this timestamp converter. For more information about point-in-time restore, see Branching — Point-in-time restore (PITR).

The project_id value used in the example below is young-silence-08999984. You must also set the $NEON_API_KEY variable or replace $NEON_API_KEY with an actual API key. The branch is given the name recovery_branch. You will change the name in a later step.

curl --request POST \
     --url https://console.neon.tech/api/v2/projects/young-silence-08999984/branches \
     --header 'Accept: application/json' \
     --header "Authorization: Bearer $NEON_API" \
     --header 'Content-Type: application/json' \
     --data '
{
  "branch": {
    "parent_timestamp": "2023-09-02T10:00:00Z",
    "name": "recovery_branch"
  }
}
'
The response body includes the id of your new branch. You will need this value (br-solitary-hat-85369851) to move the compute in the next step.

Response body
note
Creating a point-in-time branch can also be performed using the Neon Console or CLI. See Create a point-in-time branch for Neon Console instructions. See Neon CLI commands — branches for CLI instructions.

Move the compute from your current default branch to the new branch
The Update endpoint API request shown below moves the compute from your current default branch to the new branch. The required parameters are the project_id and endpoint_id of your current default branch, and the branch_id of the new branch. You must also set the $NEON_API_KEY variable or replace $NEON_API_KEY with an actual API key.

curl --request PATCH \
     --url https://console.neon.tech/api/v2/projects/young-silence-08999984/endpoints/ep-curly-term-54009904 \
     --header 'Accept: application/json' \
     --header "Authorization: Bearer $NEON_API_KEY" \
     --header 'Content-Type: application/json' \
     --data '
{
  "endpoint": {
    "branch_id": "br-solitary-hat-85369851"
  }
}
'
Response body
note
This procedure can only be performed using the Neon API. You can expect Neon Cole and CLI support to be added in a future release.

Rename the old default branch
The Update branch API request shown below renames the old default branch to old_main. You may want to delete this branch later to reduce storage usage, but just rename it for now. The required parameters are the project_id and branch_id. You must also set the $NEON_API_KEY variable or replace $NEON_API_KEY with an actual API key.

curl --request PATCH \
     --url https://console.neon.tech/api/v2/projects/young-silence-08999984/branches/br-twilight-field-06246553 \
     --header 'Accept: application/json' \
     --header "Authorization: Bearer $NEON_API_KEY" \
     --header 'Content-Type: application/json' \
     --data '
{
  "branch": {
    "name": "old_main "
  }
}
'
Response body
note
Renaming a branch can also be performed using the Neon Console or CLI. See Rename a branch for Neon Console instructions. See Neon CLI commands — branches for CLI instructions.

Rename the new branch to the name of the old default branch
Rename the new branch to the name of the old branch, which was main. The Update branch API request shown below renames the new branch from recovery_branch to main.

curl --request PATCH \
     --url https://console.neon.tech/api/v2/projects/young-silence-08999984/branches/br-solitary-hat-85369851 \
     --header 'Accept: application/json' \
     --header "Authorization: Bearer $NEON_API_KEY" \
     --header 'Content-Type: application/json' \
     --data '
{
  "branch": {
    "name": "main"
  }
}
'
Response body
note
Renaming a branch can also be performed using the Neon Console or CLI. See Rename a branch for Neon Console instructions. See Neon CLI commands — branches for CLI instructions.

Promote the new branch to default
The Set default branch API request sets the new branch as the default branch for the project.

curl --request POST \
     --url https://console.neon.tech/api/v2/projects/young-silence-08999984/branches/br-solitary-hat-85369851/set_as_default \
     --header 'Accept: application/json' \
     --header "Authorization: Bearer $NEON_API_KEY"
Response body
note
Promoting a branch to default can also be performed using the Neon Console or CLI. See Set a branch as primary for Neon Console instructions. See Neon CLI commands — branches for CLI instructions.

You should now have a new default branch, and because you moved the compute from your old default branch to the new one, you do not need to change the connection details in your applications. Once you have validated the change, consider deleting your old default branch to save storage space. See Delete a branch with the API.
Features
Get started with logical replication
Learn how to replicate data to and from your Neon Postgres database

Beta
Replicating data to Neon, where Neon is configured as a subscriber in a Postgres logical replication setup, is currently in Beta. We welcome your feedback to help improve this feature. You can provide feedback via the Feedback form in the Neon Console or by reaching out to us on Discord.

Neon's logical replication feature, available to all Neon users, allows you to replicate data to and from your Neon Postgres database:

Perform live migrations to Neon from external sources such as AWS RDS, Aurora, and Google Cloud SQL — or any platform that runs Postgres.
Stream data from your Neon database to external destinations, enabling Change Data Capture (CDC) and real-time analytics. External sources might include data warehouses, analytical database services, real-time stream processing systems, messaging and event-streaming platforms, and external Postgres databases, among others.
Replicate data from one Neon project to another for Neon project, account, Postgres version, or region migration.
Neon logical replication subscribers image

Logical replication in Neon works like it does on any standard Postgres installation. It uses a publisher-subscriber model to replicate data from the source database to the destination database. Neon can act as a publisher or subscriber.

Replication starts by copying a snapshot of the data from the publisher to the subscriber. Once this is done, subsequent changes are sent to the subscriber as they occur in real-time.

To learn more about Postgres logical replication, see the following topics.

Learn about logical replication
Logical replication concepts
Learn about Postgres logical replication concepts

Logical replication commands
Commands for managing your logical replication configuration

Logical replication in Neon
Information about logical replication specific to Neon

To get started, jump into one of our step-by-step logical replication guides.

Replicate data from Neon
airbyte logo
Airbyte
Replicate data from Neon with Airbyte

bemi logo
Bemi
Create an automatic audit trail with Bemi

clickhouse logo
ClickHouse
Change Data Capture from Neon to ClickHouse with PeerDB (PeerDB docs)

doublecloud logo
DoubleCloud
Replicate data from Neon to ClickHouse with DoubleCloud

confluent logo
Confluent (Kafka)
Replicate data from Neon with Confluent (Kafka)

decodable logo
Decodable
Replicate data from Neon with Decodable

estuary logo
Estuary Flow
Replicate data from Neon with Estuary Flow

fivetran logo
Fivetran
Replicate data from Neon with Fivetran

materialize logo
Materialize
Replicate data from Neon to Materialize

neon logo
Neon to Neon
Replicate data from Neon to Neon

postgresql logo
Neon to PostgreSQL
Replicate data from Neon to PostgreSQL

prisma logo
Prisma Pulse
Stream database changes in real-time with Prisma Pulse

snowflake logo
Snowflake
Replicate data from Neon to Snowflake with Airbyte

Replicate data to Neon
alloydb logo
AlloyDB
Replicate data from AlloyDB to Neon

aws-rds logo
Aurora
Replicate data from Aurora to Neon

google-cloud-sql logo
Cloud SQL
Replicate data from Cloud SQL to Neon

neon logo
Neon to Neon
Replicate data from Neon to Neon

postgresql logo
PostgreSQL to Neon
Replicate data from PostgreSQL to Neon

sequin logo
Sequin
Stream data from platforms like Stripe, Linear, and GitHub to Neon

aws-rds logo
RDS
Replicate data from AWS RDS PostgreSQL to Neon

Features
/
Logical replication
Postgres logical replication concepts
Learn about PostgreSQL logical replication concepts

Beta
Replicating data to Neon, where Neon is configured as a subscriber in a Postgres logical replication setup, is currently in Beta. We welcome your feedback to help improve this feature. You can provide feedback via the Feedback form in the Neon Console or by reaching out to us on Discord.

Logical Replication is a method of replicating data between databases or between your database and other data services or platforms. It differs from physical replication in that it replicates transactional changes rather than copying the entire database byte-for-byte. This approach allows for selective replication, where users can choose specific tables or rows for replication. It works by capturing DML operations in the source database and applying these changes to the target, which could be another Postgres database or data platform.

With logical replication, you can copy some or all of your data to a different location and continue sending updates from your source database in real-time, allowing you to maintain up-to-date copies of your data in different locations.

note
For step-by-step setup instructions, refer to our logical replication guides.

Publisher subscriber model
The Postgres logical replication architecture is very simple. It uses a publisher and subscriber model for data replication. The primary data source is the publisher, and the database or platform receiving the data is the subscriber. On the initial connection from a subscriber, all the data is copied from the publisher to the subscriber. After the initial copy operation, any changes made on the publisher are sent to the subscriber. You can read more about this model in the PostgreSQL documentation.

Logical replication publisher subscriber archtitecture

Enabling logical replication
In Neon, you can enable logical replication from the Neon Console. This only necessary if your Neon Postgres instance is acting as a publisher, replicating data to another Postgres instance, data service, or platform.

To enable logical replication:

Select your project in the Neon Console.
On the Neon Dashboard, select Project settings.
Select Replication.
Click Enable.
You can verify that logical replication is enabled by running the following query:

SHOW wal_level;
 wal_level
-----------
 logical
Enabling logical replication turns on detailed logging, which is required to support the replication process. This increases the amount of data written to the Write-Ahead Log (WAL). Typically, you can expect a 10% to 30% increase in the amount of data written to the WAL, depending on the extent of write activity.

Publications
The Postgres documentation describes a publication as a group of tables whose data changes are intended to be replicated through logical replication. It also describes a publication as a set of changes generated from a table or a group of tables. It's indeed both of these things.

A particular table can be included in multiple publications if necessary. Currently, publications can only include tables within a single schema. This is a Postgres limitation.

Publications can specify the types of changes they replicate, which can include INSERT, UPDATE, DELETE, and TRUNCATE operations. By default, publications replicate all of these operation types.

You can create a publication for one or more tables on the "publisher" database using CREATE PUBLICATION syntax. For example, this command creates a publication named users_publication that tracks changes made to a users table.

CREATE PUBLICATION users_publication FOR TABLE users;
Subscriptions
A subscription represents the downstream side of logical replication. Data is replicated to a subscriber. A subscription- establishes a connection to the publisher and identifies the publication it intends to subscribe to.

A single subscriber can maintain multiple subscriptions, including multiple subscriptions to the same publisher.

You can create a subscription on a "susbcriber" database or platform using CREATE SUBSCRIPTION syntax. Building on the users_publication example above, here’s how you would create a subscription:

CREATE SUBSCRIPTION users_subscription
CONNECTION 'postgresql://username:password@host:port/dbname'
PUBLICATION users_publication;
A subscription requires a unique name, a database connection string, the name and password of your replication role, and the name of the publication it subscribes to.

How does it work under the hood?
While the publisher and subscriber model forms the surface of Postgres logical replication, the underlying mechanism is driven by a few key components, described below.

Write-Ahead Log (WAL)
The WAL is central to Postgres's data durability and crash recovery mechanisms. In the context of logical replication, the WAL records all changes to your data. For logical replication, the WAL serves as the primary source of data that needs to be replicated. It's the transaction data captured in the WAL that's processed and then relayed from a publisher to a subscriber.

Replication slots
Replication slots on the publisher database track replication progress, ensuring that no data in the WAL is purged before the subscriber has successfully replicated it. This mechanism helps maintain data consistency and prevent data loss in cases of network interruption or subscriber downtime.

Replication slots are typically created automatically with new subscriptions, but they can be created manually using the pg_create_logical_replication_slot function. Some "subscriber" data services and platforms require that you create a dedicated replication slot. This is accomplished using the following syntax:

SELECT pg_create_logical_replication_slot('my_replication_slot', 'pgoutput');
The first value, my_replication_slot is the name given to the replication slot. The second value is the decoder plugin the slot should use. Decoder plugins are discussed below.

The max_replication_slots configuration parameter defines the maximum number of replication slots that can be used to manage database replication connections. Each replication slot tracks changes in the publisher database to ensure that the connected subscriber stays up to date. You'll want a replication slot for each replication connection. For example, if you expect to have 10 separate subscribers replicating from your database, you would set max_replication_slots to 10 to accommodate each connection.

The max_replication_slots configuration parameter on Neon is set to 10 by default.

max_replication_slots = 10
important
To prevent storage bloat, Neon automatically removes inactive replication slots after a period of time if there are other active replication slots. If you have or intend on having more than one replication slot, please see Unused replication slots to learn more.

Decoder plugins
The Postgres replication architecture uses decoder plugins to decode WAL entries into a logical replication stream, making the data understandable for the subscriber. The default decoder plugin for PostgreSQL logical replication is pgoutput, and it's included in Postgres by default. You don't need to install it.

Neon, supports an alternative decoder plugin called wal2json. This decoder plugin differs from pgoutput in that it converts WAL data into JSON format, which is useful for integrating Postgres with systems and applications that work with JSON data.

To use this decoder plugin, you'll need to create a dedicated replication slot for it, as shown here:

SELECT pg_create_logical_replication_slot('my_replication_slot', 'wal2json');
For for more information about this alternative decoder plugin and how top use it, see wal2json.

WAL senders
WAL senders are processes on the publisher database that read the WAL and send the relevant data to the subscriber.

The max_wal_senders parameter defines the maximum number of concurrent WAL sender processes that are responsible for streaming WAL data to subscribers. In most cases, you should have one WAL sender process for each subscriber or replication slot to ensure efficient and consistent data replication.

The max_wal_senders configuration parameter on Neon is set to 10 by default, which matches the maximum number of replication slots defined by the max_replication_slots setting.

max_wal_senders = 10
WAL receivers
On the subscriber side, WAL receivers receive the replication stream (the decoded WAL data), and apply these changes to the subscriber. The number of WAL receivers is determined by the number of connections made by subscribers.

References
Logical replication - PostgreSQL documentation
Publications - PostgreSQL documentation
CREATE PUBLICATION
CREATE SUBSCRIPTION
wal2json

Features
/
Logical replication
Logical replication commands
Commands for managing your logical replication configuration

This topic provides commands for managing publications, subscriptions, and replication slots.

For step-by-step setup instructions, refer to our logical replication guides.

Publications
This section outlines how to manage publications in your replication setup.

Create a publication
This command creates a publication named my_publication that will track changes made to the users table:

CREATE PUBLICATION my_publication FOR TABLE users;
This command creates a publication that publishes all changes in two tables:

CREATE PUBLICATION my_publication FOR TABLE users, departments;
This command creates a publication that only publishes INSERT and UPDATE operations. Delete operations will not be published.

CREATE PUBLICATION my_publication FOR TABLE users
    WITH (publish = 'insert,update');
Add a table to a publication
This command adds a table to a publication:

ALTER PUBLICATION my_publication ADD TABLE sales;
Remove a table from a publication
This command removes a table from a publication:

ALTER PUBLICATION my_publication DROP TABLE sales;
Remove a publication
This command removes a publication:

DROP PUBLICATION IF EXISTS my_publication;
Recreate a publication
This command recreates a publication within a single transaction:

BEGIN;
  -- drop the publication
  DROP PUBLICATION IF EXISTS my_publication;
  -- re-create the publication
  CREATE PUBLICATION my_publication;
COMMIT;
Subscriptions
This section outlines how to manage subscriptions in your replication setup.

Create a subscription
Building on the my_publication example in the preceding section, here’s how you can create a subscription:

CREATE SUBSCRIPTION my_subscription
CONNECTION 'postgresql://username:password@host:port/dbname'
PUBLICATION my_publication;
A subscription requires a unique name, a database connection string, the name and password of your replication role, and the name of the publication that it subscribes to.

In the example above, my_subscription is the name of the subscription that connects to a publication named my_publication. In the example above, you would replace the connection details with your Neon database connection string, which you'll find in the Connection Details widget on the Neon Dashboard.

Create a subscription with two publications
This command creates a subscription that receives data from two publications:

CREATE SUBSCRIPTION my_subscription
CONNECTION 'postgresql://username:password@host:port/dbname'
PUBLICATION my_publication, sales_publication;
A single subscriber can maintain multiple subscriptions, including multiple subscriptions to the same publisher.

Create a subscription to be enabled later
This command creates a subscription with enabled = false so that you can enable the scription at a later time:

CREATE SUBSCRIPTION my_subscription
CONNECTION 'postgresql://username:password@host:port/dbname'
PUBLICATION my_publication
WITH (enabled = false);
Change the publication subscribed to
This command modifies an existing subscription to set it to a different publication:

ALTER SUBSCRIPTION my_subscription SET PUBLICATION new_new_publication;
Change the subscription connection
This command updates the connection details for a subscription:

ALTER SUBSCRIPTION subscription_name CONNECTION 'new_connection_string';
Disable a subscription
This command disables an existing subscription:

ALTER SUBSCRIPTION my_subscription DISABLE;
Drop a subscription
This command drops an existing subscription:

DROP SUBSCRIPTION my_subscription;
Replication slots
Replication slots are created on the publisher database to track replication progress, ensuring that no data in the WAL is purged before the subscriber has successfully replicated it. This mechanism serves to maintain data consistency and prevent data loss in cases of network interruption or subscriber downtime.

important
To prevent storage bloat, Neon automatically removes inactive replication slots after a period of time if there are other active replication slots. If you have or intend on having more than one replication slot, please see Unused replication slots to learn more.

Create a replication slot
Replication slots are typically created automatically with new subscriptions, but they can be created manually using the pg_create_logical_replication_slot function. Some "subscriber" data services and platforms require that you create a dedicated replication slot. This is accomplished using the following syntax:

SELECT pg_create_logical_replication_slot('my_replication_slot', 'pgoutput');
The first value, my_replication_slot is the name given to the replication slot. The second value is the decoder plugin the slot should use.

The max_replication_slots configuration parameter defines the maximum number of replication slots that can be used to manage database replication connections. Each replication slot tracks changes in the publisher database to ensure that the connected subscriber stays up to date. You'll want a replication slot for each replication connection. For example, if you expect to have 10 separate subscribers replicating from your database, you would set max_replication_slots to 10 to accommodate each connection.

The max_replication_slots configuration parameter on Neon is set to 10 by default.

max_replication_slots = 10
Remove a replication slot
To drop a logical replication slot that you created, you can use the pg_drop_replication_slot() function. For example, if you've already created a replication slot named my_replication_slot using pg_create_logical_replication_slot(), you can drop it by executing the following SQL command:

SELECT pg_drop_replication_slot('my_replication_slot');
This command removes the specified replication slot (my_replication_slot in this case) from your database. It's important to ensure that the replication slot is no longer in use or required before dropping it, as this action is irreversible and could affect replication processes relying on this slot.

Data Definition Language (DDL) operations
Logical replication in Postgres primarily handles Data Manipulation Language (DML) operations like INSERT, UPDATE, and DELETE. However, it does not automatically replicate Data Definition Language (DDL) operations such as CREATE TABLE, ALTER TABLE, or DROP TABLE. This means that schema changes in the publisher database are not directly replicated to the subscriber database.

Manual intervention is required to replicate DDL changes. This can be done by applying the DDL changes separately in both the publisher and subscriber databases or by using third-party tools that can handle DDL replication.

Monitoring replication
To ensure that your logical replication setup is running as expected, you should monitor replication processes regularly. The pg_stat_replication view displays information about each active replication connection to the publisher.

SELECT * FROM pg_stat_replication;
It provides details like the state of the replication, the last received WAL location, sent location, write location, and the delay between the publisher and subscriber.

Additionally, the pg_replication_slots view shows information about the current replication slots on the publisher, including their size.

SELECT * FROM pg_replication_slots;
It's important to keep an eye on replication lag, which indicates how far behind the subscriber is from the publisher. A significant replication lag could mean that the subscriber isn't receiving updates in a timely manner, which could lead to data inconsistencies.

References
CREATE PUBLICATION
ALTER PUBLICATION
DROP PUBLICATION
CREATE SUBSCRIPTION
ALTER SUBSCRIPTION
DROP SUBSCRIPTION
wal2json
pg_stat_replication
pg_replication_slots

Features
/
Logical replication
Logical replication in Neon
Information about logical replication specific to Neon

Beta
Replicating data to Neon, where Neon is configured as a subscriber in a Postgres logical replication setup, is currently in Beta. We welcome your feedback to help improve this feature. You can provide feedback via the Feedback form in the Neon Console or by reaching out to us on Discord.

This topic outlines information about logical replication specific to Neon, including important notices.

Important notices
To avoid potential issues, please review the following notices carefully before using logical replication in Neon.

Neon as a publisher
These notices apply when replicating data from Neon:

Autosuspend: Neon does not autosuspend a compute that has an active connection from a logical replication subscriber. In other words, a Neon Postgres instance with an active subscriber will not scale to zero, which may result in increased compute usage. For more information, see Logical replication and autosuspend.
Removal of inactive replication slots: To prevent storage bloat, Neon automatically removes inactive replication slots if there are other active replication slots. If you will have more than one replication slot, please read Unused replication slots before you begin.
Neon as a subscriber
This notice applies when replicating data to Neon:

Duplicate subscriptions when branching from a subscriber: When a child branch is created, restored, or reset from a parent branch that is a subscriber in a logical replication configuration, any subscription defined on the parent branch is duplicated on the child branch. This duplicate subscription will attempt to establish a connection to the same publisher, potentially leading to "slot already used" errors. Additionally, if the parent branch's compute is suspended, the child branch might take over as the subscriber, which can result in a replication gap on the parent branch as updates are directed to the child branch.

To avoid interruptions and inconsistencies, it’s strongly recommended to disable and drop the duplicate subscriptions on child branches using the following commands:

ALTER SUBSCRIPTION subscription_name DISABLE;
ALTER SUBSCRIPTION subscription_name SET (slot_name = NONE);
DROP SUBSCRIPTION subscription_name;
Even with this workaround, the replication gap issue can still occur if the parent branch is suspended before the duplicate subscription on a child branch is disabled. Therefore, we encourage you to take this action promptly on newly created, restored, or reset child branches.

This issue will be addressed in an upcoming release.

Logical replication and autosuspend
By default, Neon's Autosuspend feature suspends a compute after 300 seconds (5 minutes) of inactivity. In a logical replication setup, Neon does not autosuspend a compute that has an active connection from a logical replication subscriber. In other words, a compute with an active subscriber remains active at all times. Neon determines if there are active connections from a logical replication subscriber by checking for walsender processes on the Neon Postgres instance using the following query:

SELECT *
FROM pg_stat_replication
WHERE application_name != 'walproposer';
If the count is greater than 0, a Neon compute where the publishing Postgres instance runs will not be suspended.

Replication roles
It is recommended that you create a dedicated Postgres role for replicating data from Neon to a subscriber. This role must have the REPLICATION privilege. The default Postgres role created with your Neon project and roles created using the Neon Console, CLI, or API are granted membership in the neon_superuser role, which has the required REPLICATION privilege. Roles created via SQL do not have this privilege, and the REPLICATION privilege cannot be granted.

You can verify that your role has the REPLICATION privilege by running the following query:

SELECT rolname, rolreplication
FROM pg_roles
WHERE rolname = '<role_name>';
Subscriber access
A subscriber must be able to access the Neon database that is acting as a publisher. In Neon, no action is required unless you use Neon's IP Allow feature to limit IP addresses that can connect to Neon.

If you use Neon's IP Allow feature:

Determine the IP address or addresses of the subscriber.
In your Neon project, add the IPs to your IP Allow list, which you can find in your project's settings. For instructions, see Configure IP Allow.
Publisher access
When replicating data to Neon, you may need to allow connections from Neon on the publisher platform or service.

Neon uses 3 to 6 IP addresses per region for outbound communication, corresponding to each availability zone in the region. See NAT Gateway IP addresses for Neon's NAT gateway IP addresses. When configuring access, be sure to open access to all of the NAT gateway IP addresses for your Neon project's region.

Decoder plugins
Neon supports both pgoutput and wal2json replication output decoder plugins.

pgoutput: This is the default logical replication output plugin for Postgres. Specifically, it's part of the Postgres built-in logical replication system, designed to read changes from the database's write-ahead log (WAL) and output them in a format suitable for logical replication.
wal2json: This is also a logical replication output plugin for Postgres, but it differs from pgoutput in that it converts WAL data into JSON format. This makes it useful for integrating Postgres with systems and applications that work with JSON data. For usage information, see The wal2json plugin.
Dedicated replication slots
Some data services and platforms require dedicated replication slots. You can create a dedicated replication slot using the standard PostgreSQL syntax. As mentioned above, Neon supports both pgoutput and wal2json replication output decoder plugins.

SELECT pg_create_logical_replication_slot('my_replication_slot', 'pgoutput');
SELECT pg_create_logical_replication_slot('my_replication_slot', 'wal2json');
Publisher settings
The max_wal_senders and max_replication_slots configuration parameter settings on Neon are set to 10.

max_wal_senders = 10
max_replication_slots = 10
The max_wal_senders parameter defines the maximum number of concurrent WAL sender processes that are responsible for streaming WAL data to subscribers. In most cases, you should have one WAL sender process for each subscriber or replication slot to ensure efficient and consistent data replication.
The max_replication_slots defines the maximum number of replication slots used to manage database replication connections. Each replication slot tracks changes in the publisher database to ensure that the connected subscriber stays up to date. You'll want a replication slot for each replication connection. For example, if you expect to have 10 separate subscribers replicating from your database, you would set max_replication_slots to 10 to accommodate each connection.
If you require different values for these parameters, please contact Neon support.

Unused replication slots
To prevent storage bloat, Neon automatically removes an inactive replication slot if you have other active replication slots. Removal occurs after 75 minutes.

If you have only one replication slot, and that slot becomes inactive, it is not removed due to inactivity because a single replication slot does not bloat storage. If you find that your single replication slot has been removed, please contact Neon Support.

What causes a replication slot to become inactive?
An inactive replication slot is one that doesn't acknowledge flush_lsn progress for an extended period. This is the same flush_lsn value found in the pg_stat_replication view in your Neon database.

An inactive replication slot is often the result of a dead subscriber, where the replication slot is not dropped after a subscriber is deactivated or becomes unavailable. An inactive replication slot can also result from a replication delay configured on the subscriber. For example, some subscribers allow you to configure the replication frequency or set a replication delay to minimize usage.

How to avoid removal of inactive replication slots
To avoid having "inactive" replication slots removed, ensure that your subscriber reports flush_lsn progress regularly and that your replication connection doesn't disappear for more than 75 minutes. If the 75-minute limit is not sufficient for your replication setup, please contact Neon Support to discuss a limit extension.

If using Debezium, ensure that flush.lsn.source is set to true to allow WAL logs on the source to be cleared. For other subscriber platforms, check for an equivalent setting to make sure it's configured to acknowledge progress on the subscriber.

What to do if your replication slot is removed
If you find that a replication slot was removed and you need to add it back, please see Create a replication slot for instructions or refer to the replication slot creation instructions for your subscriber.

Features
Read replicas
Maximize scalability and more with read replicas

Neon read replicas are independent computes designed to perform read operations on the same data as your primary read-write compute. Neon's read replicas do not replicate data across database instances. Instead, read requests are directed to a same data source as your read/write compute. The following diagram shows how your primary compute and read replicas send read requests to the same Pageserver, which is the component of the Neon architecture that is responsible for serving read requests.

read replica computes

Neon read replicas are asynchronous, which means they are eventually consistent. As updates are made by your primary compute, Safekeepers store the data changes durably until they are processed by Pageservers. At the same time, Safekeepers keep read replica computes up to date with the most recent changes to maintain data consistency.

Neon supports creating read replicas in the same region as your database. Cross-region read replicas are currently not supported.

You can instantly create one or more read replicas for any branch in your Neon project and configure the amount of vCPU and memory allocated to each. Read replicas also support Neon's Autoscaling and Autosuspend features, providing you with control over the compute resources used by your read replicas.

How can you use read replicas?
Neon's read replicas have a number of potential applications:

Increase throughput: By distributing read requests among multiple read replicas, you can achieve higher throughput for both read-write and read-only workloads.
Offloading work: You can assign reporting or analytical workloads to a read replica to prevent any impact on the performance of read-write application workloads.
Access control: You can use read replicas to provide read-only data access to certain users or applications that do not need write access.
Resource customization: You configure different compute size, autoscaling, and autosuspend settings for each read replica to cater to the specific needs of different users and applications.
What are the advantages of Neon's read replica architecture?
Neon's read replicas perform read operations on the same data as your read-write compute — there's no replicating data across database instances. This has several advantages:

Efficient storage: With read replicas reading from the same source as your primary read-write compute, no additional storage is required to create a read replica. Data is neither duplicated nor replicated, which means there's no additional storage required.
Data consistency: Your primary read-write compute and read replicas read data from a single source, ensuring a high degree of data consistency.
Near-instant scalability: With no data replication required, you can create read replicas almost instantly. You can also scale read replica compute resources the same way you scale your primary read-write compute resources, by increasing the compute size.
Cost effectiveness: With no additional storage or tranfer of data, costs associated with storage and data transfer are avoided. Neon's read replicas also benefit from Neon's Autoscaling and Autosuspend features, which enable efficient management of compute resources.
Instant availability. With an architecture that separates storage and compute, you can allow read replicas to scale to zero when not in use without introducing lag. When a read replica starts up, it is up to date with your primary read-write compute almost instantly.
Get started with read replicas
Read replicas are a paid plan feature. To get started, refer to the Working with read replicas guide.

Features
/
Read replicas
Working with Neon read replicas
Learn how to create and and manage read replicas in Neon

Read replicas are supported with the Neon paid plans. This guide will lead you through the process of creating and managing read replicas.

The general methodology of using read replicas to segregate read-only work from your production database operations can be applied to a variety of uses cases, such as:

Offloading analytics or reporting queries
Distributing read requests to achieve higher throughput
Providing read-only data access to specific users or applications who do not need to modify data
Configuring different CPU and memory resources for each read replica for different users and applications
Regardless of the application, the steps for creating, configuring, and connecting to a read replica are the same. You can create one or more read replicas for any branch in your Neon project and configure the vCPU and memory allocated to each. Neon's Autoscaling and Autosuspend features are also supported, providing you with control over compute usage.

Prerequisites
A Neon paid plan account
A Neon project
Create a read replica
Creating a read replica involves adding a read replica compute to a branch. You can add a read replica compute to any branch in your Neon project using the Neon Console, Neon CLI, or Neon API.

Console
CLI
API
To create a read replica from the Neon Console:

In the Neon Console, select Branches.
Select the branch where your database resides.
Click Add Read Replica.
On the Add new compute dialog, select Read replica as the Compute type.
Specify the Compute size settings. You can configure a Fixed Size compute with a specific amount of vCPU and RAM (the default) or enable autoscaling by configuring a minimum and maximum compute size. You can also configure the Suspend compute after inactivity setting, which is the amount of idle time after which your compute is automatically suspended. The default setting is 5 minutes.
note
The compute size configuration determines the processing power of your database.

When you finish making your selections, click Create.
In a few seconds, your read replica is provisioned and appears on the Computes tab on the Branches page. The following section describes how to connect to your read replica.

Connect to a read replica
Connecting to a read replica is the same as connecting to any branch, except you connect via a read replica compute instead of your primary read-write compute. The following steps describe how to connect to your read replica with connection details obtained from the Neon Console.

On the Neon Dashboard, under Connection Details, select the branch, the database, and the role you want to connect with.

Under Compute, select a Replica.

Select a connection string or a code example from the drop-down menu and copy it. This is the information you need to connect to the read replica from you client or application.

A psql connection string appears similar to the following:

postgresql://[user]:[password]@[neon_hostname]/[dbname]
If you expect a high number of connections, select Pooled connection to add the -pooler flag to the connection string or example.

No write operations are permitted on a connection to a read replica.

View read replicas
You can view read replicas using the Neon Console or Neon API.

Console
API
To view read replicas for a branch, select Branches in the Neon Console, and select a branch. Under the Computes heading, the Type field identifies your read replicas. Read replicas have a R/O value instead of R/W.

View read replicas

Edit a read replica
You can edit a read replica using the Neon Console or Neon API to change the Compute size or Autosuspend configuration.

Console
API
To edit a read replica compute using the Neon Console:

In the Neon Console, select Branches.
Select a branch.
Under Computes, identify the read replica compute you want to modify, and click Edit.
Specify your settings click Save.
Delete a read replica
You can delete a read replica using the Neon Console or Neon API. Deleting a read replica is a permanent action, but you can quickly create a new read replica if you need one.

Console
API
To delete a read replica using the Neon Console:

In the Neon Console, select Branches.
Select a branch.
On the Computes tab, find the read replica you want to delete.
Click Edit → Delete.
Default and read replica compute setting synchronization
In a Postgres primary-standby configuration, certain settings should be no smaller on a standby than on the primary in order to ensure that the standby does not run out of shared memory during recovery, as described in the PostgreSQL hot standby documentation. For Neon read replicas, it's no different. The same settings should be no smaller on a read replica compute (the "standby") than on your primary read-write compute (the "primary"). For this reason, the following settings on read replica computes are synchronized with the settings on the primary read-write compute when the read replica compute is started:

max_connections
max_prepared_transactions
max_locks_per_transaction
max_wal_senders
max_worker_processes

Features
/
Read replicas
Read replicas — Data analysis and reporting
Leverage read replicas for running data-intensive queries

With Neon's read replica feature, you can instantly create a dedicated read replica computes for running data-intensive analytics or reporting queries. This allows you to avoid disruption or performance degradation on your production database.

A read replica reads data from the same source as your primary read-write compute. There's no data replication, so creating a read replica is a near-instant process. For more information about Neon's read replica architecture, see Read replicas.

Suppose you have a sales table in your production database. The table and data might look something like this:

CREATE TABLE sales (
    id SERIAL PRIMARY KEY,
    product_id INT NOT NULL,
    sale_amount DECIMAL(10,2) NOT NULL,
    sale_date DATE NOT NULL
);
INSERT INTO sales (product_id, sale_amount, sale_date) VALUES
(1, 20.50, '2022-07-24'),
(2, 35.99, '2022-08-24'),
(1, 20.50, '2022-09-24'),
(3, 15.00, '2023-01-24'),
(1, 20.50, '2023-04-24');
...
You want to find the total sale amount for each product in the past year, but due to the large number of products and sales in your database, you know it's a costly query that could impact performance on your production system.

This guide walks you through creating a read replica, connecting to it, running your query, and optionally deleting the read replica when finished.

Create a read replica
Creating a read replica involves adding a read replica compute to a branch.

You can add a read replica compute- to any branch in your Neon project by following these steps:

In the Neon Console, select Branches.
Select the branch where your database resides.
Click Add Read Replica.
On the Add new copmpute dialog, select Read replica as the Compute type.
Specify the Compute size settings. You can configure a fixed size compute with a specific amount of vCPU and RAM (the default) or enable autoscaling by configuring a minimum and maximum compute size using the slider. You can also configure an Autosuspend time setting, which is the amount of idle time after which a compute suspends due to inactivity. The default setting is 5 minutes.
note
The compute size configuration determines the processing power of your database.

When you finish making your selections, click Create.
Your read replica is provisioned and appears on the Computes tab of the Branches page. The following section describes how to connect to your read replica.

Alternatively, you can create read replicas using the Neon CLI or Neon API.

CLI
API
neon branches add-compute mybranch --type read_only
Connect to the read replica
Connecting to a read replica is the same as connecting to any branch, except you connect via a read replica compute instead of your primary read-write compute. The following steps describe how to connect to your read replica with connection details obtained from the Neon Console.

On the Neon Dashboard, under Connection Details, select the branch, the database, and the role you want to connect with.

Under Compute, select the Replica compute.

Select a Database and the Role you want to connect with.

Copy the connection string. This is the information you need to connect to the read replica from you client or application.

The connection string appears similar to the following:

postgresql://alex:AbC123dEf@ep-cool-darkness-123456.us-east-2.aws.neon.tech/dbname
If you expect a high number of connections, select Pooled connection to add the -pooler flag to the connection string.

The information in your connection string corresponds to the following connection details:

role: alex
password:AbC123dEf
hostname: ep-cool-darkness-123456.us-east-2.aws.neon.tech
database name: dbname. Your database name may differ.
When you connect to a read replica, no write operations are permitted on the connection.

Connect to your application from a client such as psql or add the connection details to your application. For example, to connect using psql, issue the following command:

psql postgresql://alex:AbC123dEf@ep-cool-darkness-123456.us-east-2.aws.neon.tech/dbname
Run the analytics query on the read replica
An analytics query on your sales table might look something like this:

SELECT product_id, SUM(sale_amount) as total_sales
FROM sales
WHERE sale_date >= (CURRENT_DATE - INTERVAL '1 year')
GROUP BY product_id;
If you have a lot of products and sales, this query might impact performance on your production system, but running the query on your read replica, which has its own dedicated compute resources, causes no disruption.

Delete the read replica
When you are finished running analytics queries, you can delete the read replica if it's no longer required. Deleting a read replica is a permanent action, but you can quickly create a new read replica when you need one.

To delete a read replica:

In the Neon Console, select Branches.
Select a branch.
On the Computes tab, find the read replica you want to delete.
Click Edit → Delete compute.

Features
/
Read replicas
Use Neon read replicas with Prisma
Learn how to scale Prisma applications with Neon read replicas

A Neon read replica is an independent read-only compute that performs read operations on the same data as your primary read-write compute, which means adding a read replica to a Neon project requires no additional storage.

A key benefit of read replicas is that you can distribute read requests to one or more read replicas, enabling you to easily scale your applications and achieve higher throughput for both read-write and read-only workloads.

For more information about Neon's read replica feature, see Read replicas.

In this guide, we'll show you how you can leverage Neon read replicas to efficiently scale Prisma applications using Prisma Client's read replica extension: @prisma/extension-read-replicas.

Prerequisites
An application that uses Prisma with a Neon database.
A paid plan account. Read replicas are a paid plan feature.
Create a read replica
You can create one or more read replicas for any branch in your Neon project.

You can add a read replica by following these steps:

In the Neon Console, select Branches.

Select the branch where your database resides.

Click Add Read Replica.

On the Add new compute dialog, select Read replica as the Compute type.

Specify the Compute size settings options. You can configure a Fixed Size compute with a specific amount of vCPU and RAM (the default) or enable autoscaling by configuring a minimum and maximum compute size. You can also configure the Suspend compute after inactivity setting, which is the amount of idle time after which your read replica compute is automatically suspended. The default setting is 5 minutes.

note
The compute size configuration determines the processing power of your database. More vCPU and memory means more processing power but also higher compute costs. For information about compute costs, see Billing metrics.

When you finish making selections, click Create.

Your read replica compute is provisioned and appears on the Computes tab of the Branches page.

Alternatively, you can create read replicas using the Neon API or Neon CLI.

API
CLI
curl --request POST \
     --url https://console.neon.tech/api/v2/projects/late-bar-27572981/endpoints \
     --header 'Accept: application/json' \
     --header "Authorization: Bearer $NEON_API_KEY" \
     --header 'Content-Type: application/json' \
     --data '
{
  "endpoint": {
    "type": "read_only",
    "branch_id": "br-young-fire-15282225"
  }
}
' | jq
Retrieve the connection string for your read replica
Connecting to a read replica is the same as connecting to any branch in a Neon project, except you connect via a read replica compute instead of your primary read-write compute. The following steps describe how to retrieve the connection string (the URL) for a read replica from the Neon Console.

On the Neon Dashboard, under Connection Details, select the branch, the database, and the role you want to connect with.

Under Compute, select a Replica compute.

Select the connection string and copy it. This is the information you need to connect to the read replica from your Prisma Client. The connection string appears similar to the following:

postgresql://alex:AbC123dEf@ep-cool-darkness-123456.us-east-2.aws.neon.tech/dbname
If you expect a high number of connections, select Pooled connection to add the -pooler flag to the connection string, but remember to append ?pgbouncer=true to the connection string when using a pooled connection. Prisma requires this flag when using Prisma Client with PgBouncer. See Use connection pooling with Prisma for more information.

Update your env file
In your .env file, set a DATABASE_REPLICA_URL environment variable to the connection string of your read replica. Your .env file should look something like this, with your regular DATABASE_URL and the newly added DATABASE_REPLICA_URL.

DATABASE_URL="postgresql://alex:AbC123dEf@ep-cool-darkness-123456.us-east-2.aws.neon.tech/dbname"
DATABASE_REPLICA_URL="postgresql://alex:AbC123dEf@ep-damp-cell-123456.us-east-2.aws.neon.tech/dbname"
Notice that the endpoint_id (ep-damp-cell-123456) for the read replica compute differs. The read replica is a different compute and therefore has a different endpoint_id.

Configure Prisma Client to use a read replica
@prisma/extension-read-replicas adds support to Prisma Client for read replicas. The following steps show you how to install the extension and configure it to use a Neon read replica.

Install the extension in your Prisma project:

npm install @prisma/extension-read-replicas
Extend your Prisma Client instance by importing the extension and adding the DATABASE_REPLICA_URL environment variable as shown:

import { PrismaClient } from '@prisma/client';
import { readReplicas } from '@prisma/extension-read-replicas';
const prisma = new PrismaClient().$extends(
  readReplicas({
    url: DATABASE_REPLICA_URL,
  })
);
note
You can also pass an array of read replica connection strings if you want to use multiple read replicas. Neon supports adding multiple read replicas to a database branch.

// lib/prisma.ts
const prisma = new PrismaClient().$extends(
  readReplicas({
    url: [process.env.DATABASE_REPLICA_URL_1, process.env.DATABASE_REPLICA_URL_2],
  })
);
When your application runs, read operations are sent to the read replica. If you specify multiple read replicas, a read replica is selected randomly.

All write and $transaction queries are sent to the primary compute defined by DATABASE_URL, which is your read/write compute.

If you want to read from the primary compute and bypass read replicas, you can use the $primary() method in your extended Prisma Client instance:

const posts = await prisma.$primary().post.findMany()
This Prisma Client query will be routed to your primary database.

Examples
This example demonstrates how to use the @prisma/extension-read-replicas extension in Prisma Client. It uses a simple TypeScript script to read and write data in a Postgres database.

Prisma read replicas demo
A TypeScript example showing how to use the @prisma/extension-read-replicas extension in Prisma Client

Features
Time Travel
Learn how to query point-in-time connections against your data's history

To help review your data's history, Time Travel lets you connect to any selected point in time within your history retention window and then run queries against that connection.

You can use Time Travel from two places in the Neon Console, and from the Neon CLI:

SQL Editor — Time Travel is built into the SQL editor letting you switch between queries of your current data and previous iterations of your data in the same view.
Restore — Time Travel Assist is also built into the Branch Restore flow where it can help you make sure you've targeted the correct restore point before you restore a branch.
Neon CLI — Use the Neon CLI to quickly establish point-in-time connections for automated scripts or command-line-based data analysis.
How Time Travel works
Time Travel leverages Neon's instant branching capability to create a temporary branch and compute at the selected point in time, which are automatically removed once you are done querying against this point-in-time connection. The computes are ephemeral: they are not listed on the Branches page or in a CLI or API list branches request.

However, you can see the history of operations related to the creation and deletion of branches and ephemeral computes on the Operations page:

start_compute
create_branch
delete_timeline
suspend_compute
How long do ephemeral endpoints remain active
The ephemeral endpoints are created according to your configured default compute size. An ephemeral compute remains active for as long as you keep running queries against it. After 10 seconds of inactivity, the timeline is deleted and the endpoint is removed.

History retention
You are only able to run Time Travel queries that fall within your history retention window, which starts at 24 hours for Free Plan users, up to 7 days for Launch plan users, and up to 30 days for Scale plan users.

You cannot select a time outside your current retention window.

To change your retention period, see Configure history retention.

Data integrity
Time Travel only allows non-destructive read-only queries. You cannot alter historical data in any way. If you try to run any query that could alter historical data, you will get an error message like the following:

time travel error message

Time Travel with the SQL Editor
Time Travel in the SQL Editor offers a non-destructive way to explore your database's historical data through read-only queries. By toggling Time Travel in the editor, you switch from querying your current data to querying against a selected point within your history retention window.

You can use this feature to help with scenarios like:

Investigating anomolies
Assessing the impact of new features
Troubleshooting
Compliance auditing
Here's an example of a completed Time Travel query.

time travel from sql editor

Time Travel Assist with Branch Restore
Time Travel Assist is also available from the Restore page, as part of the Branch Restore feature. Before completing a restore operation, it's a good idea to use Time Travel Assist to verify that you've targetted the correct restore point.

An SQL editor is built into the Restore page for this purpose. When you make your branch and timestamp selection to restore a branch, this selection can also be used as the point-in-time connection to query against.

Here is an example of a completed query:

Time travel assist

How to use Time Travel
Here is how to use Time Travel from both the SQL Editor and from the Restore page:

SQL Editor
Branch Restore
CLI
In the Neon Console, open the SQL Editor.

Use the Time Travel toggle to enable querying against an earlier point in time.

Time Travel toggle

Use the Date & Time selector to choose a point within your history retention window.

Write your read-only query in the editor, then click Run. You don't have to include time parameters in the query; the query is automatically targeted to your selected timestamp.

Billing considerations
The ephemeral endpoints used to run your Time Travel queries do contribute to your consumption usage totals for the billing period, like any other active endpoint that consumes resources.

A couple of details to note:

The endpoints are shortlived. They are suspended 10 seconds after you stop querying.
Since these endpoints are created according to your default compute size (which applies to all new branch computes you create), you may want to reduce this default if you're performing a lot of time-travel queries for troubleshooting.

Features
/
Time Travel
Time Travel tutorial
Use Time Travel to analyze changes made to your database over time

This guide demonstrates how you could use Time Travel to address a common development scenario: debugging issues following a CI/CD deployment to production.

In this scenario, your team has recently introduced a streamlined checkout process, managed by a new_checkout_process feature flag. Soon after this flag was enabled, customer support started receiving complaints related to the new feature. As a developer, you're tasked with investigating the issues to confirm whether they are directly linked to the feature's activation.

Before You Start
To follow this tutorial, you'll need:

A Neon account. Sign up here.
A history retention period that covers the timeframe of interest, allowing for effective use of Time Travel.
Step 1: Preparing Your Database
To simulate this scenario, create a feature_flags table used for controlling new feature availability.

Create project_db Database:

In the Neon Console, create a new database named project_db.

Initialize feature_flags Table:

Execute the following in the SQL Editor, with product_db selected as the database:

CREATE TABLE feature_flags (
    feature_name TEXT PRIMARY KEY,
    enabled BOOLEAN NOT NULL
);
Insert Sample Data:

Populate the table with an initial feature flag:

INSERT INTO feature_flags (feature_name, enabled)
VALUES ('new_checkout_process', FALSE);
This setup reflects a typical development stage: the feature is integrated and deployment-ready but remains inactive, awaiting activation.

Step 2: Simulating Feature Flag Activation
Now, we'll simulate the process of enabling this feature flag to release the feature.

Enable the Feature Flag
Execute the following SQL command in the SQL Editor to simulate activating the feature by changing the feature flag's status to TRUE.

UPDATE feature_flags SET enabled = TRUE WHERE feature_name = 'new_checkout_process';
This action mirrors enabling a new feature in your production environment, typically managed as part of your CI/CD pipeline.

Step 3: Determine exactly when the feature was enabled
Since user complaints started coming in right after the feature was enabled, our first debug step is to confirm the exact moment the new_checkout_process feature flag was activated. Assume we've checked the deployment logs or CI/CD pipeline history and found the activation timestamp to be 2023-04-09 at 6:11 PM EST.

For this tutorial, locate the timestamp of the UPDATE operation in the History tab of the SQL Editor:

select timestamp

note
Timestamps in the Neon Console are shown in your local timezone. The time in this screenshot converts from 2023-04-09 at 6:11:00:00 PM EST to 2023-04-09 at 10:11:00 PM UTC.

Step 4: Verifying Feature Flag Pre-Activation Status
Let's confirm that the feature was indeed disabled just before the feature flag's activation.

Enable the Time Travel toggle in the SQL Editor.

Enter a time period just before the identified activation timestamp.

For our purposes, we'll select 2023-04-09 at 18:10 PM EST, which is one minute before our activation time.

SELECT * FROM feature_flags WHERE feature_name = 'new_checkout_process';
We'll see the feature flag shows as f for false, as expected.

check pre-activation

Step 5: Analyzing Post-Activation State
With the pre-activation state confirmed, now check the feature flag's status immediately after activation.

Adjust Time Selector to Post-Activation:
Move to a time just after the feature's activation. For example, one minute after the timestamp copied from Step 2, so 2023-04-09 at 6:12 PM EST. Re-execute the query.

SELECT * FROM feature_flags WHERE feature_name = 'new_checkout_process';
check post-activation

Now, we see the new_checkout_process feature flag is t for true, confirming that enabling the feature caused the reported issues. With this confirmation we can move on to our follow-up actions: fix the problem, turn off the feature flag, update stakeholders, or engage in a feedback loop with users to refine the feature based on real-world usage.

Features
Schema diff
Learn how to use Neon's Schema Diff tool to compare branches of your database

Neon's Schema Diff tool lets you compare an SQL script of the schemas for two selected branches in a side-by-side view (or line-by-line on mobile devices).

How Schema Diff works
Schema Diff is available in the Neon Console for use in two ways:

Compare a branch's schema to its parent
Compare selected branches during a branch restore operation
You can also use the branches schema-diff command in the Neon CLI to effect a variety of comparisons.

Compare to parent
In the detailed view for any child branch, you can check the schema differences between the selected branch and its parent. Use this view to verify the state of these schemas before you Reset from parent.

Compare to another branch's history
Built into the Time Travel assist editor, you can use Schema Diff to help when restoring branches, letting you compare states of your branch against its own or another branch's history before you complete a branch restore operation.

Comparisons using the CLI
You can use the Neon CLI to compare a branch to any point in its own or any other branch's history. The branches schema-diff command offers full flexibility for any type of schema comparison: between a branch and its parent, a branch and its earlier state, or a branch to the head or prior state of another branch.

Practical Applications
Pre-Migration Reviews: Before migrating schemas from a development branch into main, use Schema Diff to ensure only intended schema changes are applied.
Audit Changes: Historically compare schema changes to understand the evolution of your database structure.
Consistency Checks: Ensure environment consistency by comparing schemas across development, staging, and production branches.
Automation: Integrate schema-diff into CI/CD pipelines to automatically compare schemas during deployments.
How to Use Schema Diff
You can launch the Schema Diff viewer from the Branches and Restore pages in the Neon Console.

From the Branches page
Open the detailed view for the branch whose schema you want to inspect. In the row of details for the parent branch, under the COMPARE TO PARENT block, click Open schema diff.

Schema diff from branches page

From the Restore page
Just like with Time Travel Assist, your first step is to choose the branch you want to restore, then choose where you want to restore from: From history (its own history) or ** From another branch** (from another branch's history).

Click the Schema Diff button, verify that your selections are correct, then click Compare.

The two-pane view shows the schema for both your target and your selected branches.

schema diff results

Using the Neon CLI
You can use the Neon CLI to:

Compare the latest schemas of any two branches
Compare against a specific point in its own or another branch’s history
Use the schema-diff subcommand from the branches command:

neon branches schema-diff [base-branch] [compare-source[@(timestamp|lsn)]]
The operation will compare a selected branch ([compare-source]) against the latest (head) of your base branch ([base-branch]). For example, if you want to compare recent changes you made to your development branch dev/alex against your production branch main, identify main as your base branch and dev/alex as your compare-source.

neon branches schema-diff main dev/alex
You have a few options here:

Append a timestamp or LSN to compare to a specific point in dev/alex branch's history.
If you are regularly comparing development branches against main, include main in your set-context file. You can then leave out the [base-branch] from the command.
Use aliases to shorten the command.
Include --database to reduce the diff to a single database. If you don't specify a database, the diff will include all databases on the branch.
Here is the same command using aliases, with main included in set-context, pointing to an LSN from dev/alex branch's history, and limiting the diff to the database people:

neon branch sd dev/alex@0/123456 --db people
To find out what other comparisons you can make, see Neon CLI commands — branches for full documentation of the command.

Understanding the Output
+ Green Highlight: Indicates additions or new elements in the schema.
- Red Highlight: Marks deletions or removed elements from the schema.
Tutorial
For a step-by-step guide showing you how to compare two development branches using Schema Diff, see Schema diff tutorial.

Limitations
Schema Diff is currently unable to compare branches that are protected under an IP Allow list. If you need to compare a protected branch, consider temporarily removing the IP Allow list to allow the Schema Diff comparison. Alternatively, if you are comparing non-default branches, you can temporarily enable "Allow unrestricted access to non-default branches" in the IP Allow settings.
Features
/
Schema diff
Schema diff tutorial
Step-by-step guide showing you how to compare two development branches using Schema Diff

In this guide we will create an initial schema on a new database called people on our main branch. We'll then create a development branch called dev/jordan, following our recommended convention for naming development branches. After making schema changes on dev/jordan, we'll use the Schema Diff tool on the Branches page to get a side-by-side, Github-style visual comparison between the dev/jordan development branch and main.

Before you start
To complete this tutorial, you'll need:

A Neon account. Sign up here.

To interact with your Neon database from the command line:

Install the Neon CLI
Download and install the psql client
Step 1: Create the Initial Schema
First, create a new database called people on the main branch and add some sample data to it.

Console
CLI
Create the database.

In the Neon Console, go to Databases → New Database. Make sure your main branch is selected, then create the new database called people.

Add the schema.

Go to the SQL Editor, enter the following SQL statement and click Run to apply.

CREATE TABLE person (
    id SERIAL PRIMARY KEY,
    name TEXT NOT NULL,
    email TEXT UNIQUE NOT NULL
);
Step 2: Create a development branch
Create a new development branch off of main. This branch will be an exact, isolated copy of main.

For the purposes of this tutorial, name the branch dev/jordan, following our recommended convention of creating a long-lived development branch for each member of your team.

Console
CLI
Create the development branch

On the Branches page, click Create Branch, making sure of the following:

Select main as the default branch.
Name the branch dev/jordan.
Verify the schema on your new branch

From the SQL Editor, use the meta-command \d person to inspect the schema of the person table. Make sure that the people database on the branch dev/jordan is selected.

use metacommand to inspect schema

Step 3: Update schema on a dev branch
Let's introduce some differences between the two branches. Add a new table to store addresses on the dev/jordan branch.

Console
CLI
In the SQL Editor, make sure you select dev/jordan as the branch and people as the database.

Enter this SQL statemenet to create a new address table.

CREATE TABLE address (
    id SERIAL PRIMARY KEY,
    person_id INTEGER NOT NULL,
    street TEXT NOT NULL,
    city TEXT NOT NULL,
    state TEXT NOT NULL,
    zip_code TEXT NOT NULL,
    FOREIGN KEY (person_id) REFERENCES person(id)
);
Step 4: View the schema differences
Now that you have some differences between your branches, you can view the schema differences.

Console
CLI
Click on dev/jordan to open the detailed view, then under Compare to Parent click Open schema diff.

select branches for schema diff

Make sure you select people as the database and then click Compare.

schema diff results

You will see the schema differences between dev/jordan and its parent main, including the new address table that we added to the dev/jordan branch.

You can also launch Schema Diff from the Restore page, usually as part of verifying schemas before you restore a branch to its own or another branch's history. See Branch restore for more info.

Features
IP Allow and protected branches
Limit database access to trusted IP addresses

Neon's IP Allow feature, available with the Neon Scale plan, ensures that only trusted IP addresses can connect to the project where your database resides, preventing unauthorized access and helping maintain overall data security. You can limit access to individual IP addresses, IP ranges, or IP addresses and ranges defined with CIDR notation.

You can configure IP Allow in your Neon project's settings. To get started, see Configure IP Allow.

IP Allow configuration

Protected branches
You can apply IP restrictions more precisely by designating specific branches in your Neon project as protected and enabling the Restrict IP access to protected branches only option. This will apply your IP allowlist to protected branches only with no IP restrictions on other branches in your project. Typically, the protected branches feature is used with branches that contain production or sensitive data. For step-by-step instructions, refer to our Protected branches guide.

Features
Protected branches
Learn how to use Neon's protected branches feature to secure your critical data

Neon's protected branches feature implements a series of protections:

Protected branches cannot be deleted.
Protected branches cannot be reset.
Projects with protected branches cannot be deleted.
Computes associated with a protected branch cannot be deleted.
New passwords are automatically generated for Postgres roles on branches created from protected branches. See below.
With additional configuration steps, you can apply IP restrictions to protected branches only. See below.
The protected branches feature is available with the Neon Scale plan.

Set a branch as protected
This example sets a single branch as protected, but you can have up to 5 protected branches.

To set a branch as protected:

In the Neon Console, select a project.

Select Branches to view the branches for the project.

Branch page

Select a branch from the table. In this example, we'll configure our default branch main as a protected branch.

On the branch page, click the Actions drop-down menu and select Set as protected.

Set as protected

In the Set as protected confirmation dialog, click Set as protected to confirm your selection.

Set as protected confirmation

Your branch is now designated as protected, as indicated by the protected branch shield icon, shown below.

Branch page badge

The protected branch designation also appears on your Branches page.

Branches page badge

New passwords generated for Postgres roles on child branches
When you create a branch in Neon, it includes all Postgres databases and roles from the parent branch. By default, Postgres roles on the child branch will have the same passwords as on the parent branch. However, this does not apply to protected branches. When you create a child branch from a protected branch, new passwords are generated for the matching Postgres roles on the child branch.

This behavior is designed to prevent the exposure of passwords that could be used to access your protected branch. For example, if you have designated a production branch as protected, the automatic password change for child branches ensures that you can create child branches for development or testing without risking access to data on your production branch.

Feature notes
This feature was released on July, 31, 2024. If you have existing CI scripts that create branches from protected branches, please be aware that passwords for matching Postgres roles on those newly created branches will now differ. If you depend on those passwords being the same, you'll need to make adjustments to get the correct connection details for those branches.
After a branch is created, the up-to-date connection string is returned in the output of the Create Branch GitHub Action.
The Reset Branch GitHub Action also outputs connection string values, in case you are using this action in your workflows.
The Neon CLI supports a connection-string command for retrieving a branch's connection string.
Resetting or restoring a child branch from a protected parent branch currently restores passwords for matching Postgres roles on the child branch to those used on the protected parent branch. This issue will be addressed in an upcoming release. See reset from parent to understand how Neon's branch reset and restore features work.
How to apply IP restrictions to protected branches
The protected branches feature works in combination with Neon's IP Allow feature to allow you to apply IP access restrictions to protected branches only. The basic setup steps are:

Define an IP allowlist for your project
Restrict IP access to protected branches only
Set a branch as protected (if you have not done so already)
Define an IP allowlist for your project
Neon Console
CLI
API
To configure an allowlist:

Select a project in the Neon Console.
On the Project Dashboard, select Settings.
Select IP Allow.IP Allow configuration
Specify the IP addresses you want to permit. Separate multiple entries with commas.
Click Save changes.
For details about specifying IP addresses, see How to specify IP addresses.

Restrict IP access to protected branches only
After defining an IP allowlist, the next step is to select the Restrict access to protected branches only option.

IP Allow configuration

This option removes IP restrictions from all branches in your Neon project and applies them to protected branches only.

After you've selected the protected branches option, click Save changes to apply the new configuration.

Remove branch protection
Removing a protected branch designation can be performed by selecting Set as unprotected from the More drop-down menu on the branch page.

Support
Neon's Community, Standard, Priority, and Enterprise support plans are outlined below. Support plans are mapped to Neon's pricing plans. See Upgrading your support plan.

Support channels	Community	Standard	Priority	Enterprise
Neon Discord Server	✓	✓	✓	✓
Support tickets	-	✓	✓	✓
Prioritized supported tickets	-	-	✓	✓
Video chat	-	-	✓	✓
Dedicated Customer Success Team	-	-		✓
SLAs	-	-		✓
important
The Neon Discord Server is available to all Neon users but is not an official Neon Support channel. If you are a paid plan user and require assistance from the Neon Support team, please open a support ticket, as described in Standard support.

Community support
Neon's Free Plan includes Community support.

Community support is provided through the Neon Discord Server, where you can ask questions or see what others are doing with Neon. You will find Neon users and members of the Neon team actively engaged in our Discord Server.

Standard support
Neon's Launch plan includes Standard support.

Standard support includes access to the Neon Support team via support tickets.

You can open support tickets in the Neon Console. Look for the Support link in the sidebar. It opens the Create Support Ticket modal, where you can describe your issue. To access the modal directly, click here.

Support ticket modal

You can expect an initial response time of 2 business days, from 6am to 6pm Pacific Standard Time (UTC -8), Monday through Friday, excluding public holidays in the United States. For custom support solutions, please contact Sales.

Priority support
Neon's Scale plan includes Priority support.

With Priority support, your support tickets are given priority by the Neon Support team and you can request a video chat. Requests for video chat should be submitted via a support ticket.

Enterprise support
Neon's Enterprise plan includes Enterprise support.

With Enterprise support, you have everything offered with the Priority plan plus dedicated Customer Success Team support, and SLAs.

note
If you are a Launch, Scale, or Enterprise user and are unable to access the support ticket form in the Neon Console, you can use the following email address as a fallback: support@neon.tech

Upgrading your support plan
Neon's support plans are mapped to our pricing plans, as outlined in the following table. Upgrading your support plan requires upgrading your pricing plan.

Support plan	Pricing plan
Community	Free Plan
Standard	Launch plan
Priority	Scale plan
Enterprise	Enterprise plan

Neon status
Stay informed about the performance and availability of Neon

For our customers to stay informed about the performance and availability of Neon, we provide a dedicated status page where you can monitor the health of our service in real-time.

The status page includes the status for:

Console and API Requests
Database Operations
Database Connectivity
To view the Neon Status page, please click here.

We strive to maintain the highest level of service availability and performance, but in the case of interruptions or maintenance, you'll be able to find the information you need promptly and accurately. Please remember to bookmark the link for easy access.

Plans and billing
Neon plans
Learn about the different plans offered by Neon

Neon's plans are designed to meet different user requirements, ranging from hobby projects to enterprise-level production workloads. We also offer custom enterprise plans with volume-based discounts for large teams or database fleets. Refer to our Pricing page for fees and a detailed plan comparison.

Neon offers four plans:

Free Plan
Launch
Scale
Enterprise
Plan Allowances and Extra Usage
Neon plans are structured around Allowances and Extra usage. Allowances are included in your plan. With Neon's paid plans, you can purchase extra usage in set increments for when you need to go over your allowance.

Free Plan
Neon's Free Plan plan is best for hobby projects, prototypes, and learning Neon.

Free Plan allowances
The Free Plan includes the following usage allowances:

Usage type	Plan allowance
Projects	1 Neon project
Branches	10 branches
Databases	Unlimited
Storage	0.5 GiB
Compute	24/7 availability at 0.25 vCPU with 1 GB RAM on your default branch. Autoscaling up to 2 vCPU with 8 GB RAM available. Your account includes 191.9 compute hours per month, with up to 5 of those hours available to non-default branches.
Data transfer (Egress)	5 GB per month
What are active hours and compute hours?
An active hour is a measure of the amount of time a compute is active. The time your compute is idle when suspended due to inactivity is not counted. In the table above, active hours are based on a 0.25 vCPU compute size.

A compute hour is one active hour for a compute with 1 vCPU. For a compute with .25 vCPU, it takes 4 active hours to use 1 compute hour. On the other hand, if your compute has 4 vCPUs, it takes only 15 minutes to use 1 compute hour.

Compute hours formula

compute hours = compute size * active hours
Free Plan features
Autosuspend (after 5 minutes of inactivity)
All supported regions
Project sharing
Advanced Postgres features such as connection pooling, logical replication, and 60+ Postgres extensions
Neon features such as branching, point-in-time restore up to 24 hours in the past, time travel connections, and more
Community support
For a complete list of features, refer to the detailed plan comparison on the Neon pricing page.

Free Plan Compute Allowances
On the Free Plan, your default branch compute can run 24/7 at 0.25 vCPU with 1 GB of RAM. If you enable autoscaling, your compute can scale up to 2 vCPU with 8 GB of RAM, providing additional resources to meet peak demand. Note that enabling autoscaling may affect 24/7 availability depending on your usage patterns. The Free Plan includes 191.9 compute hours per month, with up to 5 of those compute hours per month available to non-default branches. If you go over the 5 compute hours allowance, non-default branch computes are suspended until the allowance resets at the beginning of the month. If you go over the 191.9 compute hour allowance, all computes are suspended until the beginning of the month. For example, if you signed up for the Free Plan in January, your compute allowance resets on February 1st.

Launch
The Launch plan provides all of the resources, features, and support you need to launch your application. It's ideal for startups and growing businesses or applications.

Launch plan allowances
The Launch plan includes the following usage allowances:

Usage type	Plan allowance
Projects	10 Neon projects
Branches	500
Databases	Unlimited
Storage	10 GiB of data storage
Compute	300 compute hours (1,200 active hours)/month for all computes in all projects
Launch plan extra usage
Launch plan users have access to extra compute and storage, which is allocated and billed automatically when plan allowances are exceeded.

Extra usage type	Cost
Extra Storage	Billed for in units of 2 GiB at $3.50 per unit, prorated for the month
Extra Compute	Billed by compute hour at $0.16 per hour
Launch plan features
Compute size up to 4 vCPUs and 16 GB RAM, Autosuspend (5 minutes+ to 7 days)
Advanced Postgres features, including connection pooling, logical replication, and 60+ Postgres extensions
Neon features such as branching, point-in-time restore up to 7 days in the past, time travel connections, and more
Standard support
For a complete list of features, refer to the detailed plan comparison on the Neon pricing page.

Scale
The Scale plan provides full platform and support access and is designed for scaling production workloads.

Scale plan allowances
The Scale plan includes the following usage allowances:

Usage type	Plan allowance
Projects	50 Neon projects
Branches	500
Databases	Unlimited
Storage	50 GiB of data storage
Compute	750 compute hours (3,000 active hours)/month for all computes in all projects
Scale plan extra usage
Scale plan users have access to extra compute, storage, and projects, which is allocated and billed automatically when plan allowances are exceeded.

Extra usage type	Cost
Extra Storage	Billed for in units of 10 GiB at $15 per unit, prorated for the month
Extra Compute	Billed by compute hour at $0.16 per hour
Extra Projects	Billed for in units of 10 at $50 per unit
Scale plan features
Compute up to 10 vCPUs and 40 GB RAM, Autosuspend (1 minute+ to 7 days)
Advanced Postgres features, including connection pooling, logical replication, 60+ Postgres extensions, and customer-provided custom extensions
Neon features such as branching, point-in-time restore up to 30 days in the past, time travel connections, and more
Priority support
For a complete list of features, refer to the detailed plan comparison on the Neon pricing page.

Enterprise
The Enterprise plan is a custom plan intended for large teams, enterprises requiring database fleets, or SaaS vendors interested in reselling Neon or integrating Neon into their service.

Enterprise plan usage is entirely customizable and can support large data sizes.

Usage type	Plan allowance
Projects	Unlimited
Branches	Custom
Databases	Unlimited
Storage	Large data sizes
Compute	Custom
Additionally, the Enterprise plan can be tailored to your specific requirements with:

Custom pricing with discounts
Higher resource allowances for projects, branches, storage, and compute
Autosuspend (disabled entirely or up to 7 days)
Customer-owned S3
Enterprise plan users have access to Enterprise support, which includes everything offered with the Priority plan plus retail customer support, Customer Success Team support, and SLAs. For more information, Neon support plans are outlined on our Support page.

If you are interested in exploring an Enterprise plan with Neon, you can request an enterprise trial or get in touch with our sales team.

Feedback
We’re always looking for ways to improve our pricing model to make it as developer-friendly as possible. If you have feedback for us, let us know via the Feedback form in the Neon Console or our feedback channel on Discord. We read and consider every submission.

Plans and billing
Pricing estimation guide
Estimate your monthly bill with Neon

You can use this guide to estimate your monthly bill with Neon based on your selected plan and estimated usage.

Select your plan and note the monthly fee
Estimate your usage
Calculate extra usage fees (if applicable)
Total monthly estimate
Step 1: Select a plan and note the monthly fee
First, select a plan that best fits your requirements. Look closely at monthly fees, plan allowances, and the features that come with each plan. You can refer to our Plans page or the Neon Pricing page, which provides fees and a detailed plan comparison.

This table provides an overview of plan fees with allowances for storage, compute, and projects:

Plan	Monthly Fee	Storage Allowance	Compute Allowance	Project Allowance
Free Plan	$0	0.5 GiB	Always-available default branch compute, 5 compute hours for branch computes	1 project
Launch	$19	10 GiB	300 compute hours	10 projects
Scale	$69	50 GiB	750 compute hours	50 projects
Enterprise	Custom	Custom	Custom	Custom
Notes
For the Enterprise plan, please contact our Sales team for an estimate based on your custom needs.

Step 2: Estimate your usage
Estimate your monthly usage to see if any "extra usage" is required beyond the storage, compute, or project allowances included in your plan.

Storage (GiB): How much storage do you expect to use? Storage includes the size of your data and change history. For more information, see Storage.
Compute (Hours): How many compute hours will you require? A compute hour is 1 active hour on a compute with 1 vCPU. Neon supports compute sizes ranging from .25 vCPU to 10 vCPU. See Compute for a compute hour formula you can use to estimate your compute usage.
Projects: How many projects do you need? Neon recommends a project per application.
Step 3: Calculate extra usage fees
Based on your usage estimates, calculate the fees for extra storage units, compute hours, and project units.

important
On paid plans, extra usage is allocated and billed automatically when you exceed plan allowances

However, extra usage fees for storage and projects are prorated for the month from the date of purchase, meaning that you are not billed the full amount if extra units of storage or projects are allocated partway through the month.
Once an extra unit of storage or projects is allocated, you are billed for that extra unit for the remainder of the month. If you reduce your usage during that month and no longer require extra units of storage or projects, the extra usage charge is dropped at the beginning of the next month when your bill resets based on current usage. For more, see Extra usage.
For the Launch plan:
The Launch plan supports extra Storage and Compute. If you need extra projects, you'll need to move up to the Scale plan.

Extra Storage: If you exceed 10 GiB, extra storage is allocated in units of 2 GiB at $3.50 per unit.
Extra Compute: If you exceed 300 compute hours, extra compute is billed at $0.16/hour.
Resource	Unit	Price
Extra Storage	2 GiB	$3.50
Extra Compute	Compute hour	$0.16
For the Scale plan:
The Scale plan supports extra Storage, Compute, and Projects.

Extra Storage: If you exceed 50 GiB, extra storage is allocated in increments of 10 GiB at $15 per increment.
Extra Compute: If you exceed 750 compute hours, extra compute is billed at $0.16/hour.
Extra Projects: If you exceed 50 projects, extra projects are allocated in units of 10 projects at $50 per unit.
Resource	Unit	Price
Extra Storage	10 GiB	$15.00
Extra Compute	Compute hour	$0.16
Extra Projects	10	$50.00
Step 4: Total monthly estimate
Add up your plan's monthly fee and extra usage fees to estimate your total monthly bill.

Total Estimate = Plan Fee + Extra Storage Fee + Extra Compute Fee + Extra Project Fee
Launch plan example
Item	Details
Plan Fee	$19
Storage Usage	14 GiB (4 GiB over, $7 extra)
Compute Usage	350 hours (50 hours over, $8 extra)
Total Estimate	$34 per month
Scale plan example
Item	Details
Plan Fee	$69
Storage Usage	60 GiB (10 GiB over, $15 extra)
Compute Usage	800 hours (50 hours over, $8 extra)
Project Usage	55 projects (5 over, $50 extra)
Total Estimate	$142 per month
For examples illustrating extra usage incurred mid-month, usage fluctuations during the billing period, and prorated charges, see Extra usage.

Feedback
We’re always looking for ways to improve our pricing model to make it as developer-friendly as possible. If you have feedback for us, let us know via the Feedback form in the Neon Console or our feedback channel on Discord. We read and consider every submission.

Need help?

Plans and billing
Sample project billing
Practical example of how Neon pricing is calculated

Generative AI example
To give you a clearer sense of how billing works, let's explore a real-world example. Consider a simple image generation app that leverages Neon as the serverless database for storing user authentication details as well as records of image generation per user. Analyzing this usage over a monthly billing period can help you understand the nuances of Neon billing based on actual scenarios and choose the right pricing plan.

Overview: Costs by usage
Roughly six months since launch, this high-traffic application attracts about 80K visitors daily, up to 450K weekly. It receives a steady influx of new users, with 3-5 new accounts created every hour. Each user's activity is capped at 5 images per month. This pattern of interaction and account creation gives you a sense of the steady volume of activity hitting the database.

Assumptions
Tech stack (user management portion of the app):
Authentication: NextAuth.JS for authentication with OAuth
Database: Neon Serverless Postgres to store user info and session detail
ORM: Prisma ORM for database interactions
Deployment Region: US East (Ohio)
Userbase:
Daily Active Users. 80,000 users/day, implying a consistent volume of read queries. With a global, consumer-oriented user base, traffic is evenly distributed with no distinct peaks or dormant periods.
Account creation. Average of 3-5 sign-ups per hour, totaling 120 new accounts per day. This gives you an idea of the number of write operations to the database for user authentication.
User activity. Each user's usage is capped at 5 generations per month. This includes logging IDs of generated photos and the incremental number of generations, which are written to the relevant tables.
note
Given the high number of connections used by this application, connection pooling is essential.

Compute hours and storage:
Compute hours. This is the metric Neon uses to track compute usage. 1 compute hour is equal to 1 active hour for a compute with 1 vCPU. If you have a compute with .25 vCPU, as you do in this sample scenario, it takes 4 active hours to use 1 compute hour. You can use this formula to calculate compute hour usage: compute hours = compute size * active hours. The average daily number of active hours is 23.94, totaling 718.35 active hours for the sample month. This indicates steady but low-intensity database usage.
Storage. The amount of database storage currently used by your project. It includes the total volume of data across all branches plus a history of database changes. The amount of history retained is defined by your chosen history retention period. The storage size in this sample scenario is now over 25 GiB and growing steadily with new written data as the user base grows.
Usage breakdown for the month
These graphs show the compute and storage usage for the month.

Compute
Compute usage is steady at almost 24 active hours per day across the month.

Sample billing graph

A daily average of 23.94 active hours amounts to 713.35 active hours for the month.

Storage
Project storage grew 4.4 GiB over the month, from 23.6 GiB to 28 GiB.

Sample storage graph

Table view
Here are the monthly totals for compute and storage usage.

Metric	Daily Average	Monthly Total
Compute	23.94 active hours	718.35 active hours
Metric	Start of the month	End of the month
Storage	23.6 GiB	28 GiB
Which Neon pricing plan fits best?
At roughly 718 active hours for the month with a compute size of 0.25 vCPU, this application is well under the 300 compute hours (1,200 active hours)/month allowance for the Launch plan and 750 compute hours (3000 active hours)/month for the Scale plan. However, with a storage size of 25 GiB, the storage requirements for the application are over the Launch plan allowance of 10 GiB. You could go with the Launch plan which offers 10 GiB of storage plus extra storage at $3.50 per 2 GiB unit or the Scale plan which offers 50 GiB storage. Let's do that math to compare monthly bills:

Launch plan:

Base fee: $19
Storage usage: 25 GiB (15 GiB over the allowance)
Compute usage: 718 active hours (within the 300 compute hour/1200 active hour allowance)
Extra storage fee: 8 * $3.50 = $28
Extra compute fee: $0
Total estimate: $19 + $28 = $47 per month

Scale plan:

Base fee: $69
Storage usage: 25 GiB (within the 50 GiB allowance)
Compute usage: 718 active hours (within the 750 compute hour/3000 active hour allowance)
Extra storage fee: $0
Extra compute fee: $0
Total estimate: $69 per month

The Launch plan is more economical in the short term, but you might consider upgrading to the Scale plan when purchasing extra storage on the Launch plan is no longer cheaper than moving up to the $69 per month Scale plan. The Scale plan has a higher monthly storage allowance (50 GiB) and a cheaper per-unit extra storage cost (10 GiB at $15 vs. 2 GiB at $3.5). The Scale plan also offers additional features and more projects, which may factor into your decision about when to upgrade.

AI & Embeddings
Build AI applications with Neon Postgres as your vector database

Vector databases enable efficient storage and retrieval of vector data, which is an essential component in building AI applications that leverage Large Language Models (LLMs).

Neon supports the pgvector open-source extension, which enables Postgres as a vector database for storing and querying embeddings. This means you can leverage the open-source database that you trust as your vector store and forget about migrating data or adding a third-party vector storage solution.

Neon's AI Starter Kit provides resources, starter apps, and examples to help get you started.

Ship faster with Neon's AI Starter Kit
Sign up for Neon Postgres and jumpstart your AI application. Our starter apps and resources will help you get up and running.

Sign Up
The Neon AI Starter Kit includes:

Neon Postgres with the latest version of the Postgres pgvector extension for storing vector embeddings
A variety of hackable, pre-built AI starter apps:
AI chat
RAG chat
Semantic search
Hybrid search
Reverse image search
Chat with PDF
A vector search optimization guide for better AI application performance
A scaling guide for scaling your app with Neon's Autoscaling and Read Replica features
A collection of AI apps built with Neon that you can reference while building your own app
AI basics
AI concepts
Learn how embeddings are used to build AI applications

The pgvector extension
Learn about the pgvector Postgres extension

AI starter apps
Hackable, fully-featured, pre-built starter apps to get you up and running.

AI chatbot (OpenAI + LllamIndex)
A Netx.js AI chatbot starter app built with OpenAI and LlamaIndex

AI chatbot (OpenAI + LangChain)
A Netx.js AI chatbot starter app built with OpenAI and LangChain

RAG chatbot (OpenAI + LlamaIndex)
A Next.js RAG chatbot starter app built with OpenAI and LlamaIndex

RAG chatbot (OpenAI + LangChain)
A Next.js RAG chatbot starter app built with OpenAI and LangChain

Semantic search chatbot (OpenAI + LlamaIndex)
A Next.js Semantic Search chatbot starter app built with OpenAI and LlamaIndex

Semantic search chatbot (OpenAI + LangChain)
A Next.js Semantic Search chatbot starter app built with OpenAI and LangChain

Hybrid search (OpenAI)
A Next.js Hybrid Search starter app built with OpenAI

Reverse image search (OpenAI + LlamaIndex)
A Next.js Reverse Image Search Engine starter app built with OpenAI and LlamaIndex

Chat with PDF (OpenAI + LlamaIndex)
A Next.js Chat with PDF chatbot starter app built with OpenAI and LlamaIndex

Chat with PDF (OpenAI + LangChain)
A Next.js Chat with PDF chatbot starter app built with OpenAI and LangChain

AI integrations
Learn how to integrate Neon Postgres with LLMs and AI platforms.

LangChain (with OpenAI)
Learn how to use LangChain with OpenAI to create AI applications faster

LlamaIndex (with OpenAI)
Learn how to use LlamaIndex with OpenAI to create AI applications faster

Preparing your AI app for production
Optimize pgvector search
Optimize pgvector search for better application performance

Scale with Neon
Scale your AI app with Neon's Autoscaling and Read Replica features

AI apps built with Neon
AI applications built with Neon Postgres that you can reference as code examples or inspiration.

Feature your app here
Share your AI app on our #showcase channel on Discord for consideration.

AI vector database per tenant
Deploy an AI vector database per-tenant architecture with Neon

Guide: Build a RAG chatbot
Build a RAG chatbot in an Astro application with LlamaIndex and Postgres

Guide: Build a Reverse Image Search Engine
Using LlamaIndex with Postgres to Build your own Reverse Image Search Engine

Ask Neon Chatbot
An Ask Neon AI-powered chatbot built with pgvector

Vercel Postgres pgvector Starter
Enable vector similarity search with Vercel Postgres powered by Neon

YCombinator Semantic Search App
YCombinator semantic search application

Web-based AI SQL Playground
An AI-enabled SQL playground application for natural language queries

Jupyter Notebook for vector search with Neon
Jupyter Notebook for vector search with Neon, pgvector, and OpenAI

Image search with Neon and Vertex AI
Community: An image serch app built with Neon and Vertex AI

Text-to-SQL conversion with Mistral + LangChain
A Text-to-SQL conversion app built with Mistral AI, Neon, and LangChain

Postgres GPT Expert
Blog + repo: Create and publish a custom Postgres GPT Expert using OpenAI's GPT

AI tools
Learn about popular AI tools and how to use them with Neon Postgres.

Google Colab
A cloud-based environment to write and execute Python code, perfect for machine learning and data science tasks

Azure Data Studio Notebooks
A cloud-based Jupyter notebook service integrated with Azure Data Studio for creating, running, and sharing notebooks

AI & Embeddings
AI Concepts
Learn how embeddings are used to build AI applications

Embeddings are an essential component in building AI applications. This topic describes embeddings and how they are used, generated, and stored in Postgres.

What are embeddings?
When working with unstructured data, a common objective is to transform it into a more structured format that is easier to analyze and retrieve. This transformation can be achieved through the use of 'embeddings', which are vectors containing an array of floating-point numbers that represent the features or dimensions of your data. For example, a sentence like "The cow jumped over the moon" might be represented by an embedding that looks like this: [0.5, 0.3, 0.1].

The advantage of embeddings is that they allow us to measure the similarity between different pieces of text. By calculating the distance between two embeddings, we can assess their relatedness - the smaller the distance, the greater the similarity, and vice versa. This quality is particularly useful as it enables embeddings to capture the underlying meaning of the text.

Take the following three sentences, for example:

Sentence 1: "The cow jumped over the moon."
Sentence 2: "The bovine leaped above the celestial body."
Sentence 3: "I enjoy eating pancakes."
You can determine the most similar sentences by following these steps:

Generate embeddings for each sentence. For illustrative purposes, assume these values represent actual embeddings:

Embedding for sentence 1 → [0.5, 0.3, 0.1]
Embedding for sentence 2 → [0.6, 0.29, 0.12]
Embedding for sentence 3 → [0.1, -0.2, 0.4]
Compute the distance between all pairs of embeddings (1 & 2, 2 & 3, and 1 & 3).

Identify the pair of embeddings with the shortest distance between them.

When we apply this process, it is likely that sentences 1 and 2, both of which involve jumping cattle, will emerge as the most related according to a distance calculation.

Vector similarity search
Transforming data into embeddings and computing similarities between one or more items is referred to as vector search or similarity search. This process has a wide range of applications, including:

Information retrieval: By representing user queries as vectors, we can perform more accurate searches based on the meaning behind the queries, allowing us to retrieve more relevant information.
Natural language processing: Embeddings capture the essence of the text, making them excellent tools for tasks such as text classification and sentiment analysis.
Recommendation systems: Using vector similarity, we can recommend items similar to a given item, whether they be movies, products, books, or otherwise. This technique allows us to create more personalized and relevant recommendations.
Anomaly detection: By determining the similarity between items within a dataset, we can identify outliers or anomalies—items that don't quite fit the pattern. This can be crucial in many fields, from cybersecurity to quality control.
Distance metrics
Vector similarity search computes similarities (the distance) between data points. Calculating how far apart data points are helps us understand the relationship between them. Distance can be computed in different ways using different metrics. Some popular distance metrics include:

Euclidean (L2): Often referred to as the "ordinary" distance you'd measure with a ruler.
Manhattan (L1): Also known as "taxicab" or "city block" distance.
Cosine: This calculates the cosine of the angle between two vectors.
Other distance metrics supported by the pgvector extension include Hamming distance and [Jaccard distance]https://en.wikipedia.org/wiki/Jaccard_index).

Different distance metrics can be more appropriate for different tasks, depending on the nature of the data and the specific relationships you're interested in. For instance, cosine similarity is often used in text analysis.

Generating embeddings
A common approach to generating embeddings is to use an LLM API, such as OpenAI’s Embeddings API. This API allows you to input a text string into an API endpoint, which then returns the corresponding embedding. The "cow jumped over the moon" is a simplistic example with 3 dimensions. Most embedding models generate embeddings with a much larger number of dimensions. OpenAI's newest and most performant embedding models, text-embedding-3-small and text-embedding-3-large, generate embeddings with 1536 and 3072 dimensions by default, respectively.

Here's an example of how to use OpenAI's text-embedding-3-small model to generate an embedding:

curl https://api.openai.com/v1/embeddings \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -d '{
    "input": "Your text string goes here",
    "model": "text-embedding-3-small"
  }'
note
Running the command above requires an OpenAI API key, which must be obtained from OpenAI.

Upon successful execution, you'll receive a response similar to the following:

{
  "object": "list",
  "data": [
    {
      "object": "embedding",
      "index": 0,
      "embedding": [
        -0.006929283495992422,
        -0.005336422007530928,
        ... (omitted for spacing)
        -4.547132266452536e-05,
        -0.024047505110502243
      ],
    }
  ],
  "model": "text-embedding-3-small",
  "usage": {
    "prompt_tokens": 5,
    "total_tokens": 5
  }
}
To learn more about OpenAI's embeddings, see Embeddings. Here, you'll find an example of obtaining embeddings from an Amazon fine-food reviews dataset supplied as a CSV file. See Obtaining the embeddings.

There are many embedding models you can use, such as those provided by Mistral AI, Cohere, Hugging Face, etc. AI tools like LanngChain provide interfaces and integrations for working with a variety of models. See LangChain: Text embedding models. You'll also find a Neon Postgres guide on the LangChain site and Class NeonPostgres, which provides an interface for working with a Neon Postgres database.

Storing vector embeddings in Postgres
Neon supports the pgvector Postgres extension, which enables the storage and retrieval of vector embeddings directly within your Postgres database. When building AI applications, installing this extension eliminates the need to extend your architecture to include a separate vector store. Installing the pgvector extension simply requires running the following CREATE EXTENSION statement from the Neon SQL Editor or any SQL client connected to your Neon Postgres database.

CREATE EXTENSION vector;
After installing the pgvector extension, you can create a table to store your embeddings. For example, you might define a table similar to the following to store your embeddings:

CREATE TABLE items(id BIGSERIAL PRIMARY KEY, embedding VECTOR(1536));
To add embeddings to the table, you would insert the data as shown:

INSERT INTO items(embedding) VALUES ('[
    -0.006929283495992422,
    -0.005336422007530928,
    ...
    -4.547132266452536e-05,
    -0.024047505110502243
]');
For detailed information about using pgvector, refer to our guide: The pgvector extension.

AI & Embeddings
The pgvector extension
Enable Postgres as a vector store with the pgvector extension

The pgvector extension enables you to store vector embeddings and perform vector similarity search in Postgres. It is particularly useful for applications involving natural language processing, such as those built on top of OpenAI's GPT models.

pgvector supports:

Exact and approximate nearest neighbor search
Single-precision, half-precision, binary, and sparse vectors
L2 distance, inner product, cosine distance, L1 distance, Hamming distance, and Jaccard distance
Any language with a Postgres client
ACID compliance, point-in-time recovery, JOINs, and all other Postgres features
This topic describes how to enable the pgvector extension in Neon and how to create, store, and query vectors.

Try it on Neon!
Neon is Serverless Postgres built for the cloud. Explore Postgres features and functions in our user-friendly SQL editor. Sign up for a free account to get started.

Sign Up
Enable the pgvector extension
You can enable the pgvector extension by running the following CREATE EXTENSION statement in the Neon SQL Editor or from a client such as psql that is connected to Neon.

CREATE EXTENSION vector;
For information about using the Neon SQL Editor, see Query with Neon's SQL Editor. For information about using the psql client with Neon, see Connect with psql.

Create a table to store vectors
To create a table for storing vectors, you would use an SQL command similar to the following. Embeddings are stored in the VECTOR type column. You can adjust the number of dimensions as needed.

CREATE TABLE items (
  id BIGSERIAL PRIMARY KEY,
  embedding VECTOR(3)
);
note
The pgvector extension supports some specialized types other than VECTOR for storing embeddings. See HNSW vector types, and IVFFlat vector types.

This command generates a table named items with an embedding column capable of storing vectors with 3 dimensions. OpenAI's text-embedding-3-small model supports 1536 dimensions by default for each piece of text, which creates more accurate embeddings for natural language processing tasks. However, using larger embeddings generally costs more and consumes more compute, memory, and storage than using smaller embeddings. To learn more about embeddings and the cost-performance tradeoff, see Embeddings, in the OpenAI documentation.

Storing embeddings
After generating embeddings using a service like OpenAI’s Embeddings API, you can store them in your database. Using a Postgres client library in your preferred programming language, you can execute an INSERT statement similar to the following to store embeddings.

Insert two new rows into the items table with the provided embeddings.

INSERT INTO items (embedding) VALUES ('[1,2,3]'), ('[4,5,6]');
Load vectors in bulk using the COPY command:

COPY items (embedding) FROM STDIN WITH (FORMAT BINARY);
tip
For a Python script that loads embeddings in bulk, see bulk_loading.py.

Upsert vectors:

INSERT INTO items (id, embedding) VALUES (1, '[1,2,3]'), (2, '[4,5,6]')
   ON CONFLICT (id) DO UPDATE SET embedding = EXCLUDED.embedding;
Update vectors:

UPDATE items SET embedding = '[1,2,3]' WHERE id = 1;
Delete vectors:

DELETE FROM items WHERE id = 1;
Querying vectors
To retrieve vectors and calculate similarity, use SELECT statements and the distance function operators supported by pgvector.

Get the nearest neighbor to a vector by L2 distance:

SELECT * FROM items ORDER BY embedding <-> '[3,1,2]' LIMIT 5;
Get the nearest neighbor to a row by L2 distance:

SELECT * FROM items WHERE id != 1 ORDER BY embedding <-> (SELECT embedding FROM items WHERE id = 1) LIMIT 5;
Get rows within a certain distance by L2 distance:

SELECT * FROM items WHERE embedding <-> '[3,1,2]' < 5;
note
To use an index with a query, include ORDER BY and LIMIT clauses, as shown in the second query example above.

Distance function operators
<-> - L2 distance
<#> - (negative) inner product
<=> - cosine distance
<+> - L1 distance
note
The inner product operator (<#>) returns the negative inner product since Postgres only supports ASC order index scans on operators.

Distance queries
Get the distances:

SELECT embedding <-> '[3,1,2]' AS distance FROM items;
For inner product, multiply by -1 (since <#> returns the negative inner product):

SELECT (embedding <#> '[3,1,2]') * -1 AS inner_product FROM items;
For cosine similarity, use 1 - cosine distance:

SELECT 1 - (embedding <=> '[3,1,2]') AS cosine_similarity FROM items;
Aggregate queries
To average vectors:

SELECT AVG(embedding) FROM items;
To average groups of vectors:

SELECT category_id, AVG(embedding) FROM items GROUP BY category_id;
Indexing vectors
By default, pgvector performs exact nearest neighbor search, providing perfect recall. Adding an index on the vector column can improve query performance with a minor cost in recall. Unlike typical indexes, you will see different results for queries after adding an approximate index.

Supported index types include:

HNSW
IVFFLAT
HNSW
An HNSW index creates a multilayer graph. It has better query performance than an IVFFlat index (in terms of speed-recall tradeoff), but has slower build times and uses more memory. Also, an HNSW index can be created without any data in the table since there isn’t a training step like there is for an IVFFlat index.

HNSW vector types
HNSW indexes are supported with the following vector types:

vector - up to 2,000 dimensions
halfvec - up to 4,000 dimensions
bit - up to 64,000 dimensions
sparsevec - up to 1,000 non-zero elements
note
Notice how indexes are defined differently depending on the distance function being used. For example vector_l2_ops is specified for L2 distance, vector_ip_ops for inner product, and so on. Make sure you define your index according to the distance function you intend to use.

L2 distance:

CREATE INDEX ON items USING hnsw (embedding vector_l2_ops);
Inner product:

CREATE INDEX ON items USING hnsw (embedding vector_ip_ops);
Cosine distance:

CREATE INDEX ON items USING hnsw (embedding vector_cosine_ops);
L1 distance:

CREATE INDEX ON items USING hnsw (embedding vector_l1_ops);
Hamming distance:

CREATE INDEX ON items USING hnsw (embedding bit_hamming_ops);
Jaccard distance:

CREATE INDEX ON items USING hnsw (embedding bit_jaccard_ops);
HNSW index build options
m - the max number of connections per layer (16 by default)
ef_construction - the size of the dynamic candidate list for constructing the graph (64 by default)
This example demonstrates how to set the parameters:

CREATE INDEX ON items USING hnsw (embedding vector_l2_ops) WITH (m = 16, ef_construction = 64);
A higher value of ef_construction provides better recall at the cost of index build time and insert speed.

HNSW index query options
You can specify the size of the candidate list for search. The size is 40 by default.

SET hnsw.ef_search = 100;
A higher value provides better recall at the cost of speed.

This query shows how to use SET LOCAL inside a transaction to set ef_search for a single query:

BEGIN;
SET LOCAL hnsw.ef_search = 100;
SELECT ...
COMMIT;
HNSW index build time
To optimize index build time, consider configuring the maintenance_work_mem and max_parallel_maintenance_workers session variables before building an index:

note
Like other index types, it’s faster to create an index after loading your initial data.

maintenance_work_mem

Indexes build significantly faster when the graph fits into Postgres maintenance_work_mem.

A notice is shown when the graph no longer fits:

NOTICE:  hnsw graph no longer fits into maintenance_work_mem after 100000 tuples
DETAIL:  Building will take significantly more time.
HINT:  Increase maintenance_work_mem to speed up builds.
In Postgres, the maintenance_work_mem setting determines the maximum memory allocation for tasks such as CREATE INDEX. The default maintenance_work_mem value in Neon is set according to your Neon compute size:

Compute Units (CU)	vCPU	RAM	maintenance_work_mem
0.25	0.25	1 GB	64 MB
0.50	0.50	2 GB	64 MB
1	1	4 GB	67 MB
2	2	8 GB	134 MB
3	3	12 GB	201 MB
4	4	16 GB	268 MB
5	5	20 GB	335 MB
6	6	24 GB	402 MB
7	7	28 GB	470 MB
8	8	32 GB	537 MB
To optimize pgvector index build time, you can increase the maintenance_work_mem setting for the current session with a command similar to the following:

SET maintenance_work_mem='10 GB';
The recommended setting is your working set size (the size of your tuples for vector index creation). However, your maintenance_work_mem setting should not exceed 50 to 60 percent of your compute's available RAM (see the table above). For example, the maintenance_work_mem='10 GB' setting shown above has been successfully tested on a 7 CU compute, which has 28 GB of RAM, as 10 GiB is less than 50% of the RAM available for that compute size.

max_parallel_maintenance_workers

You can also speed up index creation by increasing the number of parallel workers. The default is 2.

The max_parallel_maintenance_workers sets the maximum number of parallel workers that can be started by a single utility command such as CREATE INDEX. By default, the max_parallel_maintenance_workers setting is 2. For efficient parallel index creation, you can increase this setting. Parallel workers are taken from the pool of processes established by max_worker_processes (10), limited by max_parallel_workers (8).

You can increase the maintenance_work_mem setting for the current session with a command similar to the following:

SET max_parallel_maintenance_workers = 7
For example, if you have a 7 CU compute size, you could set max_parallel_maintenance_workers to 7, before index creation, to make use of all of the vCPUs available.

For a large number of workers, you may also need to increase the Postgres max_parallel_workers, which is 8 by default.

Check indexing progress
You can check indexing progress with the following query:

SELECT phase, round(100.0 * blocks_done / nullif(blocks_total, 0), 1) AS "%" FROM pg_stat_progress_create_index;
The phases for HNSW are:

initializing
loading tuples
For related information, see CREATE INDEX Progress Reporting, in the PostgreSQL documentation.

IVFFlat
An IVFFlat index divides vectors into lists and searches a subset of those lists that are closest to the query vector. It has faster build times and uses less memory than HNSW, but has lower query performance with respect to the speed-recall tradeoff.

Keys to achieving good recall include:

Creating the index after the table has some data
Choosing an appropriate number of lists. A good starting point is rows/1000 for up to 1M rows and sqrt(rows) for over 1M rows.
Specifying an appropriate number of probes when querying. A higher number is better for recall, and a lower is better for speed. A good starting point is sqrt(lists).
IVFFlat vector types
IVFFlat indexes are supported with the following vector types:

vector - up to 2,000 dimensions
halfvec - up to 4,000 dimensions (added in 0.7.0)
bit - up to 64,000 dimensions (added in 0.7.0)
The following examples show how to add an index for each distance function:

note
Notice how indexes are defined differently depending on the distance function being used. For example vector_l2_ops is specified for L2 distance, vector_cosine_ops for cosine distance, and so on.

The following examples show how to add an index for each distance function:

L2 distance

CREATE INDEX ON items USING ivfflat (embedding vector_l2_ops) WITH (lists = 100);
note
Use halfvec_l2_ops for halfvec (and similar with the other distance functions).

Inner product

CREATE INDEX ON items USING ivfflat (embedding vector_ip_ops) WITH (lists = 100);
Cosine distance

CREATE INDEX ON items USING ivfflat (embedding vector_cosine_ops) WITH (lists = 100);
Hamming distance

CREATE INDEX ON items USING ivfflat (embedding bit_hamming_ops) WITH (lists = 100);
IVFFlat query options
You can specify the number of probes, which is 1 by default.

SET ivfflat.probes = 10;
A higher value provides better recall at the cost of speed. You can set the value to the number of lists for exact nearest neighbor search, at which point the planner won’t use the index.

You can also use SET LOCAL inside a transaction to set the number of probes for a single query:

BEGIN;
SET LOCAL ivfflat.probes = 10;
SELECT ...
COMMIT;
IVFFlat index build time
To optimize index build time, consider configuring the maintenance_work_mem and max_parallel_maintenance_workers session variables before building an index:

note
Like other index types, it’s faster to create an index after loading your initial data.

note
Like other index types, it’s faster to create an index after loading your initial data.

maintenance_work_mem

In Postgres, the maintenance_work_mem setting determines the maximum memory allocation for tasks such as CREATE INDEX. The default maintenance_work_mem value in Neon is set according to your Neon compute size:

Compute Units (CU)	vCPU	RAM	maintenance_work_mem
0.25	0.25	1 GB	64 MB
0.50	0.50	2 GB	64 MB
1	1	4 GB	67 MB
2	2	8 GB	134 MB
3	3	12 GB	201 MB
4	4	16 GB	268 MB
5	5	20 GB	335 MB
6	6	24 GB	402 MB
7	7	28 GB	470 MB
8	8	32 GB	537 MB
9	9	36 GB	604 MB
10	10	40 GB	671 MB
To optimize pgvector index build time, you can increase the maintenance_work_mem setting for the current session with a command similar to the following:

SET maintenance_work_mem='10 GB';
The recommended setting is your working set size (the size of your tuples for vector index creation). However, your maintenance_work_mem setting should not exceed 50 to 60 percent of your compute's available RAM (see the table above). For example, the maintenance_work_mem='10 GB' setting shown above has been successfully tested on a 7 CU compute, which has 28 GB of RAM, as 10 GiB is less than 50% of the RAM available for that compute size.

max_parallel_maintenance_workers

You can also speed up index creation by increasing the number of parallel workers. The default is 2.

The max_parallel_maintenance_workers sets the maximum number of parallel workers that can be started by a single utility command such as CREATE INDEX. By default, the max_parallel_maintenance_workers setting is 2. For efficient parallel index creation, you can increase this setting. Parallel workers are taken from the pool of processes established by max_worker_processes (10), limited by max_parallel_workers (8).

You can increase the maintenance_work_mem setting for the current session with a command similar to the following:

SET max_parallel_maintenance_workers = 7
For example, if you have a 7 CU compute size, you could set max_parallel_maintenance_workers to 7, before index creation, to make use of all of the vCPUs available.

For a large number of workers, you may also need to increase the Postgres max_parallel_workers, which is 8 by default.

Check indexing progress
You can check indexing progress with the following query:

SELECT phase, round(100.0 * blocks_done / nullif(blocks_total, 0), 1) AS "%" FROM pg_stat_progress_create_index;
The phases for HNSW are:

initializing
loading tuples
For related information, see CREATE INDEX Progress Reporting, in the PostgreSQL documentation.

Filtering
There are a few ways to index nearest neighbor queries with a WHERE clause:

SELECT * FROM items WHERE category_id = 123 ORDER BY embedding <-> '[3,1,2]' LIMIT 5;
Create an index on one or more of the WHERE columns for exact search"

CREATE INDEX ON items (category_id);
Create a partial index on the vector column for approximate search:

CREATE INDEX ON items USING hnsw (embedding vector_l2_ops) WHERE (category_id = 123);
Use partitioning for approximate search on many different values of the WHERE columns:

CREATE TABLE items (embedding vector(3), category_id int) PARTITION BY LIST(category_id);
Half-precision vectors
Half-precision vectors enable the storage of vector embeddings using 16-bit floating-point numbers, or half-precision, which reduces both storage size and memory usage by nearly half compared 32-bit floats. This efficiency comes with minimal loss in precision, making half-precision vectors beneficial for applications dealing with large datasets or facing memory constraints.

When integrating OpenAI's embeddings, you can take advantage of half-precision vectors by storing embeddings in a compressed format. For instance, OpenAI’s high-dimensional embeddings can be effectively stored with half-precision vectors, achieving high levels of accuracy, such as a 98% rate. This approach optimizes memory usage while maintaining performance.

You can use the halfvec type to store half-precision vectors, as shown here:

CREATE TABLE items (id bigserial PRIMARY KEY, embedding halfvec(3));
Binary vectors
Binary vector embeddings are a form of vector representation where each component is encoded as a binary digit, typically 0 or 1. For example, the word "cat" might be represented as [0, 1, 0, 1, 1, 0, 0, 1, ...], with each position in the vector being binary.

These embeddings are advantageous for their efficiency in both storage and computation. Because they use only one bit per dimension, binary embeddings require less memory compared to traditional embeddings that use floating-point numbers. This makes them useful when there is limited memory or when dealing with large datasets. Additionally, operations with binary values are generally quicker than those involving real numbers, leading to faster computations.

However, the trade-off with binary vector embeddings is a potential loss in accuracy. Unlike denser embeddings, which have real-valued entries and can represent subtleties in the data, binary embeddings simplify the representation. This can result in a loss of information and may not fully capture the intricacies of the data they represent.

Use the bit type to store binary vector embeddings:

CREATE TABLE items (id bigserial PRIMARY KEY, embedding bit(3));
INSERT INTO items (embedding) VALUES ('000'), ('111');
Get the nearest neighbors by Hamming distance (added in 0.7.0)

SELECT * FROM items ORDER BY embedding <~> '101' LIMIT 5;
Or (before 0.7.0)

SELECT * FROM items ORDER BY bit_count(embedding # '101') LIMIT 5;
Jaccard distance (<%>) is also supported with binary vector embeddings.

Binary quantization
Binary quantization is a process that transforms dense or sparse embeddings into binary representations by thresholding vector dimensions to either 0 or 1.

Use expression indexing for binary quantization:

CREATE INDEX ON items USING hnsw ((binary_quantize(embedding)::bit(3)) bit_hamming_ops);
Get the nearest neighbors by Hamming distance:

SELECT * FROM items ORDER BY binary_quantize(embedding)::bit(3) <~> binary_quantize('[1,-2,3]') LIMIT 5;
Re-rank by the original vectors for better recall:

SELECT * FROM (
    SELECT * FROM items ORDER BY binary_quantize(embedding)::bit(3) <~> binary_quantize('[1,-2,3]') LIMIT 20
) ORDER BY embedding <=> '[1,-2,3]' LIMIT 5;
Sparse vectors
Sparse vectors have a large number of dimensions, where only a small proportion are non-zero.

Use the sparsevec type to store sparse vectors:

CREATE TABLE items (id bigserial PRIMARY KEY, embedding sparsevec(5));
Insert vectors:

INSERT INTO items (embedding) VALUES ('{1:1,3:2,5:3}/5'), ('{1:4,3:5,5:6}/5');
The format is {index1:value1,index2:value2}/dimensions and indices start at 1 like SQL arrays.

Get the nearest neighbors by L2 distance:

SELECT * FROM items ORDER BY embedding <-> '{1:3,3:1,5:2}/5' LIMIT 5;
Differences in behaviour between pgvector 0.5.1 and 0.7.0
Differences in behavior in the following corner cases were found during our testing of pgvector 0.7.0:

Distance between a valid and NULL vector
The distance between a valid and NULL vector (NULL::vector) with pgvector 0.7.0 differs from pgvector 0.5.1 when using an HNSW or IVFFLAT index, as shown in the following examples:

HNSW

For the following script, comparing the NULL::vector to non-null vectors the resulting output changes:

SET enable_seqscan = off;
CREATE TABLE t (val vector(3));
INSERT INTO t (val) VALUES ('[0,0,0]'), ('[1,2,3]'), ('[1,1,1]'), (NULL);
CREATE INDEX ON t USING hnsw (val vector_l2_ops);
INSERT INTO t (val) VALUES ('[1,2,4]');
SELECT * FROM t ORDER BY val <-> (SELECT NULL::vector);
pgvector 0.7.0 output:

val
---------
 [1,1,1]
 [1,2,4]
 [1,2,3]
 [0,0,0]
pgvector 0.5.1 output:

val
---------
 [0,0,0]
 [1,1,1]
 [1,2,3]
 [1,2,4]
IVFFLAT

For the following script, comparing the NULL::vector to non-null vectors the resulting output changes:

SET enable_seqscan = off;
CREATE TABLE t (val vector(3));
INSERT INTO t (val) VALUES ('[0,0,0]'), ('[1,2,3]'), ('[1,1,1]'), (NULL);
CREATE INDEX ON t USING ivfflat (val vector_l2_ops) WITH (lists = 1);
INSERT INTO t (val) VALUES ('[1,2,4]');
SELECT * FROM t ORDER BY val <-> (SELECT NULL::vector);
pgvector 0.7.0 output:

val
---------
 [0,0,0]
 [1,2,3]
 [1,1,1]
 [1,2,4]
pgvector 0.5.1 output:

val
---------
[0,0,0]
[1,1,1]
[1,2,3]
[1,2,4]
Error messages improvement for invalid literals
If you use an invalid literal value for the vector data type, you will now see the following error message:

SELECT '[4e38,1]'::vector;
ERROR:  "4e38" is out of range for type vector
LINE 1: SELECT '[4e38,1]'::vector;
Resources
pgvector source code: https://github.com/pgvector/pgvector

AI & Embeddings
/
AI integrations
LangChain
Build AI applications faster with LangChain and Postgres

LangChain is a popular framework for working with AI, Vectors, and embeddings. LangChain supports using Neon as a vector store, using the pgvector extension.

Initialize Postgres Vector Store
LangChain simplifies the complexity of managing document insertion and embeddings generation using vector stores by providing streamlined methods for these tasks.

Here's how you can initialize Postgres Vector with LangChain:

// File: vectorStore.ts
import { NeonPostgres } from '@langchain/community/vectorstores/neon';
import { OpenAIEmbeddings } from '@langchain/openai';
const embeddings = new OpenAIEmbeddings({
  dimensions: 512,
  model: 'text-embedding-3-small',
});
export async function loadVectorStore() {
  return await NeonPostgres.initialize(embeddings, {
    connectionString: process.env.POSTGRES_URL as string,
  });
}
// Use in your code (say, in API routes)
const vectorStore = await loadVectorStore();
Generate Embeddings with OpenAI
LangChain handles embedding generation internally while adding vectors to the Postgres database, simplifying the process for users. For more detailed control over embeddings, refer to the respective JavaScript and Python documentation.

Stream Chat Completions with OpenAI
LangChain can find similar documents to the user's latest query and invoke the OpenAI API to power chat completion responses, providing a seamless integration for creating dynamic interactions.

Here's how you can power chat completions in an API route:

import { loadVectorStore } from './vectorStore';
import { pull } from 'langchain/hub';
import { ChatOpenAI } from '@langchain/openai';
import { createRetrievalChain } from 'langchain/chains/retrieval';
import type { ChatPromptTemplate } from '@langchain/core/prompts';
import { AIMessage, HumanMessage } from '@langchain/core/messages';
import { createStuffDocumentsChain } from 'langchain/chains/combine_documents';
const topK = 3;
export async function POST(request: Request) {
  const llm = new ChatOpenAI();
  const encoder = new TextEncoder();
  const vectorStore = await loadVectorStore();
  const { messages = [] } = await request.json();
  const userMessages = messages.filter((i) => i.role === 'user');
  const input = userMessages[userMessages.length - 1].content;
  const retrievalQAChatPrompt = await pull<ChatPromptTemplate>('langchain-ai/retrieval-qa-chat');
  const retriever = vectorStore.asRetriever({ k: topK, searchType: 'similarity' });
  const combineDocsChain = await createStuffDocumentsChain({
    llm,
    prompt: retrievalQAChatPrompt,
  });
  const retrievalChain = await createRetrievalChain({
    retriever,
    combineDocsChain,
  });
  const customReadable = new ReadableStream({
    async start(controller) {
      const stream = await retrievalChain.stream({
        input,
        chat_history: messages.map((i) =>
          i.role === 'user' ? new HumanMessage(i.content) : new AIMessage(i.content)
        ),
      });
      for await (const chunk of stream) {
        controller.enqueue(encoder.encode(chunk.answer));
      }
      controller.close();
    },
  });
  return new Response(customReadable, {
    headers: {
      Connection: 'keep-alive',
      'Content-Encoding': 'none',
      'Cache-Control': 'no-cache, no-transform',
      'Content-Type': 'text/plain; charset=utf-8',
    },
  });
}
Starter apps
Hackable, fully-featured, pre-built starter apps to get you up and running with LlamaIndex and Postgres.

AI chatbot (OpenAI + LangChain)
A Netx.js AI chatbot starter app built with OpenAI and LangChain

RAG chatbot (OpenAI + LangChain)
A Next.js RAG chatbot starter app built with OpenAI and LangChain

Semantic search chatbot (OpenAI + LangChain)
A Next.js Semantic Search chatbot starter app built with OpenAI and LangChain

Reverse image search (OpenAI + LangChain)
A Next.js Reverse Image Search Engine starter app built with OpenAI and LangChain

Chat with PDF (OpenAI + LangChain)
A Next.js Chat with PDF chatbot starter app built with OpenAI and LangChain

AI & Embeddings
/
AI integrations
LlamaIndex
Build AI applications faster with LlamaIndex and Postgres

LlamaIndex is a popular framework for working with AI, Vectors, and embeddings. LlamaIndex supports using Neon as a vector store, using the pgvector extension.

Initialize Postgres Vector Store
LlamaIndex simplifies the complexity of managing document insertion and embeddings generation using vector stores by providing streamlined methods for these tasks.

Here's how you can initialize Postgres Vector with LlamaIndex:

// File: vectorStore.ts
import { OpenAIEmbedding, Settings } from 'llamaindex';
import { PGVectorStore } from 'llamaindex/storage/vectorStore/PGVectorStore';
Settings.embedModel = new OpenAIEmbedding({
  dimensions: 512,
  model: 'text-embedding-3-small',
});
const vectorStore = new PGVectorStore({
  dimensions: 512,
  connectionString: process.env.POSTGRES_URL,
});
export default vectorStore;
// Use in your code (say, in API routes)
const index = await VectorStoreIndex.fromVectorStore(vectorStore);
Generate Embeddings with OpenAI
LlamaIndex handles embedding generation internally while adding vectors to the Postgres database, simplifying the process for users. For more detailed control over embeddings, refer to the respective JavaScript and Python documentation.

Stream Chat Completions with OpenAI
LlamaIndex can find similar documents to the user's latest query and invoke the OpenAI API to power chat completion responses, providing a seamless integration for creating dynamic interactions.

Here's how you can power chat completions in an API route:

import vectorStore from './vectorStore';
import { ContextChatEngine, VectorStoreIndex } from 'llamaindex';
interface Message {
  role: 'user' | 'assistant' | 'system' | 'memory';
  content: string;
}
export async function POST(request: Request) {
  const encoder = new TextEncoder();
  const { messages = [] } = (await request.json()) as { messages: Message[] };
  const userMessages = messages.filter((i) => i.role === 'user');
  const query = userMessages[userMessages.length - 1].content;
  const index = await VectorStoreIndex.fromVectorStore(vectorStore);
  const retriever = index.asRetriever();
  const chatEngine = new ContextChatEngine({ retriever });
  const customReadable = new ReadableStream({
    async start(controller) {
      const stream = await chatEngine.chat({ message: query, chatHistory: messages, stream: true });
      for await (const chunk of stream) {
        controller.enqueue(encoder.encode(chunk.response));
      }
      controller.close();
    },
  });
  return new Response(customReadable, {
    headers: {
      Connection: 'keep-alive',
      'Content-Encoding': 'none',
      'Cache-Control': 'no-cache, no-transform',
      'Content-Type': 'text/plain; charset=utf-8',
    },
  });
}
Starter apps
Hackable, fully-featured, pre-built starter apps to get you up and running with LlamaIndex and Postgres.

AI chatbot (OpenAI + LllamIndex)
A Netx.js AI chatbot starter app built with OpenAI and LlamaIndex

RAG chatbot (OpenAI + LlamaIndex)
A Next.js RAG chatbot starter app built with OpenAI and LlamaIndex

Semantic search chatbot (OpenAI + LlamaIndex)
A Next.js Semantic Search chatbot starter app built with OpenAI and LlamaIndex

Reverse image search (OpenAI + LlamaIndex)
A Next.js Reverse Image Search Engine starter app built with OpenAI and LlamaIndex

Chat with PDF (OpenAI + LlamaIndex)
A Next.js Chat with PDF chatbot starter app built with OpenAI and LlamaIndex

AI & Embeddings
/
Prepare your AI app for production
Optimize pgvector search
Fine-tune parameters for efficient and accurate similarity searches in Postgres

This guide explores how to effectively use pgvector for vector similarity searches in your AI applications. We'll address the following key questions:

How to profile your vector search queries, when using pgvector?
When to use indexes and tradeoffs between the available options?
Which parameters to tune for best performance?
We'll examine sequential scans, HNSW indexing, and IVFFlat indexing, providing benchmarks and practical recommendations for various dataset sizes. This will help you optimize pgvector queries in your Neon database for both accuracy and speed.

Without indexes, pgvector performs a sequential scan on the database and calculates the distance between the query vector and all vectors in the table. This approach does an exact search and guarantees 100% recall, but it can be costly with large datasets.

what is recall?
Recall is a metric used to evaluate the performance of a search algorithm. It measures how effectively the search retrieves relevant items from a dataset. It is defined as the ratio of the number of relevant items retrieved by the search to the total number of relevant items in the dataset.

The query below uses EXPLAIN ANALYZE to generate an execution plan and display the performance of the similarity search query.

EXPLAIN ANALYZE SELECT * FROM items ORDER BY embedding <-> '[0.011699999682605267,..., 0.008700000122189522]' LIMIT 100;
This is what the query plan looks like:

Limit  (cost=748.19..748.44 rows=100 width=173) (actual time=39.475..39.487 rows=100 loops=1)
  ->  Sort  (cost=748.19..773.19 rows=10000 width=173) (actual time=39.473..39.480 rows=100 loops=1)
        Sort Key: ((vec <-> '[0.0117,..., 0.0866]'::vector))
        Sort Method: top-N heapsort  Memory: 70kB
        ->  Seq Scan on items  (cost=0.00..366.00 rows=10000 width=173) (actual time=0.087..37.571 rows=10000 loops=1)
Planning Time: 0.213 ms
Execution Time: 39.527 ms
You can see in the plan that the query performs a sequential scan (Seq Scan) on the items table, which means that the query compares the query vector against all vectors in the items table. In other words, the query does not use an index.

To understand how queries perform at scale, we tested sequential scan vector searches with pgvector on subsets of the GIST-960 dataset with 10k, 50k, 100k, 500k, and 1M rows using a Neon database instance with 4 vCPUs and 16 GB of RAM.

The sequential scan search performed reasonably well for tables with 10k rows (~36ms). However, sequential scans start to become costly at 50k rows.

So, when should you use sequential scans rather than defining an index?

When your dataset is small and you do not intend to scale it.
When you need 100% recall (accuracy). Adding indexes trades recall for performance.
When you do not expect a high volume of queries per second, which would require indexes for performance.
Otherwise, consider adding an index for better performance.

Indexing with HNSW
HNSW is a graph-based approach to indexing multi-dimensional data. It constructs a multi-layered graph, where each layer is a subset of the previous one. During a vector similarity search, the algorithm navigates through the graph from the top layer to the bottom to quickly find the nearest neighbor. An HNSW graph is known for its superior performance in terms of speed and accuracy.

note
An HNSW index performs better than IVFFlat (in terms of speed-recall tradeoff) and can be created without any data in the table since there isn’t a training step like there is for an IVFFlat index. However, HNSW indexes have slower build times and use more memory.

HNSW graph

The search process begins at the topmost layer of the HNSW graph. From the starting node, the algorithm navigates to the nearest neighbor in the same layer. The algorithm repeats this step until it can no longer find neighbors more similar to the query vector.

Using the found node as an entry point, the algorithm moves down to the next layer in the graph and repeats the process of navigating to the nearest neighbor. The process of navigating to the nearest neighbor and moving down a layer is repeated until the algorithm reaches the bottom layer.

In the bottom layer, the algorithm continues navigating to the nearest neighbor until it cannot find any nodes that are more similar to the query vector. The current node is then returned as the most similar node to the query vector.

The key idea behind HNSW is that by starting the search at the top layer and moving down through each layer, the algorithm can quickly navigate to the area of the graph that contains the node that is most similar to the query vector. This makes the search process much faster than if it had to search through every node in the graph.

Tuning the HNSW algorithm
The following options allow you to tune the HNSW algorithm when creating an index:

m: Defines the maximum number of links created for each node during graph construction. A higher value increases accuracy (recall), but it also increases the size of the index in memory and index construction time. Higher values are typically used with high-dimensionality datasets or when a high degree of accuracy is required. The default value is 16. Acceptable values for m typically fall between 2 and 100. For many applications, beginning with a range of 12 to 48 is advisable.
ef_construction: Defines the size of the list for the nearest neighbors. This value influences the tradeoff between index quality and construction speed. A high ef_construction value creates a higher quality graph, enabling more accurate search results but also means that index construction takes longer. The value should be set to at least twice the value of m. The default setting is 64. There comes a point where increasing ef_construction no longer improves index quality. To evaluate search accuracy, you can start by setting ef_construction equal to ef_search and incrementally increasing ef_construction to achieve the desired result. If accuracy is lower than 0.9, there may be opportunity for improvement by increasing ef_construction.
This example demonstrates how to set the parameters:

CREATE INDEX ON items USING hnsw (embedding vector_l2_ops) WITH (m = 16, ef_construction = 64);
HNSW search tuning:

ef_search: Defines the size of the dynamic candidate list for search. The default value is 40. This value influences the trade-off between query accuracy (recall) and speed. A higher value increases accuracy at the cost of speed. The value should be equal to or larger than k, which is the number of nearest neighbors you want your search to return (defined by the LIMIT clause in your SELECT query).
To configure this value, do so using a SET statement before executing queries:

SET hnsw.ef_search = 100;
You can also use SET LOCAL inside a transaction to set it for a single query:

BEGIN;
SET LOCAL hnsw.ef_search = 100;
SELECT ...
COMMIT;
In summary:

To prioritize search speed over accuracy, use lower values for m and ef_search.
Conversely, to prioritize accuracy over search speed, use a higher value for m and ef_search.
Using a higher value for ef_construction yields more accurate search results at the cost of index build time.
Indexing with IVFFlat
IVFFlat indexes partition the dataset into clusters ("lists") to optimize for vector search.

You can create an IVFFlat index using the query below:

CREATE INDEX items_embedding_cosine_idx ON items USING ivfflat (embedding vector_l2_ops) WITH (lists = 1000);
IVFFlat in pgvector has two parameters:

lists

This parameter specifies the number of k-means clusters (or "lists") to divide the dataset into
Each cluster contains a subset of the data, and each data point belongs to the closest cluster centroid.
probes

This parameter determines the number of lists to explore during the search for the nearest neighbors.
By probing multiple lists, the search algorithm can find the closest points more accurately, balancing between speed and accuracy.
By default, the probes parameter is set to 1. This means that during a search, only one cluster is explored. This approach is fine if your query vector is close to the centroid. However, if the query vector is located near the edge of the cluster, closer neighbors in adjacent clusters will not be included in the search, which can result in a lower recall.

You must specify the number of probes in the same connection as the search query:

SET ivfflat.probes = 100;
SET enable_seqscan=off;
SELECT * FROM items ORDER BY embedding <-> '[0.011699999682605267,..., 0.008700000122189522]' LIMIT 100;
note
In the example above, enable_seqscan=off forces Postgres to use index scans.

The output of this query appears as follows:

Limit  (cost=1971.50..1982.39 rows=100 width=173) (actual time=4.500..5.738 rows=100 loops=1)
  ->  Index Scan using items_embedding_idx on vectors  (cost=1971.50..3060.50 rows=10000 width=173) (actual time=4.499..5.726 rows=100 loops=1)
        Order By: (vec <-> '[0.0117, ... ,0.0866]'::vector)
Planning Time: 0.295 ms
Execution Time: 5.867 ms
We've experimented with lists equal to 1000, 2000, and 4000, and probes equal to 1, 2, 10, 50, 100, 200.

Although there is a substantial gain in recall for increasing the number of probes, you will reach a point of diminishing returns when recall plateaus and execution time increases.

Therefore, we encourage experimenting with different values for probes and lists to achieve optimal search performance for your queries. Good places to start are:

Using a lists size equal to rows / 1000 for tables with up to 1 million rows, and sqrt(rows) for larger datasets.
Start with a probes value equal to lists / 10 for tables up to 1 million rows, and sqrt(lists) for larger datasets.
Conclusion
The sequential scan approach of pgvector performs well for small datasets but can be costly for larger ones. Use sequential scans if you require 100% accuracy, but expect performance issues with higher volumes of queries per second.

You can optimize searches using HNSW or IVFFlat indexes for approximate nearest neighbor (ANN) search, but HNSW indexes have better query performance than IVFFlat with build time and memory usage tradeoffs.

Be sure to test different index tuning parameter settings to find the right balance between speed and accuracy for your specific use case and dataset.

AI & Embeddings
/
AI tools
Google Colab
Use Google Colab with Neon for vector similarity search

Google Colab is a hosted Jupyter Notebook service that requires no setup to use and provides free access to computing resources, including GPUs and TPUs. You can use Google Colab to run python code through the browser.

This guide shows how to create a notebook in Colab, connect to a Neon database, install the pgvector extension to enabled Neon as a vector store, and run a vector search query.

Prerequisites
To perform the steps in this guide, you require a Neon database for storing vectors. You can use the ready-to-use neondb database or create your own. See Create a database for instructions.

Retrieve your database connection string
In the Connection Details widget on the Neon Dashboard, select a branch, a user, and the database you want to connect to. A connection string is constructed for you.

Connection details widget

Create a notebook
In your browser, navigate to Google Colab, and click New notebook.

Google Colab

Alternatively, you can open a predefined Google Colab notebook for this guide by clicking the Open in Colab button below.

Open In Colab
Connect to your database
In your Colab notebook, create a code block to define your database connection and create a cursor object. Replace postgresql://[user]:[password]@[neon_hostname]/[dbname] with the database connection string you retrieved in the previous step.

import os
import psycopg2
# Provide your Neon connection string
connection_string = "postgresql://[user]:[password]@[neon_hostname]/[dbname]"
# Connect using the connection string
connection = psycopg2.connect(connection_string)
# Create a new cursor object
cursor = connection.cursor()
Execute the code block (Ctrl + Enter).

Add a code block for testing the database connection.

# Execute this query to test the database connection
cursor.execute("SELECT 1;")
result = cursor.fetchone()
# Check the query result
if result == (1,):
    print("Your database connection was successful!")
else:
    print("Your connection failed.")
Execute the code block (Ctrl + Enter).

Install the pgvector extension
Create a codeblock to install the pgvector extension to enable your Neon database as a vector store:

# Execute this query to install the pgvector extension
cursor.execute("CREATE EXTENSION IF NOT EXISTS vector;")
Execute the code block (Ctrl + Enter).

Create a table and add vector data
Add a code block to create a table and insert data:

create_table_sql = '''
CREATE TABLE items (
id BIGSERIAL PRIMARY KEY,
embedding VECTOR(3)
);
'''
# Insert data
insert_data_sql = '''
INSERT INTO items (embedding) VALUES ('[1,2,3]'), ('[4,5,6]'), ('[7,8,9]');
'''
# Execute the SQL statements
cursor.execute(create_table_sql)
cursor.execute(insert_data_sql)
# Commit the changes
connection.commit()
Execute the code block (Ctrl + Enter).

Query your data
Add a codeblock to perform a vector similarity search.

cursor.execute("SELECT * FROM items ORDER BY embedding <-> '[3,1,2]' LIMIT 3;")
all_data = cursor.fetchall()
print(all_data)
Execute the code block (Ctrl + Enter).

Next steps
For more information about using Neon with pgvector, see The pgvector extension.

Azure Data Studio Notebooks
Use Azure Data Studio Notebooks with Neon for vector similarity search

A Jupyter Notebook is an open-source web application that allows you to create and share documents containing live code, equations, visualizations, and narrative text. Azure Data Studio supports Jupyter Notebooks, enabling users to combine SQL queries, Python code, and markdown text in a single interactive document.

This guide describes how to create a new python notebook in Azure Data Studio, connect to a Neon database, install the pgvector extension to enable Neon as a vector store, and run a vector search query.

Prerequisites
To perform the steps in this guide, you will require:

Azure Data Studio - Download the latest version of Azure Data Studio for your operating system here.

A Neon account - If you do not have one, sign up at Neon. Your Neon project comes with a ready-to-use Postgres database named neondb. You can use it, or create your own by following the instructions here.

Retrieve your Neon database connection string
In the Connection Details widget on the Neon Dashboard, select a branch, a user, and the database you want to connect to. A connection string is constructed for you.

Connection details widget

Create a notebook
Go to the File menu for Azure Data Studio and select New Notebook.
Select Python 3 for the Kernel and set Attach to to "localhost" where it can access your Python installation.
You can save the notebook using the Save or Save as... command from the File menu.

Configure Python for Notebooks
The first time you connect to the Python kernel in a notebook, the Configure Python for Notebooks page is displayed. You can select either:

New Python installation to install a new copy of Python for Azure Data Studio, or
Use existing Python installation to specify the path to an existing Python installation for Azure Data Studio to use
To view the location and version of the active Python kernel, you can create a code cell and run the following Python commands:

import os
import sys
print(sys.version_info)
print(os.path.dirname(sys.executable))
Running a code cell
You can create cells containing Python code that you can run in place by clicking the Run cell button (the round blue arrow) to the left of the cell. The results are shown in the notebook after the cell finishes running. In the pgvector example that follows, you'll add and execute several code cells.

pgvector example
After you've set up Azure Data Studio and have created a notebook, you can use the following basic example to get started with Neon and pgvector.

Install the psycopg driver
psycopg is a popular Postgres database adapter for the Python programming language. It allows Python applications to connect to and interact with Postgres databases.

Install the psycopg adapter by adding and executing the following code cell:

!pip install psycopg
Connect to your database
In your notebook, create a code block to define your Neon database connection and create a cursor object. Replace postgresql://[user]:[password]@[neon_hostname]/[dbname] with the database connection string you retrieved previously.

import os
import psycopg
# Provide your Neon connection string
connection_string = "postgresql://[user]:[password]@[neon_hostname]/[dbname]"
# Connect using the connection string
connection = psycopg.connect(connection_string)
# Create a new cursor object
cursor = connection.cursor()
Execute the code block.

Add a code block for testing the database connection.

# Execute this query to test the database connection
cursor.execute("SELECT 1;")
result = cursor.fetchone()
# Check the query result
if result == (1,):
    print("Your database connection was successful!")
else:
    print("Your connection failed.")
Execute the code block.

Install the pgvector extension
Create a codeblock to install the pgvector extension to enable your Neon database as a vector store:

# Execute this query to install the pgvector extension
cursor.execute("CREATE EXTENSION IF NOT EXISTS vector;")
Execute the code block.

Create a table and add vector data
Add a code block to create a table and insert data:

create_table_sql = '''
CREATE TABLE items (
id BIGSERIAL PRIMARY KEY,
embedding VECTOR(3)
);
'''
# Insert data
insert_data_sql = '''
INSERT INTO items (embedding) VALUES ('[1,2,3]'), ('[4,5,6]'), ('[7,8,9]');
'''
# Execute the SQL statements
cursor.execute(create_table_sql)
cursor.execute(insert_data_sql)
# Commit the changes
connection.commit()
Execute the code block.

Query your data
Add a codeblock to perform a vector similarity search.

cursor.execute("SELECT * FROM items ORDER BY embedding <-> '[3,1,2]' LIMIT 1;")
all_data = cursor.fetchall()
print(all_data)
Execute the code block.

Next steps
For more information about using Neon with pgvector, see The pgvector extension.

Glossary
access token
See Token.

active hours
A usage metric that tracks the amount of time a compute is active, rather than idle when suspended due to inactivity. The time that your compute is idle is not counted toward compute usage.

Also see Compute hours.

Activity Monitor
A process that monitors a Neon compute for activity. During periods of inactivity, the Activity Monitor gracefully places the compute into an Idle state to save energy and resources. The Activity Monitor closes idle connections after 5 minutes of inactivity. When a connection is made to an idle compute, the Activity Monitor reactivates the compute.

API
See Neon API.

API Key
A unique identifier used to authenticate a user or a calling program to an API. An API key is required to authenticate to the Neon API. For more information, see Manage API keys.

apply_config
A Neon Control Plane operation that applies a new configuration to a Neon object or resource. For example, creating, deleting, or updating Postgres users and databases initiates this operation. See System operations for more information.

Autosuspend
A feature that suspends a compute after a specified period of inactivity (5 minutes, by default) to minimize compute usage. This feature is also referred to as "scale to zero". When suspended, a compute is placed into an Idle state. Otherwise, the compute is in an Active state. Users on paid plans can configure the Autosuspend feature. For example, you can increase the delay period to reduce the frequency of suspensions, or you can disable autosuspend to maintain an "always-active" compute. For more information, see Edit a compute.

autoscaler-agent
A control mechanism in the Neon autoscaling system that collects metrics from VMs, makes scaling decisions, and performs checks and requests to implement those decisions.

Autoscaling
A feature that automatically adjusts the allocation of vCPU and RAM for compute within specified minimum and maximum compute size boundaries, optimizing for performance and cost-efficiency. For information about how Neon implements the Autoscaling feature, see Autoscaling.

Availability Checker
A periodic load generated by the Control Plane to determine if a compute can start and read and write data. The Availability Checker queries a system database without accessing user data. You can monitor these checks, how long they take, and how often they occur, on the Systems operations tab on the Monitoring page in the Neon Console.

backpressure
A mechanism that manages the lag between the Pageserver and compute node or the Pageserver and Write-Ahead Log (WAL) service. If the WAL service runs ahead of the Pageserver, the time to serve page requests increases, which could result in increased query times or timeout errors. The backpressure mechanism manages lag using a stop-and-wait backend throttling strategy.

branch
An isolated copy of data, similar to a Git branch. Data includes databases, schemas, tables, records, indexes, roles — everything that comprises data in a Postgres instance. Just as a Git branch allows developers to work on separate features or fixes without impacting their main line of code, a Neon branch enables users to modify a copy of their data in isolation from their main line of data. This approach facilitates parallel database development, testing, and other features, similar to Git's code branching system.

Each Neon project is created with a main line of data referred to as the root branch. A branch created from the root branch or another branch is a copy-on-write clone.

You can create a branch from the current or past state of another branch. A branch created from the current state of another branch includes the data that existed on that branch at the time of branch creation. A branch created from a past state of another branch includes the data that existed in the past state.

Connecting to a database on a branch requires connecting via a compute attached to the branch. See Connect to a branch.

Branching
A Neon feature that allows you to create an isolated copy of your data for parallel database development, testing, and other purposes, similar to branching in Git. See Branch.

check_availability
A Neon Control Plane operation that checks the availability of data in a branch and that a compute can start on a branch. Branches without a compute are not checked. This operation, performed by the availability checker, is a periodic load generated by the Control Plane. You can monitor these checks, how long they take, and how often they occur, on the Systems operations tab on the Monitoring page in the Neon Console.

CI/CD
Continuous integration and continuous delivery or continuous deployment.

CIDR notation
CIDR (Classless Inter-Domain Routing) notation is a method used to define ranges of IP addresses in network management. It is presented in the format of an IP address, followed by a slash, and then a number (e.g., 203.0.113.0/24). The number after the slash represents the size of the address block, providing a compact way to specify a large range of IP addresses. In Neon's IP Allow feature, CIDR notation allows for efficiently specifying a block of IP addresses, especially useful for larger networks or subnets. This can be advantageous when managing access to branches with numerous potential users, such as in a large development team or a company-wide network. For related information, see Configure IP Allow.

cgroups
Control groups, a Linux kernel feature that allows the organization, prioritization, and accounting of system resources for groups of processes.

Compute
A service that provides virtualized computing resources, including CPU, memory, and storage, for running applications. In the context of Neon, a compute runs Postgres.

Neon creates a primary read-write compute for the project's default branch. Neon supports both read-write and read replica computes. A branch can have a single primary (read-write) compute but supports multiple read replica computes. The compute hostname is required to connect to a Neon Postgres database from a client or application. A compute endpoint is the access point through which users connect to a Neon compute.

compute endpoint
The access point through which users connect to a Neon compute. In the context of Neon, the compute endpoint is represented by a connection string, which includes necessary credentials and connection parameters. This connection string enables clients, such as applications or users, to securely connect to a Postgres database running on a Neon compute. See connection string.

connection pooling
A method of creating a pool of connections and caching those connections for reuse. Neon supports PgBouncer in transaction mode for connection pooling. For more information, see Connection pooling.

connection string
A string containing details for connecting to a Neon Postgres database. The details include a user name (role), compute hostname, and database name; for example:

postgresql://alex:AbC123dEf@ep-cool-darkness-123456.us-east-2.aws.neon.tech/dbname
The compute hostname includes an endpoint_id (ep-cool-darkness-123456), a region slug (us-east-2), the cloud platform (aws), and Neon domain (neon.tech).

Connection strings for a Neon databases can be obtained from the Connection Details widget on the Neon Dashboard. For information about connecting to Neon, see Connect from any application.

compute size
The Compute Units (CU) that are allocated to a Neon compute. A Neon compute can have anywhere from .25 to 10 CU. The number of units determines the processing capacity of the compute.

Compute Unit (CU)
A unit that measures the processing power or "size" of a Neon compute. A Compute Unit (CU) includes vCPU and RAM. A Neon compute can have anywhere from .25 to 10 CUs. The following table shows the vCPU and RAM for each CU:

Compute Unit (CU)	vCPU	RAM
.25	.25	1 GB
.5	.5	2 GB
1	1	4 GB
2	2	8 GB
3	3	12 GB
4	4	16 GB
5	5	20 GB
6	6	24 GB
7	7	28 GB
8	8	32 GB
9	9	36 GB
10	10	40 GB
compute hours
A usage metric for tracking compute usage. 1 compute hour is equal to 1 active hour for a compute with 1 vCPU. If you have a compute with .25 vCPU, as you would on the Neon Free Plan, it would require 4 active hours to use 1 compute hour. On the other hand, if you have a compute with 4 vCPU, it would only take 15 minutes to use 1 compute hour.

To calculate compute hour usage, you would use the following formula:

compute hours = compute size * active hours
For more information, see Compute.

Also see Active hours.

console
See Neon Console.

Control Plane
The part of the Neon architecture that manages cloud storage and compute resources.

copy-on-write
A technique used to copy data efficiently. Neon uses the copy-on-write technique when creating branches. When a branch is created, data is marked as shared rather than physically duplicated. Parent and child branches refer to the same physical data resource. Data is only physically copied when a write occurs. The affected portion of data is copied and the write is performed on the copied data.

create_branch
A Neon Control Plane operation that creates a branch in a Neon project. For related information, see Manage branches. See System operations for more information.

create_timeline
Sets up storage and creates the default branch when a Neon project is created. See System operations for more information.

data-at-rest encryption
A method of storing inactive data that converts plaintext data into a coded form or cipher text, making it unreadable without an encryption key. Neon stores inactive data in NVMe SSD volumes. The data on NVMe instance storage is encrypted using an XTS-AES-256 block cipher implemented in a hardware module on the instance.

Data transfer
A usage metric that measures the total volume of data transferred out of Neon (known as "egress") during a given billing period. Neon does not charge for egress data, but we limit the amount of egress available on Free Plan projects to 5 GB per month. See Data tranfser.

Database
A named collection of database objects. A Neon project is created with a database that resides in the default public schema. If you do not specify a name for the database when creating a Noen project, it's created with the name neondb. A Neon project can contain multiple databases. Users cannot manipulate system databases, such as the postgres, template0, or template1 databases.

database branching
See Branching.

database fleet
A collection of database instances, typically managed as a single entity.

decoder plugin
Utilized in PostgreSQL replication architecture to decode WAL entries into a format understandable by the subscriber. The pgoutput decoder plugin is the default decoder, with alternatives like wal2json for specific use cases. Neon supports pgoutput and wal2json. See Postgres logical replication concepts.

dedicated resources
Resources including compute and storage dedicated to a single Neon account.

delete_tenant
A Neon Control Plane operation that deletes stored data when a Neon project is deleted. See System operations for more information.

Endpoint ID
A string that identifies a Neon compute. Neon Endpoint IDs are generated Heroku-like memorable random names, similar to ep-calm-flower-a5b75h79. These names are always prefixed by ep for "endpoint". You can find your Endpoint ID by navigating to your project in the Neon Console, selecting Branches from the sidebar, and clicking on a branch. The Endpoint ID is shown in the table under the Computes heading.

Egress
The data transferred out of the Neon service to an external destination. See Data transfer.

Enterprise plan
A custom volume-based paid plan offered by Neon. See Neon plans.

Free Plan
See Neon Free Plan.

History
The history of data changes for all branches in your Neon project. A history is maintained to support point-in-time restore. For more information, see Storage details.

IP allowlist
An IP allowlist is a security measure used in network and database management. It specifies a list of IP addresses that are permitted to access a certain resource. Any IP address not on the list is automatically blocked, ensuring that only authorized users or systems can gain access. In Neon, IP Allow is a Scale plan feature that can be used to control access to the branch where your database resides. The allowlist can be applied to all branches (the default) or the default branch only. For more information, see Configure the IP Allow list.

Kubernetes
An open-source container orchestration platform that automates the deployment, scaling, and management of containerized applications.

Kubernetes cluster
A set of interconnected nodes that run containerized applications and services using Kubernetes, an open-source orchestration platform for automating deployment, scaling, and management of containerized applications. The cluster consists of at least one control plane node, which manages the overall state of the cluster, and multiple worker nodes, where the actual application containers are deployed and executed. The worker nodes communicate with the control plane node to ensure the desired state of the applications is maintained.

Kubernetes node
A worker machine in a Kubernetes cluster, which runs containerized applications.

Kubernetes scheduler
A component of Kubernetes that assigns newly created pods to nodes based on resource availability and other constraints.

KVM
Kernel-based Virtual Machine, a virtualization infrastructure built into the Linux kernel that allows it to act as a hypervisor for virtual machines.

Launch plan
A paid plan offered by Neon that provides all of the resources, features, and support you need to launch your application. It's ideal for startups and growing businesses or applications. See Neon plans.

live migration
A feature provided by some hypervisors, such as QEMU, that allows the transfer of a running virtual machine from one host to another with minimal interruption.

Local File Cache
The Local File Cache (LFC) is a layer of caching that stores frequently accessed data from the storage layer in the local memory of the compute. This cache helps to reduce latency and improve query performance by minimizing the need to fetch data from the storage layer repeatedly. The LFC acts as an add-on or extension of Postgres shared buffers. In Neon the shared_buffers setting is always 128 MB, regardless of compute size. The LFC extends cache memory up to 80% of your compute's RAM.

logical data size
For a Postgres database, it is the size of the database, including all tables, indexes, views, and stored procedures. In Neon, a branch can have multiple databases. The logical data size for a branch is therefore equal to the total logical size of all databases on the branch.

logical replication
A method of replicating data between databases or platforms, focusing on replicating transactional changes (like INSERT, UPDATE, DELETE) rather than the entire database, enabling selective replication of specific tables or rows. Neon supports logical replication of data to external destinations. See Logical replication.

LSN
Log Sequence Number. A byte offset to a location in the WAL stream. The Neon branching feature supports creating branches with data up to a specified LSN.

LRU policy
Least Recently Used policy, an algorithm for cache replacement that evicts the least recently accessed items first.

Monitoring Dashboard
A feature of the Neon Console that provides several graphs to help you monitor system and database metrics, updated in real time based on your usage data.

Neon
A serverless Postgres platform designed to help developers build reliable and scalable applications faster. We separate compute and storage to offer modern developer features such as autoscaling, branching, point-in-time restore, and more. For more information, see Why Neon?.

Neon API
The Neon RESTful Application Programming Interface. Any operation performed in the Neon Console can also be performed using the Neon API.

Neon Console
A browser-based graphical interface for managing Neon projects and resources.

Neon Free Plan
A Neon service plan for which there are no usage charges. For information about the Neon Free Plan and associated limits, see Neon Free Plan.

Neon user
The user account that registers and authenticates with Neon using an email, GitHub, Google, or partner account. After authenticating, a Neon user account can create and manage projects, branches, users, databases, and other project resources.

NeonVM
A QEMU-based tool used by Neon to create and manage VMs within a Kubernetes cluster, allowing for the allocation and deallocation of vCPU and RAM. For more information, refer to the NeonVM source in the neondatabase/autoscaling repository.

non-default branch
Any branch in a Neon project that is not designated as the default branch. For more information, see Non-default branch.

Page
An 8KB unit of data, which is the smallest unit that Postgres uses for storing relations and indexes on disk. In Neon, a page is also the smallest unit of data that resides on a Pageserver. For information about Postgres page format, see Database Page Layout, in the PostgreSQL Documentation.

Paid plan
A paid Neon service plan. See Neon plans.

Pageserver
A Neon architecture component that reads WAL records from Safekeepers to identify modified pages. The Pageserver accumulates and indexes incoming WAL records in memory and writes them to disk in batches. Each batch is written to an immutable file that is never modified after creation. Using these files, the Pageserver can quickly reconstruct any version of a page dating back to the defined history retention period. Neon retains a history for all branches.

The Pageserver uploads immutable files to cloud storage, which is the final, highly durable destination for data. After a file is successfully uploaded to cloud storage, the corresponding WAL records can be removed from the Safekeepers.

passwordless authentication
The ability to authenticate without providing a password. Neon’s Passwordless auth feature supports passwordless authentication.

point-in-time restore
Restoration of data to a state that existed at an earlier time. Neon retains a history of changes in the form of Write-Ahead-Log (WAL) records, which allows you to restore data to an earlier time. A point-in-time restore is performed by creating a branch using the Time or LSN option. By default, Neon retains a history of changes for all branches in a project. The supported limits are 24 hours for Neon Free Plan users, 7 days for Launch plan users, and 30 days for Scale plan users. For more information about this feature, see Branching — Point-in-time restore.

pooled connection string
A pooled connection string in Neon includes a -pooler option, which directs your connection to a pooled connection port at the Neon Proxy. This is an example of a pooled connection:

postgresql://alex:AbC123dEf@ep-cool-darkness-123456-pooler.us-east-2.aws.neon.tech/dbname
A pooled connection can support a high number of concurrent users and is recommended for use with serverless and edge functions. For more information, see Connection pooling.

You can obtain a pooled connection string for your database from the Connection Details widget on the Neon Dashboard. Select the Pooled connection option to add the -pooler option to the connection string. For further instructions, see How to use connection pooling.

PostgreSQL
An open-source relational database management system (RDBMS) emphasizing extensibility and SQL compliance.

Postgres role
A Postgres role named for the registered Neon account is created with each Neon project. This role and any additional role created in the Neon Console, API, or CLI is assigned the neon_superuser role, which allows creating databases, roles, and reading and writing data in all tables, views, sequences. Roles created with SQL are created with the same basic public schema privileges granted to newly created roles in a standalone Postgres installation. These users are not assigned the neon_superuser role. They must be selectively granted permissions for each database object. For more information, see Manage database access.

Older projects may have a web-access system role, used by the SQL Editor and Neon’s Passwordless auth. The web-access role is system-managed. It cannot be modified, removed, or used in other authentication scenarios.

default branch
A designation that is given to a single branch in a Neon project. Each Neon project is created with a root branch called main, which carries the default branch designation by default.

The compute associated with a default branch remains available if you exceed your project's limits, ensuring uninterrupted access to data that resides on the default branch.

You can change your default branch, but a branch carrying the default branch designation cannot be deleted.

For more information, see default branch.

Project
A collection of branches, databases, roles, and other project resources and settings. A project contains a compute with a Postgres server and storage for the project data.

Project ID
A string that identifies your Neon project. Neon Project IDs are generated Heroku-like memorable random names, similar to cool-forest-86753099. You can find your project ID by navigating to your project in the Neon Console and selecting Settings from the sidebar. The project ID is also visible in the Neon Console URL after navigating to a project: https://console.neon.tech/app/projects/cool-forest-86753099

Project Sharing
A feature that allows you to share Neon projects with other Neon users. See Share a project for more information.

Project storage
The total volume of data stored in your Neon project. Also, a billing metric that measures the total volume of data and history, in GiB-hours, stored in your Neon project. See Storage.

prorate
Adjusting a payment or charge so it corresponds to the actual usage or time period involved, rather than charging a full amount. Neon prorates the cost for extra units of storage when you exceed your plan's allowance. For example, if you purchase an extra unit of storage halfway through the monthly billing period, you are only charged half the unit price.

Proxy
A Neon component that functions as a multitenant service that accepts and handles connections from clients that use the Postgres protocol.

protected branch
You can designate any Neon branch as a "protected branch", which implements a series of protections:

Protected branches cannot be deleted.
Protected branches cannot be reset.
Projects with protected branches cannot be deleted.
Computes associated with a protected branch cannot be deleted.
New passwords are automatically generated for Postgres roles on branches created from protected branches.
With additional configuration steps, you can apply IP restrictions to protected branches only.
The protected branches feature is available with the Neon Scale plan. Typically, the protected branch status is given to a branch or branches that hold production data or sensitive data. For information about how to configure a protected branch, refer to our Protected branches guide.

Publisher
In the context of logical replication, the publisher is the primary data source where changes occur. It's responsible for sending those changes to one or more subscribers. A Neon database can act as a publisher in a logical replication setup. See Logical replication.

QEMU
A free and open-source emulator and virtualizer that performs hardware virtualization.

RAM
Random Access Memory, a type of computer memory used to store data that is being actively processed.

region
The geographic location where Neon project resources are located. Neon supports creating projects in several Amazon Web Services (AWS) regions. For information about regions supported by Neon, see Regions.

replication slot
On the publisher database in a logical replication setup, replication slots track the progress of replication to ensure no data in the WAL is purged before the subscriber has successfully replicated it, thus preventing data loss or inconsistency. See Postgres logical replication concepts.

resale
Selling the Neon service as part of another service offering. Neon's Platform Partnership plan offers resale of the Neon service as an option. See Neon plans for more information.

root branch
The primary line of data for every Neon project, initially named main. The root branch cannot be deleted and is set as the default branch of your Neon project by default. You can change your project's default branch, but you cannot change the root branch.

Safekeeper
A Neon architecture component responsible for the durability of database changes. Postgres streams WAL records to Safekeepers. A quorum algorithm based on Paxos ensures that when a transaction is committed, it is stored on a majority of Safekeepers and can be recovered if a node is lost. Safekeepers are deployed in different availability zones to ensure high availability and durability.

scale-to-zero
Scale-to-zero refers to Neon's Autosuspend feature, which places a compute into an Idle state when it is not being used. Neon suspends a compute after five minutes of inactivity, by default. See Autosuspend.

Scale plan
A paid plan offered by Neon that provides full platform and support access. It's designed for scaling production workloads. See Neon plans.

Schema Diff
A Neon feature that lets you compare database schemas between different branches for better debugging, code review, and team collobration. See Schema Diff.

serverless
A cloud-based development model that enables developing and running applications without having to manage servers.

shared buffers
A memory area in Postgres for caching blocks of data from storage (disk on standalone Postgres or Pageservers in Neon). This cache enhances the performance of database operations by reducing the need to access the slower storage for frequently accessed data. Neon uses a Local File Cache (LFC), which acts as an add-on or extension of shared buffers. In Neon the shared_buffers setting is always 128 MB, regardless of compute size. The LFC extends cache memory up to 80% of your compute's RAM. For additional information about shared buffers in Postgres, see Resource Consumption, in the Postgres documentation.

SNI
Server Name Indication. A TLS protocol extension that allows a client or browser to indicate which hostname it wants to connect to at the beginning of a TLS handshake.

SQL Editor
A feature of the Neon Console that enables running queries on a Neon database. The SQL Editor also enables saving queries, viewing query history, and analyzing or explaining queries.

start_compute
A Neon Control Plane operation that starts a compute when there is an event or action that requires compute resources. For example, connecting to a suspended compute initiates this operation. See System operations for more information. For information about how Neon manages compute resources, see Compute lifecycle.

Storage
Where data is recorded and stored. Neon storage consists of Pageservers, which store hot data, and a cloud object store, such as Amazon S3, that stores cold data for cost optimization and durability.

Also, a usage metric that tracks the total volume of data and history stored in Neon. For more information, see Storage.

subscriber
The database or platform receiving changes from the publisher in a logical replication setup. It applies changes received from the publisher to its own data set. Currently, a Neon database can only act as a publisher in a logical replication setup. See Logical replication.

subscription
Represents the downstream side of logical replication, establishing a connection to the publisher and subscribing to one or more publications to receive updates. See Postgres logical replication concepts.

suspend_compute
A Neon Control Plane operation that suspends a compute after a period of inactivity. See System operations for more information. For information about how Neon manages compute resources, see Compute lifecycle.

technical preview
An early version of a feature or changes released for testing and feedback purposes.

tenant_attach
A Neon Control Plane operation that attaches a Neon project to storage. For example, this operation occurs when when you create a new Neon project. See System operations for more information.

tenant_detach
A Neon Control Plane operation that detaches a Neon project from storage. For example, this operation occurs after the project as been idle for 30 days. See System operations for more information.

tenant_reattach
A Neon Control Plane operation that reattaches a Neon project to storage. For example, this operation occurs when a detached Neon project receives a request. See System operations for more information.

token
An encrypted access token that enables you to authenticate with Neon using the Neon API. An access token is generated when creating a Neon API key. For more information, see Manage API keys.

unpooled connection string
An unpooled connection string connects to your Neon database directly. It does not use connection pooling, and it looks similar to this:

postgresql://alex:AbC123dEf@ep-cool-darkness-123456.us-east-2.aws.neon.tech/dbname
You can obtain an unpooled connection string for your database from the Connection Details widget on the Neon Dashboard. Ensure that the Pooled connection option is not selected. A direct connection is subject to the max_connections limit for your compute. For more information, see How to size your compute.

Time Travel
A Neon feature that lets you connect to any selected point in time within your history retention window and run queries against that connection. See Time Travel.

user
See Neon user and Postgres role.

vm-monitor
A program that runs inside the VM alongside Postgres, responsible for requesting more resources from the autoscaler-agent and validating proposed downscaling to ensure sufficient memory.

vCPU
Virtual CPU, a unit of processing power allocated to a virtual machine or compute.

WAL
See Write-Ahead Logging.

WAL receiver
In logical replication, on the subscriber side, the WAL receiver is a process that receives the replication stream (decoded WAL data) and applies these changes to the subscriber's database. See Postgres logical replication concepts.

WAL sender
In logical replication, the WAL sender is a process on the publisher database that reads the WAL and sends relevant data to the subscriber. See Postgres logical replication concepts.

WAL slice
Write-ahead logs in a specific LSN range.

WAL stream
The stream of data written to the Write-Ahead Log (WAL) during transactional processing.

working set
A subset of frequently accessed or recently used data and indexes that ideally reside in memory (RAM) for quick access, allowing for better performance. See how to size your compute to learn how to set your minimum compute to an adequate size to handle your working set.

Write-Ahead Logging (WAL)
A standard mechanism that ensures the durability of your data. Neon relies on WAL to separate storage and compute, and to support features such as branching and point-in-time restore.

In logical replication, the WAL records all changes to the data, serving as the source for data that needs to be replicated.

Written data
A usage metric that measures the total volume of data written from compute to storage within a given billing period, measured in gigibytes (GiB). Writing data from compute to storage ensures the durability and integrity of your data.

